<?xml version='1.0' encoding='utf-8'?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:prism="http://prismstandard.org/namespaces/basic/3.0/" version="2.0"><channel><title>ZotWatch Feed</title><link>https://ehehe.cn/zotwatch/</link><description>AI-assisted literature watch</description><lastBuildDate>Mon, 22 Dec 2025 05:51:58 +0000</lastBuildDate><item><title>Spatial-temporal landslide susceptibility modeling in data-scarce areas: Utilizing recurrent neural networks and transfer learning</title><link>https://doi.org/10.1016/j.eswa.2025.130929</link><guid>10.1016/j.eswa.2025.130929</guid><pubDate>Sat, 20 Dec 2025 07:23:43 +0000</pubDate><dc:creator>Zhengshan Tian</dc:creator><dc:creator>Yong Zhang</dc:creator><dc:creator>Yi Wang</dc:creator><dc:creator>Zhice Fang</dc:creator><dc:creator>Shuhui Zheng</dc:creator><prism:publicationName>Expert Systems with Applications</prism:publicationName><prism:doi>10.1016/j.eswa.2025.130929</prism:doi><description>Given the scarcity of time-series landslide inventories and their uneven spatiotemporal distribution, conducting spatiotemporal landslide susceptibility assessments (LSA) in regions with limited historical landslide data poses significant challenges. In this study, we propose a novel landslide susceptibility assessment framework that combines Recurrent Neural Networks (RNNs) and Transfer Learning (TL) methods to increase the accuracy of spatial–temporal LSA. Two rainfall-prone regions in southeastern China, Taiwan and Hong Kong, were selected as study areas. To establish landslide susceptibility models for the sampled areas, we used three types of recurrent neural networks (Long Short-Term Memory (LSTM), Recurrent Neural Network (RNN), and Gated Recurrent Unit (GRU)) along with four TL methods (model-based TL, feature-based TL, GAMs-based ensemble TL, and unsupervised feature-based TL). Landslide data from Hualien (2004–2017) was selected as the source domain, while three temporal phases of data from Hong Kong (2012–2019) served as the target domain to assess the feasibility of spatiotemporal transfer learning. The results indicate that the unsupervised feature-based TL model (DAE-RNN) exhibits better adaptability and predictive performance compared to other models. Therefore, we used unlabeled source data to pretrain the DAE-RNN and subsequently fine-tune the model with spatiotemporal data from Hong Kong (1992–2009). Further analysis reveals that very high-susceptibility areas are primarily concentrated in Lantau Island and the northeastern part of the Kowloon Peninsula, with a potential migration trend toward the central region around 1999. These findings indicate that the proposed framework can effectively achieve spatiotemporal transfer of landslide susceptibility, providing a valuable scientific basis for the dynamic monitoring and early warning of landslide risks in Hong Kong.
Published: 2025-12-20T07:23:43+00:00
Venue: Expert Systems with Applications
Score: 0.438 (consider)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Zhengshan Tian; Yong Zhang; Yi Wang; Zhice Fang; Shuhui Zheng&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; Expert Systems with Applications&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1016/j.eswa.2025.130929"&gt;10.1016/j.eswa.2025.130929&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.438 (consider)&lt;/p&gt;
&lt;p&gt;Given the scarcity of time-series landslide inventories and their uneven spatiotemporal distribution, conducting spatiotemporal landslide susceptibility assessments (LSA) in regions with limited historical landslide data poses significant challenges. In this study, we propose a novel landslide susceptibility assessment framework that combines Recurrent Neural Networks (RNNs) and Transfer Learning (TL) methods to increase the accuracy of spatial–temporal LSA. Two rainfall-prone regions in southeastern China, Taiwan and Hong Kong, were selected as study areas. To establish landslide susceptibility models for the sampled areas, we used three types of recurrent neural networks (Long Short-Term Memory (LSTM), Recurrent Neural Network (RNN), and Gated Recurrent Unit (GRU)) along with four TL methods (model-based TL, feature-based TL, GAMs-based ensemble TL, and unsupervised feature-based TL). Landslide data from Hualien (2004–2017) was selected as the source domain, while three temporal phases of data from Hong Kong (2012–2019) served as the target domain to assess the feasibility of spatiotemporal transfer learning. The results indicate that the unsupervised feature-based TL model (DAE-RNN) exhibits better adaptability and predictive performance compared to other models. Therefore, we used unlabeled source data to pretrain the DAE-RNN and subsequently fine-tune the model with spatiotemporal data from Hong Kong (1992–2009). Further analysis reveals that very high-susceptibility areas are primarily concentrated in Lantau Island and the northeastern part of the Kowloon Peninsula, with a potential migration trend toward the central region around 1999. These findings indicate that the proposed framework can effectively achieve spatiotemporal transfer of landslide susceptibility, providing a valuable scientific basis for the dynamic monitoring and early warning of landslide risks in Hong Kong.&lt;/p&gt;</content:encoded></item><item><title>Automated TLS multi-scan registration in forest environments: A novel solution based on hash table</title><link>https://doi.org/10.1016/j.isprsjprs.2025.11.021</link><guid>10.1016/j.isprsjprs.2025.11.021</guid><pubDate>Sat, 20 Dec 2025 07:54:26 +0000</pubDate><dc:creator>Xiaochen Wang</dc:creator><dc:creator>Xinlian Liang</dc:creator><prism:publicationName>ISPRS Journal of Photogrammetry and Remote Sensing</prism:publicationName><prism:doi>10.1016/j.isprsjprs.2025.11.021</prism:doi><description>Terrestrial laser scanning (TLS) has proven to be an effective tool for forest inventories due to its accurate, non-destructive capability to document 3D space structures. The multi-scan mode of TLS enables comprehensive data acquisition, but the point cloud of each scan must be aligned to a common coordinate frame. In practice, the most common solution involves manually placing artificial markers in the field, which is time-consuming and labor-intensive. Consequently, the automated multi-scan registration method is highly appreciated for subsequent applications. This study presents an automated TLS multi-scan registration algorithm for forest point clouds, HashReg, utilizing the high-efficiency operations of Hash Table. HashReg comprises four key procedures, including stem mapping, estimating coarse transformation parameters, factor graph optimization, and fine-tuned registration. Using optimized transformation parameters, the global poses of individual TLS scans are subsequently determined within a unified coordinate system through a depth-first strategy. Extensive experiments were performed on four datasets with diverse forest characteristics, such as dense and sparse stems, flat and undulating terrain, and natural and plantation forests. The experimental results demonstrate that HashReg achieves milliradian-level rotation accuracy and centimeter-level translation accuracy, i.e., 0–3 mrad and 0–3 cm for most of the plots, respectively. Another evaluation metric, the point-wise upper bound errors, is reported to show the variation of point discrepancy with increasing distance. For most plots, these errors remained within the centimeter range, i.e., 1–4 cm, 1–5 cm, and 2–7 cm for the distance at 5 m, 10 m, and 20 m respectively. Moreover, the efficiency of HashReg’s four key procedures was also assessed. The running time of coarse registration and global optimization is at the millisecond level, i.e., 4 ms and 6 ms, while the stem mapping and fine registration were at the second level, i.e., 3 s and 15 s. Comparison with four state-of-the-art (SOTA) point cloud registration approaches, including FMP + BnB, HL-MRF, GlobalMatch, and SGHR, was quantitatively conducted on three public datasets. HashReg achieves superior accuracy, i.e., ranking first or second across all plots, with 100 % successful registrations. It also has substantially higher efficiency, with runtime improvements exceeding two-fold relative to the SOTA methods. All these advantages demonstrate that HashReg can bridge the gap between raw data and practical applications. The implementation of HashReg is open-sourced at https://github.com/MSpace-WHU/Forest_TLS_Reg .
Published: 2025-12-20T07:54:26+00:00
Venue: ISPRS Journal of Photogrammetry and Remote Sensing
Score: 0.427 (consider)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Xiaochen Wang; Xinlian Liang&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; ISPRS Journal of Photogrammetry and Remote Sensing&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1016/j.isprsjprs.2025.11.021"&gt;10.1016/j.isprsjprs.2025.11.021&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.427 (consider)&lt;/p&gt;
&lt;p&gt;Terrestrial laser scanning (TLS) has proven to be an effective tool for forest inventories due to its accurate, non-destructive capability to document 3D space structures. The multi-scan mode of TLS enables comprehensive data acquisition, but the point cloud of each scan must be aligned to a common coordinate frame. In practice, the most common solution involves manually placing artificial markers in the field, which is time-consuming and labor-intensive. Consequently, the automated multi-scan registration method is highly appreciated for subsequent applications. This study presents an automated TLS multi-scan registration algorithm for forest point clouds, HashReg, utilizing the high-efficiency operations of Hash Table. HashReg comprises four key procedures, including stem mapping, estimating coarse transformation parameters, factor graph optimization, and fine-tuned registration. Using optimized transformation parameters, the global poses of individual TLS scans are subsequently determined within a unified coordinate system through a depth-first strategy. Extensive experiments were performed on four datasets with diverse forest characteristics, such as dense and sparse stems, flat and undulating terrain, and natural and plantation forests. The experimental results demonstrate that HashReg achieves milliradian-level rotation accuracy and centimeter-level translation accuracy, i.e., 0–3 mrad and 0–3 cm for most of the plots, respectively. Another evaluation metric, the point-wise upper bound errors, is reported to show the variation of point discrepancy with increasing distance. For most plots, these errors remained within the centimeter range, i.e., 1–4 cm, 1–5 cm, and 2–7 cm for the distance at 5 m, 10 m, and 20 m respectively. Moreover, the efficiency of HashReg’s four key procedures was also assessed. The running time of coarse registration and global optimization is at the millisecond level, i.e., 4 ms and 6 ms, while the stem mapping and fine registration were at the second level, i.e., 3 s and 15 s. Comparison with four state-of-the-art (SOTA) point cloud registration approaches, including FMP + BnB, HL-MRF, GlobalMatch, and SGHR, was quantitatively conducted on three public datasets. HashReg achieves superior accuracy, i.e., ranking first or second across all plots, with 100 % successful registrations. It also has substantially higher efficiency, with runtime improvements exceeding two-fold relative to the SOTA methods. All these advantages demonstrate that HashReg can bridge the gap between raw data and practical applications. The implementation of HashReg is open-sourced at https://github.com/MSpace-WHU/Forest_TLS_Reg .&lt;/p&gt;</content:encoded></item><item><title>Symbolic Distillation of a Fully Tokenized Transformer for Settlement Prediction in Pre-bored Grouted Planted Nodular Piles in Stratified Soils</title><link>https://doi.org/10.1016/j.knosys.2025.115186</link><guid>10.1016/j.knosys.2025.115186</guid><pubDate>Sun, 21 Dec 2025 22:42:21 +0000</pubDate><dc:creator>Hung La</dc:creator><dc:creator>Tan Nguyen</dc:creator><prism:publicationName>Knowledge-Based Systems</prism:publicationName><prism:doi>10.1016/j.knosys.2025.115186</prism:doi><description>This study introduces an interpretable and high-fidelity hybrid modeling framework for predicting the load–settlement behavior of Pre-bored Grouted Planted Nodular (PGPN) piles in stratified soils. A depth-resolved database of 1,002 full-scale static load tests, containing ten segmental Standard Penetration Test (SPT) indices along the embedment, was compiled to capture realistic soil–pile interactions. The proposed Fully Tokenized Transformer (FT-Transformer), optimized via the Tree-structured Parzen Estimator (TPE), outperformed leading tabular learning architectures—including TabNet, SAINT, XGBoost, and the vanilla Transformer—across thirty randomized splits, achieving mean test performance of R² = 0.943 and RMSE = 3.14 mm. A series of ablation studies confirmed the contribution of the tokenization strategy and TPE optimization to model stability and reproducibility. Multi-level interpretability analyses combining SHAP, permutation importance, attention visualization, and 2-D partial dependence plots indicated that applied load ( P ), pile diameter ( D c ), and upper-layer SPT resistance govern the nonlinear soil–pile response, reflecting the predominance of shaft friction over end bearing. To ensure field practicality, a symbolic distillation step using PySR converted the trained transformer into a closed-form equation that preserves near-identical predictive fidelity (R² ≈ 0.94) while enabling instantaneous hand computation. The symbolic model was independently validated using two unseen full-scale load tests from published studies, demonstrating strong generalization to external conditions. This FT-Transformer–TPE–PySR framework thus establishes a new paradigm for explainable, data-driven, and field-deployable foundation design—bridging deep learning accuracy with transparent engineering interpretability.
Published: 2025-12-21T22:42:21+00:00
Venue: Knowledge-Based Systems
Score: 0.423 (consider)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Hung La; Tan Nguyen&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; Knowledge-Based Systems&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1016/j.knosys.2025.115186"&gt;10.1016/j.knosys.2025.115186&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.423 (consider)&lt;/p&gt;
&lt;p&gt;This study introduces an interpretable and high-fidelity hybrid modeling framework for predicting the load–settlement behavior of Pre-bored Grouted Planted Nodular (PGPN) piles in stratified soils. A depth-resolved database of 1,002 full-scale static load tests, containing ten segmental Standard Penetration Test (SPT) indices along the embedment, was compiled to capture realistic soil–pile interactions. The proposed Fully Tokenized Transformer (FT-Transformer), optimized via the Tree-structured Parzen Estimator (TPE), outperformed leading tabular learning architectures—including TabNet, SAINT, XGBoost, and the vanilla Transformer—across thirty randomized splits, achieving mean test performance of R² = 0.943 and RMSE = 3.14 mm. A series of ablation studies confirmed the contribution of the tokenization strategy and TPE optimization to model stability and reproducibility. Multi-level interpretability analyses combining SHAP, permutation importance, attention visualization, and 2-D partial dependence plots indicated that applied load ( P ), pile diameter ( D c ), and upper-layer SPT resistance govern the nonlinear soil–pile response, reflecting the predominance of shaft friction over end bearing. To ensure field practicality, a symbolic distillation step using PySR converted the trained transformer into a closed-form equation that preserves near-identical predictive fidelity (R² ≈ 0.94) while enabling instantaneous hand computation. The symbolic model was independently validated using two unseen full-scale load tests from published studies, demonstrating strong generalization to external conditions. This FT-Transformer–TPE–PySR framework thus establishes a new paradigm for explainable, data-driven, and field-deployable foundation design—bridging deep learning accuracy with transparent engineering interpretability.&lt;/p&gt;</content:encoded></item><item><title>Test-Time Reconstruction with Physics-integrated Dual Cooperative Learning for Unsupervised Model Adaptation</title><link>https://doi.org/10.1016/j.eswa.2025.130831</link><guid>10.1016/j.eswa.2025.130831</guid><pubDate>Sun, 21 Dec 2025 15:36:50 +0000</pubDate><dc:creator>Binchun Lu</dc:creator><dc:creator>Lidan Fu</dc:creator><dc:creator>Juntao Ren</dc:creator><dc:creator>Yixuan Pan</dc:creator><dc:creator>Yonggui Dong</dc:creator><prism:publicationName>Expert Systems with Applications</prism:publicationName><prism:doi>10.1016/j.eswa.2025.130831</prism:doi><description>Electromagnetic tomography (EMT) has emerged as an effective nondestructive imaging technique, wherein reconstruction based on a physical forward operator (FO) is essential for visualizing cross-sectional conductivity distributions of the tested medium. However, environmental and operational variations introduce uncertainty into the FO, causing deviations from its initial value. Prevailing learning-based methods, typically trained on the source domain under the assumption that the FO is known and stable, often experience significant performance degradation when operating under changed conditions. To mitigate this limitation, this study employs unsupervised learning to adapt to domain shifts caused by variations in the FO, relying solely on limited target domain measurements. Specifically, we develop a novel test-time reconstruction method based on physics-integrated dual cooperative network (TTR-PDCNet), comprising an unfolding sub-network based on physical FO for range-space learning, and a spatial-frequency Mamba sub-network for null-space learning. The proposed TTR-PDCNet employs a dual cooperative learning mechanism to guide the end-to-end self-supervised adaptation. Moreover, direct inverse path of invertible flow and iterative inverse path of unfolding module promote consistency for the reconstruction in the range space, while sub-networks in the two spaces jointly achieve mutual consistency across the full representational space. The proposed method demonstrates empirical success in reconstruction tasks via model adaptation, with extensive experiments conducted on both simulation and a real EMT system, highlighting its advantages over existing fixed-model and test-time adaptation approaches. This paves the way for unsupervised test-time reconstruction under practical working conditions with FO mismatch.
Published: 2025-12-21T15:36:50+00:00
Venue: Expert Systems with Applications
Score: 0.423 (consider)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Binchun Lu; Lidan Fu; Juntao Ren; Yixuan Pan; Yonggui Dong&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; Expert Systems with Applications&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1016/j.eswa.2025.130831"&gt;10.1016/j.eswa.2025.130831&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.423 (consider)&lt;/p&gt;
&lt;p&gt;Electromagnetic tomography (EMT) has emerged as an effective nondestructive imaging technique, wherein reconstruction based on a physical forward operator (FO) is essential for visualizing cross-sectional conductivity distributions of the tested medium. However, environmental and operational variations introduce uncertainty into the FO, causing deviations from its initial value. Prevailing learning-based methods, typically trained on the source domain under the assumption that the FO is known and stable, often experience significant performance degradation when operating under changed conditions. To mitigate this limitation, this study employs unsupervised learning to adapt to domain shifts caused by variations in the FO, relying solely on limited target domain measurements. Specifically, we develop a novel test-time reconstruction method based on physics-integrated dual cooperative network (TTR-PDCNet), comprising an unfolding sub-network based on physical FO for range-space learning, and a spatial-frequency Mamba sub-network for null-space learning. The proposed TTR-PDCNet employs a dual cooperative learning mechanism to guide the end-to-end self-supervised adaptation. Moreover, direct inverse path of invertible flow and iterative inverse path of unfolding module promote consistency for the reconstruction in the range space, while sub-networks in the two spaces jointly achieve mutual consistency across the full representational space. The proposed method demonstrates empirical success in reconstruction tasks via model adaptation, with extensive experiments conducted on both simulation and a real EMT system, highlighting its advantages over existing fixed-model and test-time adaptation approaches. This paves the way for unsupervised test-time reconstruction under practical working conditions with FO mismatch.&lt;/p&gt;</content:encoded></item><item><title>Multi-target regression measurement model based on cascaded broad stochastic configuration network and its applications</title><link>https://doi.org/10.1016/j.eswa.2025.130885</link><guid>10.1016/j.eswa.2025.130885</guid><pubDate>Sat, 20 Dec 2025 16:16:39 +0000</pubDate><dc:creator>Kaicheng Hu</dc:creator><dc:creator>Aijun Yan</dc:creator><prism:publicationName>Expert Systems with Applications</prism:publicationName><prism:doi>10.1016/j.eswa.2025.130885</prism:doi><description>In the production process, the key parameters characterizing the operating conditions are diverse. Constructing a multi-target regression (MTR) measurement model to simultaneously monitor multiple key parameters can provide comprehensive information for optimization control and intelligent decision-making. However, production processes often involve complex physicochemical reactions, and there are high-dimensional nonlinear relationships between multiple parameters, which makes the construction of MTR models challenging. This paper proposes a multi-target cascaded broad stochastic configuration network (M-CBSCN) modeling method to construct high-performance MTR models. This method configures hidden layer nodes based on a supervisory mechanism and introduces sparse coding to enhance the sparsity of input weights. The network structure and parameters are collaboratively optimized to explore the correlations between multiple targets by adding a latent layer and group sparse regularization, thereby reducing prediction errors. On this basis, the modeling accuracy is further enhanced through cascading hidden layer nodes. Theoretical analysis validates the convergence of M-CBSCN algorithm. Experimental results on benchmark and real industrial datasets demonstrate that M-CBSCN measurement model exhibits satisfactory performance.
Published: 2025-12-20T16:16:39+00:00
Venue: Expert Systems with Applications
Score: 0.420 (consider)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Kaicheng Hu; Aijun Yan&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; Expert Systems with Applications&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1016/j.eswa.2025.130885"&gt;10.1016/j.eswa.2025.130885&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.420 (consider)&lt;/p&gt;
&lt;p&gt;In the production process, the key parameters characterizing the operating conditions are diverse. Constructing a multi-target regression (MTR) measurement model to simultaneously monitor multiple key parameters can provide comprehensive information for optimization control and intelligent decision-making. However, production processes often involve complex physicochemical reactions, and there are high-dimensional nonlinear relationships between multiple parameters, which makes the construction of MTR models challenging. This paper proposes a multi-target cascaded broad stochastic configuration network (M-CBSCN) modeling method to construct high-performance MTR models. This method configures hidden layer nodes based on a supervisory mechanism and introduces sparse coding to enhance the sparsity of input weights. The network structure and parameters are collaboratively optimized to explore the correlations between multiple targets by adding a latent layer and group sparse regularization, thereby reducing prediction errors. On this basis, the modeling accuracy is further enhanced through cascading hidden layer nodes. Theoretical analysis validates the convergence of M-CBSCN algorithm. Experimental results on benchmark and real industrial datasets demonstrate that M-CBSCN measurement model exhibits satisfactory performance.&lt;/p&gt;</content:encoded></item><item><title>Multi-objective and simulation approaches for flowshop scheduling in rubber manufacturing with recycle waste and uncertainties</title><link>https://doi.org/10.1016/j.eswa.2025.130917</link><guid>10.1016/j.eswa.2025.130917</guid><pubDate>Sun, 21 Dec 2025 15:36:50 +0000</pubDate><dc:creator>Peng-Yeng Yin</dc:creator><prism:publicationName>Expert Systems with Applications</prism:publicationName><prism:doi>10.1016/j.eswa.2025.130917</prism:doi><description>Responsible consumption and production is Sustainable Development Goal 12 set by the United Nations. The focus is to reduce resources during use and creating of the products, and to minimize environmental harm. To meet this goal, production in many industries needs to be transformed. One example is the rubber industry where many rubber scraps are disposed by incineration and landfill. The combustion smoke and landfill washouts during these processes create harm to environment. This paper investigates a dual-line flowshop practiced by a rubber factory which transforms rubber scraps from the primal line into reusable materials for the dual line. As the dual line uses only reusable materials from the primal line, the two lines are interdependent. It is realized from interviews with factory workers, machine processing times and rubber scraps quantities are uncertainty parameters and manifest some characteristics. This paper proposes novel techniques for building risk-aware models based on Monte Carlo Simulation (MCS) on uncertainty parameters. Both mono-objective and multi-objective models are proposed to minimize makespan with a maximum loss measured at a specified confidence level. The novelty of proposed models relies on simulation optimization (SO) framework which combines MCS simulation and two optimization approaches, genetic algorithm (GA) and Non-dominated Sorting Genetic Algorithm II (NSGA-II). MCS models the stochastic parameters while the embedded optimization methods effectively find near-optimal solutions. A novel chromosome structure is designed to simultaneously deal with job scheduling problem on two production lines. Experimental results show that the proposed framework can produce shorter makespans than existing heuristics under specified risk levels over MCS simulations, and the existing heuristics cannot measure the risk of the produced result. Thorough sensitive analysis is conducted to validate the used parameter values. The scalability analysis shows that the proposed framework is scalable to large problem sizes. This paper proposes modifications and integration of novel techniques to adapt to a risk-aware simulation optimization framework for solving a real-world rubber circular production problem.
Published: 2025-12-21T15:36:50+00:00
Venue: Expert Systems with Applications
Score: 0.416 (consider)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Peng-Yeng Yin&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; Expert Systems with Applications&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1016/j.eswa.2025.130917"&gt;10.1016/j.eswa.2025.130917&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.416 (consider)&lt;/p&gt;
&lt;p&gt;Responsible consumption and production is Sustainable Development Goal 12 set by the United Nations. The focus is to reduce resources during use and creating of the products, and to minimize environmental harm. To meet this goal, production in many industries needs to be transformed. One example is the rubber industry where many rubber scraps are disposed by incineration and landfill. The combustion smoke and landfill washouts during these processes create harm to environment. This paper investigates a dual-line flowshop practiced by a rubber factory which transforms rubber scraps from the primal line into reusable materials for the dual line. As the dual line uses only reusable materials from the primal line, the two lines are interdependent. It is realized from interviews with factory workers, machine processing times and rubber scraps quantities are uncertainty parameters and manifest some characteristics. This paper proposes novel techniques for building risk-aware models based on Monte Carlo Simulation (MCS) on uncertainty parameters. Both mono-objective and multi-objective models are proposed to minimize makespan with a maximum loss measured at a specified confidence level. The novelty of proposed models relies on simulation optimization (SO) framework which combines MCS simulation and two optimization approaches, genetic algorithm (GA) and Non-dominated Sorting Genetic Algorithm II (NSGA-II). MCS models the stochastic parameters while the embedded optimization methods effectively find near-optimal solutions. A novel chromosome structure is designed to simultaneously deal with job scheduling problem on two production lines. Experimental results show that the proposed framework can produce shorter makespans than existing heuristics under specified risk levels over MCS simulations, and the existing heuristics cannot measure the risk of the produced result. Thorough sensitive analysis is conducted to validate the used parameter values. The scalability analysis shows that the proposed framework is scalable to large problem sizes. This paper proposes modifications and integration of novel techniques to adapt to a risk-aware simulation optimization framework for solving a real-world rubber circular production problem.&lt;/p&gt;</content:encoded></item><item><title>ST-Imputer: Multivariate Dependency-aware Diffusion Network with Physics Guidance for Spatiotemporal Imputation</title><link>https://doi.org/10.1016/j.inffus.2025.104084</link><guid>10.1016/j.inffus.2025.104084</guid><pubDate>Sat, 20 Dec 2025 23:22:45 +0000</pubDate><dc:creator>Xingyu Zhao</dc:creator><dc:creator>Jianpeng Qi</dc:creator><dc:creator>Bin Lu</dc:creator><dc:creator>Lei Zhou</dc:creator><dc:creator>Lei Cao</dc:creator><dc:creator>Junyu Dong</dc:creator><dc:creator>Yanwei Yu</dc:creator><prism:publicationName>Information Fusion</prism:publicationName><prism:doi>10.1016/j.inffus.2025.104084</prism:doi><description>Data preparation is crucial for achieving optimal results in deep learning. Unfortunately, missing values are common when preparing large-scale spatiotemporal databases. Most existing imputation methods primarily focus on exploring the spatiotemporal correlations of single-source data; however, high missing rates in single-source data result in sparse distributions. Furthermore, existing methods typically focus on shallow correlations at a single scale, limiting the ability of imputation models to effectively leverage multi-scale spatial features. To tackle these challenges, we propose a multivariate dependency-aware spatiotemporal imputation model, named ST-Imputer. Specifically, we introduce multi-source context data to provide sufficient correlation features for target data ( i.e ., data that needs imputation), alleviating the issue of insufficient available features caused by high missing rates in single-source data. By applying a multi-variate spatiotemporal dependency extraction module, ST-Imputer captures potential associations between different spatial scales. Subsequently, the noise prediction module utilizes the learned dual-view features to formulate the spatiotemporal transmission module, thereby reducing weight errors caused by excessive noise. Finally, physical constraints are applied to prevent unrealistic predictions. Extensive experiments on three large-scale datasets demonstrate the significant superiority of ST-Imputer, achieving up to a 13.07% improvement in RMSE. The code of our model is available at https://github.com/Lion1a/ST-Imputer .
Published: 2025-12-20T23:22:45+00:00
Venue: Information Fusion
Score: 0.413 (consider)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Xingyu Zhao; Jianpeng Qi; Bin Lu; Lei Zhou; Lei Cao; Junyu Dong; Yanwei Yu&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; Information Fusion&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1016/j.inffus.2025.104084"&gt;10.1016/j.inffus.2025.104084&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.413 (consider)&lt;/p&gt;
&lt;p&gt;Data preparation is crucial for achieving optimal results in deep learning. Unfortunately, missing values are common when preparing large-scale spatiotemporal databases. Most existing imputation methods primarily focus on exploring the spatiotemporal correlations of single-source data; however, high missing rates in single-source data result in sparse distributions. Furthermore, existing methods typically focus on shallow correlations at a single scale, limiting the ability of imputation models to effectively leverage multi-scale spatial features. To tackle these challenges, we propose a multivariate dependency-aware spatiotemporal imputation model, named ST-Imputer. Specifically, we introduce multi-source context data to provide sufficient correlation features for target data ( i.e ., data that needs imputation), alleviating the issue of insufficient available features caused by high missing rates in single-source data. By applying a multi-variate spatiotemporal dependency extraction module, ST-Imputer captures potential associations between different spatial scales. Subsequently, the noise prediction module utilizes the learned dual-view features to formulate the spatiotemporal transmission module, thereby reducing weight errors caused by excessive noise. Finally, physical constraints are applied to prevent unrealistic predictions. Extensive experiments on three large-scale datasets demonstrate the significant superiority of ST-Imputer, achieving up to a 13.07% improvement in RMSE. The code of our model is available at https://github.com/Lion1a/ST-Imputer .&lt;/p&gt;</content:encoded></item><item><title>Oracle Bone Image Denoising via CM-UNet with Convolutional Multi-head Attention for Complex Noise Types</title><link>https://doi.org/10.1016/j.patcog.2025.112929</link><guid>10.1016/j.patcog.2025.112929</guid><pubDate>Sat, 20 Dec 2025 07:19:48 +0000</pubDate><dc:creator>Shibin Wang</dc:creator><dc:creator>Yu Wang</dc:creator><dc:creator>Qi Yu</dc:creator><dc:creator>Dong Liu</dc:creator><dc:creator>Xueshan Li</dc:creator><prism:publicationName>Pattern Recognition</prism:publicationName><prism:doi>10.1016/j.patcog.2025.112929</prism:doi><description>Oracle bone inscriptions are a valuable cultural heritage that carries crucial information about ancient civilizations. Due to natural weathering and human activities, existing oracle bone rubbing images often contain complex noise, such as cracks and ink diffusion, which severely hinders automated interpretation and research. Although deep learning has made significant progress in image denoising, the lack of paired data with real noise limits existing methods in effectively modeling the noise characteristics in oracle rubbings, resulting in suboptimal denoising quality and damage to character structures. In this work, we build upon the Oracle-241 dataset and employ the Style Transfer and Separation Network (STSN) to construct a large-scale paired dataset of clean and noisy oracle images containing real noise, providing high-quality supervised signals for training. To address the challenges of the denoising task, we further propose an improved CM-UNet network and design a Convolutional Multi-head Attention Module (CMBlock), which effectively enhances denoising performance under complex noise conditions while preserving the structural integrity of the characters. Experimental results demonstrate that CM-UNet outperforms existing methods in both noise suppression and character structure preservation, achieving superior performance in PSNR, SSIM, and LPIPS. This work introduces a novel, interdisciplinary approach that bridges computer vision and archaeology to denoise oracle bone inscriptions while preserving their structural integrity, offering a new tool for digitization and a transferable paradigm for restoring historical documents. The source code is publicly available at: https://github.com/wang11602/CM-UNet .
Published: 2025-12-20T07:19:48+00:00
Venue: Pattern Recognition
Score: 0.409 (consider)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Shibin Wang; Yu Wang; Qi Yu; Dong Liu; Xueshan Li&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; Pattern Recognition&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1016/j.patcog.2025.112929"&gt;10.1016/j.patcog.2025.112929&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.409 (consider)&lt;/p&gt;
&lt;p&gt;Oracle bone inscriptions are a valuable cultural heritage that carries crucial information about ancient civilizations. Due to natural weathering and human activities, existing oracle bone rubbing images often contain complex noise, such as cracks and ink diffusion, which severely hinders automated interpretation and research. Although deep learning has made significant progress in image denoising, the lack of paired data with real noise limits existing methods in effectively modeling the noise characteristics in oracle rubbings, resulting in suboptimal denoising quality and damage to character structures. In this work, we build upon the Oracle-241 dataset and employ the Style Transfer and Separation Network (STSN) to construct a large-scale paired dataset of clean and noisy oracle images containing real noise, providing high-quality supervised signals for training. To address the challenges of the denoising task, we further propose an improved CM-UNet network and design a Convolutional Multi-head Attention Module (CMBlock), which effectively enhances denoising performance under complex noise conditions while preserving the structural integrity of the characters. Experimental results demonstrate that CM-UNet outperforms existing methods in both noise suppression and character structure preservation, achieving superior performance in PSNR, SSIM, and LPIPS. This work introduces a novel, interdisciplinary approach that bridges computer vision and archaeology to denoise oracle bone inscriptions while preserving their structural integrity, offering a new tool for digitization and a transferable paradigm for restoring historical documents. The source code is publicly available at: https://github.com/wang11602/CM-UNet .&lt;/p&gt;</content:encoded></item><item><title>Shrinkage Matters: Evidence from Accuracy-Diversity Trade-off in Regression Ensembles</title><link>https://doi.org/10.1016/j.inffus.2025.104073</link><guid>10.1016/j.inffus.2025.104073</guid><pubDate>Sat, 20 Dec 2025 00:11:42 +0000</pubDate><dc:creator>Han Feng</dc:creator><dc:creator>Pengyang Song</dc:creator><dc:creator>Yinuo Ren</dc:creator><dc:creator>Hanfeng Zhou</dc:creator><dc:creator>Jue Wang</dc:creator><prism:publicationName>Information Fusion</prism:publicationName><prism:doi>10.1016/j.inffus.2025.104073</prism:doi><description>Regression ensembles, a competitive machine learning technique, have gained popularity in recent years. Popular ensemble schemes have evolved from equal weights (EWs), which utilize simple averages, to optimal weights (OWs), which optimize weights by minimizing mean squared error (MSE). Extensive research has not only validated the robustness of EWs but also introduced the concept of shrinkage, shrinking OWs towards EWs. This paper tackles the ensemble challenge through diversity theory, where ensemble MSE is decomposed into two components: global error and global diversity. Within the decomposition framework, OWs typically minimize global error at the expense of reduced global diversity, while EWs tend to maximize global diversity but often ignore the accuracy. To address the accuracy-diversity trade-off, we derive an optimal shrinkage factor that manages to minimize the ensemble MSE. Simulation results reveal the mediation effect of shrinkage weights, and empirical experiments on six UCI datasets and Brent monthly future prices demonstrate the superiority of the proposed method, whose mechanism is further expounded through an in-depth analysis of the shrinkage components. Overall, our approach provides a novel perspective on the efficacy of shrinkage in regression ensembles.
Published: 2025-12-20T00:11:42+00:00
Venue: Information Fusion
Score: 0.404 (consider)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Han Feng; Pengyang Song; Yinuo Ren; Hanfeng Zhou; Jue Wang&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; Information Fusion&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1016/j.inffus.2025.104073"&gt;10.1016/j.inffus.2025.104073&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.404 (consider)&lt;/p&gt;
&lt;p&gt;Regression ensembles, a competitive machine learning technique, have gained popularity in recent years. Popular ensemble schemes have evolved from equal weights (EWs), which utilize simple averages, to optimal weights (OWs), which optimize weights by minimizing mean squared error (MSE). Extensive research has not only validated the robustness of EWs but also introduced the concept of shrinkage, shrinking OWs towards EWs. This paper tackles the ensemble challenge through diversity theory, where ensemble MSE is decomposed into two components: global error and global diversity. Within the decomposition framework, OWs typically minimize global error at the expense of reduced global diversity, while EWs tend to maximize global diversity but often ignore the accuracy. To address the accuracy-diversity trade-off, we derive an optimal shrinkage factor that manages to minimize the ensemble MSE. Simulation results reveal the mediation effect of shrinkage weights, and empirical experiments on six UCI datasets and Brent monthly future prices demonstrate the superiority of the proposed method, whose mechanism is further expounded through an in-depth analysis of the shrinkage components. Overall, our approach provides a novel perspective on the efficacy of shrinkage in regression ensembles.&lt;/p&gt;</content:encoded></item><item><title>A reliable framework for brain tumor segmentation via multi-modal fusion and uncertainty modeling</title><link>https://doi.org/10.1016/j.inffus.2025.104085</link><guid>10.1016/j.inffus.2025.104085</guid><pubDate>Sat, 20 Dec 2025 16:19:38 +0000</pubDate><dc:creator>Tongxue Zhou</dc:creator><dc:creator>Mingyang Li</dc:creator><dc:creator>Su Ruan</dc:creator><dc:creator>Tingjin Luo</dc:creator><dc:creator>Bingbing Jiang</dc:creator><dc:creator>Junan Zhu</dc:creator><dc:creator>Ping Ma</dc:creator><dc:creator>Defu Yang</dc:creator><dc:creator>Guang Yang</dc:creator><prism:publicationName>Information Fusion</prism:publicationName><prism:doi>10.1016/j.inffus.2025.104085</prism:doi><description>Accurate brain tumor segmentation from MRI scans is critical for effective diagnosis and treatment planning. Recent advances in deep learning have significantly improved brain tumor segmentation performance. However, these models still face challenges in clinical adoption due to their inherent uncertainties and potential for errors. In this paper, we propose a novel MR brain tumor segmentation approach that integrates multi-modal data fusion and uncertainty quantification to improve the accuracy and reliability of brain tumor segmentation. Recognizing that each MR modality contributes unique insights into the tumor’s characteristics, we propose a novel modality-aware guidance by explicitly categorizing the modalities into ”teacher” (FLAIR and T1c) and ”student” (T2 and T1) groups. Since the teacher modalities are the most informative modalities for identifying brain tumors, we propose a multi-modal teacher-student fusion strategy. This strategy leverages the teacher modalities to guide the student modalities in both spatial and channel feature representation aspects. To address prediction reliability, we employ Monte Carlo dropout during training to generate multiple uncertainty estimates. Additionally, we develop a novel uncertainty-aware loss function that optimizes segmentation accuracy while quantifying the uncertainty in predictions. Experimental results conducted on three BraTS datasets demonstrate the effectiveness of the proposed components and the superior performance compared to the state-of-the-art methods, highlighting their potential for clinical application.
Published: 2025-12-20T16:19:38+00:00
Venue: Information Fusion
Score: 0.399 (ignore)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Tongxue Zhou; Mingyang Li; Su Ruan; Tingjin Luo; Bingbing Jiang; Junan Zhu; Ping Ma; Defu Yang; Guang Yang&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; Information Fusion&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1016/j.inffus.2025.104085"&gt;10.1016/j.inffus.2025.104085&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.399 (ignore)&lt;/p&gt;
&lt;p&gt;Accurate brain tumor segmentation from MRI scans is critical for effective diagnosis and treatment planning. Recent advances in deep learning have significantly improved brain tumor segmentation performance. However, these models still face challenges in clinical adoption due to their inherent uncertainties and potential for errors. In this paper, we propose a novel MR brain tumor segmentation approach that integrates multi-modal data fusion and uncertainty quantification to improve the accuracy and reliability of brain tumor segmentation. Recognizing that each MR modality contributes unique insights into the tumor’s characteristics, we propose a novel modality-aware guidance by explicitly categorizing the modalities into ”teacher” (FLAIR and T1c) and ”student” (T2 and T1) groups. Since the teacher modalities are the most informative modalities for identifying brain tumors, we propose a multi-modal teacher-student fusion strategy. This strategy leverages the teacher modalities to guide the student modalities in both spatial and channel feature representation aspects. To address prediction reliability, we employ Monte Carlo dropout during training to generate multiple uncertainty estimates. Additionally, we develop a novel uncertainty-aware loss function that optimizes segmentation accuracy while quantifying the uncertainty in predictions. Experimental results conducted on three BraTS datasets demonstrate the effectiveness of the proposed components and the superior performance compared to the state-of-the-art methods, highlighting their potential for clinical application.&lt;/p&gt;</content:encoded></item><item><title>Predicting the time of supply interruption due to the repair of failed water pipes</title><link>https://doi.org/10.1016/j.eswa.2025.130930</link><guid>10.1016/j.eswa.2025.130930</guid><pubDate>Sat, 20 Dec 2025 00:08:48 +0000</pubDate><dc:creator>Jiduo Xing</dc:creator><dc:creator>Tarek Zayed</dc:creator><dc:creator>Shihui Ma</dc:creator><dc:creator>Yuyang Shao</dc:creator><prism:publicationName>Expert Systems with Applications</prism:publicationName><prism:doi>10.1016/j.eswa.2025.130930</prism:doi><description>Water supply interruptions due to the repair works on pipe failure incidents pose challenges to operational efficiency, customer satisfaction and resource management. Therefore, predicting the time of supply interruption (TSI) is crucial for utility’s decision makers in preparing repair works and resource allocation strategies. This paper aims to explore the application of intelligent data-driven approaches in TSI prediction when facing water supply suspension due to the repair works on failed pipes. Multiple sources of data, including pipe-, environment-, and operation-related factors, are collected; machine learning (ML) and deep learning (DL) algorithms are selected to train the models; and SHapley additive exPlanations (SHAP) is employed to interpret the developed models clarifying the factor contributions. The results illustrate that in FW, convolutional neural network (CNN) achieves the best performance with an accuracy of 83.99%; while in SW, artificial neural network (ANN) demonstrates the best performance, boosting an accuracy of 75.76%. Notably, ‘Size’ and ‘Material’ are two most impactful factors contributing to TSI prediction, while ‘Failure type’ has the least impact. A real pilot study of HKWDN is applied, and 72% of the water pipe failure incidents could have accurate predictions of TSI. This study could serve as a proactive tool for predictively assessing the duration of water supply interruption, which enables more efficient resource allocations and prioritization of repair works, thereby minimizing the inconvenience caused to the public and accomplishing a reliable decision-making in WDN management.
Published: 2025-12-20T00:08:48+00:00
Venue: Expert Systems with Applications
Score: 0.392 (ignore)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Jiduo Xing; Tarek Zayed; Shihui Ma; Yuyang Shao&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; Expert Systems with Applications&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1016/j.eswa.2025.130930"&gt;10.1016/j.eswa.2025.130930&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.392 (ignore)&lt;/p&gt;
&lt;p&gt;Water supply interruptions due to the repair works on pipe failure incidents pose challenges to operational efficiency, customer satisfaction and resource management. Therefore, predicting the time of supply interruption (TSI) is crucial for utility’s decision makers in preparing repair works and resource allocation strategies. This paper aims to explore the application of intelligent data-driven approaches in TSI prediction when facing water supply suspension due to the repair works on failed pipes. Multiple sources of data, including pipe-, environment-, and operation-related factors, are collected; machine learning (ML) and deep learning (DL) algorithms are selected to train the models; and SHapley additive exPlanations (SHAP) is employed to interpret the developed models clarifying the factor contributions. The results illustrate that in FW, convolutional neural network (CNN) achieves the best performance with an accuracy of 83.99%; while in SW, artificial neural network (ANN) demonstrates the best performance, boosting an accuracy of 75.76%. Notably, ‘Size’ and ‘Material’ are two most impactful factors contributing to TSI prediction, while ‘Failure type’ has the least impact. A real pilot study of HKWDN is applied, and 72% of the water pipe failure incidents could have accurate predictions of TSI. This study could serve as a proactive tool for predictively assessing the duration of water supply interruption, which enables more efficient resource allocations and prioritization of repair works, thereby minimizing the inconvenience caused to the public and accomplishing a reliable decision-making in WDN management.&lt;/p&gt;</content:encoded></item><item><title>ChatAssistDesign: A Language-Interactive Framework for Iterative Vector Floorplan Generation via Conditional Diffusion</title><link>https://doi.org/10.1016/j.inffus.2025.104091</link><guid>10.1016/j.inffus.2025.104091</guid><pubDate>Sat, 20 Dec 2025 23:23:06 +0000</pubDate><dc:creator>Luping Li</dc:creator><dc:creator>Xing Su</dc:creator><dc:creator>Han Lin</dc:creator><dc:creator>Haoying Han</dc:creator><dc:creator>Chao Fan</dc:creator><dc:creator>Zhao Zhang</dc:creator><dc:creator>Hongzhe Yue</dc:creator><prism:publicationName>Information Fusion</prism:publicationName><prism:doi>10.1016/j.inffus.2025.104091</prism:doi><description>Architectural design, a complex optimization process requiring iterative revisions by skilled architects, increasingly leverages computational tools. While deep generative models show promise in automating floorplan generation, two key limitations persist: (1) reliance on domain expertise, creating high technical barriers for non-experts, and (2) lack of iterative refinement capabilities, limiting post-generation adjustments. To address these challenges, we propose ChatAssistDesign, an interactive text-driven framework combining (1) Floorplan Designer, a large language model (LLM) agent guiding users through design workflows, and (2) ConDiffPlan, a vector-based conditional diffusion model for layout generation. Extensive experimental results demonstrate that our framework achieves significant improvements over state-of-the-art methods in terms of layout diversity, visual realism, text-to-layout alignment accuracy, and crucially, the ability to support iterative refinement while maintaining high robustness against constraint conflicts. By abstracting design complexity from user skill and enabling dynamic post hoc edits, our approach reduces entry barriers and improves integration with downstream tasks.
Published: 2025-12-20T23:23:06+00:00
Venue: Information Fusion
Score: 0.389 (ignore)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Luping Li; Xing Su; Han Lin; Haoying Han; Chao Fan; Zhao Zhang; Hongzhe Yue&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; Information Fusion&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1016/j.inffus.2025.104091"&gt;10.1016/j.inffus.2025.104091&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.389 (ignore)&lt;/p&gt;
&lt;p&gt;Architectural design, a complex optimization process requiring iterative revisions by skilled architects, increasingly leverages computational tools. While deep generative models show promise in automating floorplan generation, two key limitations persist: (1) reliance on domain expertise, creating high technical barriers for non-experts, and (2) lack of iterative refinement capabilities, limiting post-generation adjustments. To address these challenges, we propose ChatAssistDesign, an interactive text-driven framework combining (1) Floorplan Designer, a large language model (LLM) agent guiding users through design workflows, and (2) ConDiffPlan, a vector-based conditional diffusion model for layout generation. Extensive experimental results demonstrate that our framework achieves significant improvements over state-of-the-art methods in terms of layout diversity, visual realism, text-to-layout alignment accuracy, and crucially, the ability to support iterative refinement while maintaining high robustness against constraint conflicts. By abstracting design complexity from user skill and enabling dynamic post hoc edits, our approach reduces entry barriers and improves integration with downstream tasks.&lt;/p&gt;</content:encoded></item><item><title>Two-stream attentive spatial-temporal graph convolutional network for P300 detection in brain-computer interface</title><link>https://doi.org/10.1016/j.eswa.2025.130874</link><guid>10.1016/j.eswa.2025.130874</guid><pubDate>Sat, 20 Dec 2025 00:08:51 +0000</pubDate><dc:creator>Jincen Wang</dc:creator><dc:creator>Yan Zhao</dc:creator><dc:creator>Cunhang Fan</dc:creator><dc:creator>Yong Li</dc:creator><dc:creator>Fan Liu</dc:creator><dc:creator>Hailun Lian</dc:creator><dc:creator>Cheng Lu</dc:creator><prism:publicationName>Expert Systems with Applications</prism:publicationName><prism:doi>10.1016/j.eswa.2025.130874</prism:doi><description>P300 potential detection is a critical technology in the field of brain-computer interfaces (BCIs), with significant implications for rehabilitation and neuroscience research. Due to the distinctive spatiotemporal characteristics of P300 potentials, accurately extracting and modeling spatiotemporal features is essential for effective P300 detection. However, existing multi-channel electroencephalogram (EEG) signals-based P300 detection methods face two major challenges in capturing discriminative spatiotemporal features: (1) the inability to effectively model the non-Euclidean connectivity relationships among EEG electrode channels, and (2) the failure to simultaneously focus on P300-relevant critical electrode channels and time slices. To address these issues, we propose a novel Two-Stream Attentive Spatial-Temporal Graph Convolutional Network (TASTGCN) for P300 detection. Specifically, we design a two-stream spatial-temporal graph convolution module (TSTGCM): the spatial GCN stream utilizes an adjacency matrix adaptively learned from electrode features to flexibly capture dynamic brain connectivity patterns, while the temporal GCN stream extracts temporal dependencies in parallel. Furthermore, a spatiotemporal attention refinement module (STARM) adaptively weighs different electrodes and time points to perceive the most salient P300-related information. Finally, an attentive feature fusion module (AFFM) based on a cross-attention mechanism is employed to integrate the refined features and generate the final discriminative representations. Extensive experiments on public datasets demonstrate that TASTGCN significantly outperforms state-of-the-art methods, validating its ability to capture the discriminative spatiotemporal features of P300 potentials.
Published: 2025-12-20T00:08:51+00:00
Venue: Expert Systems with Applications
Score: 0.388 (ignore)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Jincen Wang; Yan Zhao; Cunhang Fan; Yong Li; Fan Liu; Hailun Lian; Cheng Lu&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; Expert Systems with Applications&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1016/j.eswa.2025.130874"&gt;10.1016/j.eswa.2025.130874&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.388 (ignore)&lt;/p&gt;
&lt;p&gt;P300 potential detection is a critical technology in the field of brain-computer interfaces (BCIs), with significant implications for rehabilitation and neuroscience research. Due to the distinctive spatiotemporal characteristics of P300 potentials, accurately extracting and modeling spatiotemporal features is essential for effective P300 detection. However, existing multi-channel electroencephalogram (EEG) signals-based P300 detection methods face two major challenges in capturing discriminative spatiotemporal features: (1) the inability to effectively model the non-Euclidean connectivity relationships among EEG electrode channels, and (2) the failure to simultaneously focus on P300-relevant critical electrode channels and time slices. To address these issues, we propose a novel Two-Stream Attentive Spatial-Temporal Graph Convolutional Network (TASTGCN) for P300 detection. Specifically, we design a two-stream spatial-temporal graph convolution module (TSTGCM): the spatial GCN stream utilizes an adjacency matrix adaptively learned from electrode features to flexibly capture dynamic brain connectivity patterns, while the temporal GCN stream extracts temporal dependencies in parallel. Furthermore, a spatiotemporal attention refinement module (STARM) adaptively weighs different electrodes and time points to perceive the most salient P300-related information. Finally, an attentive feature fusion module (AFFM) based on a cross-attention mechanism is employed to integrate the refined features and generate the final discriminative representations. Extensive experiments on public datasets demonstrate that TASTGCN significantly outperforms state-of-the-art methods, validating its ability to capture the discriminative spatiotemporal features of P300 potentials.&lt;/p&gt;</content:encoded></item><item><title>MSDiff: Dynamic dual-attention driven multi-stage diffusion for low-dose CT image denoising</title><link>https://doi.org/10.1016/j.neucom.2025.132456</link><guid>10.1016/j.neucom.2025.132456</guid><pubDate>Sat, 20 Dec 2025 00:08:10 +0000</pubDate><dc:creator>Lulu Wang</dc:creator><dc:creator>Lang Gu</dc:creator><dc:creator>Zhengtao Yu</dc:creator><dc:creator>Jinglong Du</dc:creator><dc:creator>Yingna Li</dc:creator><prism:publicationName>Neurocomputing</prism:publicationName><prism:doi>10.1016/j.neucom.2025.132456</prism:doi><description>Low-dose CT imaging faces challenges in balancing radiation reduction with diagnostic accuracy due to inherent noise and artifacts. While current denoising methods, including deep learning and DDPMs, have improved performance, they still show limitations in effectiveness, structural preservation, and computational efficiency. Additionally, CT slice diversity across equipment, protocols, and patients poses a key challenge: adapting pre-trained models to new dose levels with limited resources. In this paper, we propose a novel Multi-stage Degradation-Restoration Diffusion framework (MSDiff). First, a three-stage optimization mechanism (coarse-to-consistency refinement) progressively suppresses error accumulation through sequential degradation-restoration cycles. Second, a Dynamic Dual-Attention Network (DDA-Net) integrates channel-spatial attention mechanisms, enabling rapid adaptation to unknown dose levels using only an LDCT image and an unpaired normal-dose CT (NDCT) image while preserving anatomical integrity. Finally, a state space model based 2D-Selective-Scan (SS2D) module is designed for perceptual loss feature extraction, enhancing semantic characterization of LDCT images and improving high frequency detail retention. Experimental results on “Low Dose CT Image and Projection Data” demonstrate that the MSDiff achieves a PSNR of 45.21 dB, outperforming competing algorithms.
Published: 2025-12-20T00:08:10+00:00
Venue: Neurocomputing
Score: 0.386 (ignore)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Lulu Wang; Lang Gu; Zhengtao Yu; Jinglong Du; Yingna Li&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; Neurocomputing&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1016/j.neucom.2025.132456"&gt;10.1016/j.neucom.2025.132456&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.386 (ignore)&lt;/p&gt;
&lt;p&gt;Low-dose CT imaging faces challenges in balancing radiation reduction with diagnostic accuracy due to inherent noise and artifacts. While current denoising methods, including deep learning and DDPMs, have improved performance, they still show limitations in effectiveness, structural preservation, and computational efficiency. Additionally, CT slice diversity across equipment, protocols, and patients poses a key challenge: adapting pre-trained models to new dose levels with limited resources. In this paper, we propose a novel Multi-stage Degradation-Restoration Diffusion framework (MSDiff). First, a three-stage optimization mechanism (coarse-to-consistency refinement) progressively suppresses error accumulation through sequential degradation-restoration cycles. Second, a Dynamic Dual-Attention Network (DDA-Net) integrates channel-spatial attention mechanisms, enabling rapid adaptation to unknown dose levels using only an LDCT image and an unpaired normal-dose CT (NDCT) image while preserving anatomical integrity. Finally, a state space model based 2D-Selective-Scan (SS2D) module is designed for perceptual loss feature extraction, enhancing semantic characterization of LDCT images and improving high frequency detail retention. Experimental results on “Low Dose CT Image and Projection Data” demonstrate that the MSDiff achieves a PSNR of 45.21 dB, outperforming competing algorithms.&lt;/p&gt;</content:encoded></item><item><title>Adaptive neural network fault-tolerant control of tendon actuated continuum robots under actuator failures and external disturbances</title><link>https://doi.org/10.1016/j.robot.2025.105310</link><guid>10.1016/j.robot.2025.105310</guid><pubDate>Sat, 20 Dec 2025 00:07:59 +0000</pubDate><dc:creator>Hongyun Liu</dc:creator><dc:creator>Weidong Liu</dc:creator><dc:creator>Jinbo Zhong</dc:creator><prism:publicationName>Robotics and Autonomous Systems</prism:publicationName><prism:doi>10.1016/j.robot.2025.105310</prism:doi><description>This paper proposes an adaptive neural network backstepping sliding mode fault-tolerant control (ANN-BSMFTC) strategy to enhance the control robustness of tendon-actuated continuum robots (TACR) under actuator failures and sudden external disturbances. Initially, a precise dynamic model of TACR is established based on Cosserat rod theory. Subsequently, a backstepping control framework is employed to derive the system’s virtual control quantities, with sliding mode control (SMC) embedded to strengthen robustness against parameter perturbations and external disturbances. Furthermore, a radial basis function neural network (RBFNN) is incorporated to online approximate unknown components in the control law through its global approximation capability. The asymptotic convergence of the closed-loop system is rigorously proven under concurrent partial actuator failure and external step disturbance conditions using Lyapunov stability theory. Comparative simulation experiments with sliding mode fault-tolerant control (SMFTC), backstepping fault-tolerant control (BFTC), and backstepping sliding mode fault-tolerant control (BSMFTC) validate the effectiveness. Results demonstrate that the proposed ANN-BSMFTC strategy achieves optimal spatial trajectory tracking performance, maintaining the average normalized root mean square error (NRMSE) of position tracking below 5% under extreme conditions involving actuator faults and sudden disturbances.
Published: 2025-12-20T00:07:59+00:00
Venue: Robotics and Autonomous Systems
Score: 0.386 (ignore)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Hongyun Liu; Weidong Liu; Jinbo Zhong&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; Robotics and Autonomous Systems&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1016/j.robot.2025.105310"&gt;10.1016/j.robot.2025.105310&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.386 (ignore)&lt;/p&gt;
&lt;p&gt;This paper proposes an adaptive neural network backstepping sliding mode fault-tolerant control (ANN-BSMFTC) strategy to enhance the control robustness of tendon-actuated continuum robots (TACR) under actuator failures and sudden external disturbances. Initially, a precise dynamic model of TACR is established based on Cosserat rod theory. Subsequently, a backstepping control framework is employed to derive the system’s virtual control quantities, with sliding mode control (SMC) embedded to strengthen robustness against parameter perturbations and external disturbances. Furthermore, a radial basis function neural network (RBFNN) is incorporated to online approximate unknown components in the control law through its global approximation capability. The asymptotic convergence of the closed-loop system is rigorously proven under concurrent partial actuator failure and external step disturbance conditions using Lyapunov stability theory. Comparative simulation experiments with sliding mode fault-tolerant control (SMFTC), backstepping fault-tolerant control (BFTC), and backstepping sliding mode fault-tolerant control (BSMFTC) validate the effectiveness. Results demonstrate that the proposed ANN-BSMFTC strategy achieves optimal spatial trajectory tracking performance, maintaining the average normalized root mean square error (NRMSE) of position tracking below 5% under extreme conditions involving actuator faults and sudden disturbances.&lt;/p&gt;</content:encoded></item><item><title>RWKV-SKF: A recurrent architecture with state-space and frequency-domain filtering for dissolved oxygen predicting and revealing influencing mechanisms</title><link>https://doi.org/10.1016/j.ins.2025.123018</link><guid>10.1016/j.ins.2025.123018</guid><pubDate>Sat, 20 Dec 2025 16:08:54 +0000</pubDate><dc:creator>Peijian Zeng</dc:creator><dc:creator>Xingming Liao</dc:creator><dc:creator>Jianhui Xu</dc:creator><dc:creator>Shuisen Chen</dc:creator><dc:creator>Zhuowei Wang</dc:creator><dc:creator>Aimin Yang</dc:creator><dc:creator>Xingda Chen</dc:creator><prism:publicationName>Information Sciences</prism:publicationName><prism:doi>10.1016/j.ins.2025.123018</prism:doi><description>Dissolved oxygen (DO) is a critical parameter for maintaining the ecological integrity of estuarine ecosystems. However, accurate DO prediction is hindered by measurement noise and complex periodic dynamics driven by tidal and seasonal cycles. To address these challenges, this study proposes a novel Recurrent Weighted Key-Value with State-Space Kalman and Fourier Filtering (RWKV-SKF) framework for enhanced DO forecasting. The RWKV-SKF integrates four specialized components: the Kalman Filtering Module (KFM) mitigates sensor noise; the Fourier Derivative Module (FDM) extracts dominant periodic features through spectral analysis; the Time Mix Module (TMM) captures short-term temporal dependencies; and the Channel Mix Module (CMM) models inter-variable interactions. By extending the RWKV architecture, the framework synergistically combines denoising, periodicity identification, and sequential learning. Experimental evaluations on both 4-hourly and daily DO monitoring datasets demonstrate that RWKV-SKF achieves state-of-the-art performance, reducing prediction errors by 0.97 % and 7.63 %, respectively, compared to the second-best model and attaining the lowest MSE of 0.5285 and 0.5499 among 19 baselines. These results highlight RWKV-SKF’s superior ability to handle noisy, cyclic DO dynamics, offering a robust solution for early warning and management of estuarine hypoxia.
Published: 2025-12-20T16:08:54+00:00
Venue: Information Sciences
Score: 0.385 (ignore)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Peijian Zeng; Xingming Liao; Jianhui Xu; Shuisen Chen; Zhuowei Wang; Aimin Yang; Xingda Chen&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; Information Sciences&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1016/j.ins.2025.123018"&gt;10.1016/j.ins.2025.123018&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.385 (ignore)&lt;/p&gt;
&lt;p&gt;Dissolved oxygen (DO) is a critical parameter for maintaining the ecological integrity of estuarine ecosystems. However, accurate DO prediction is hindered by measurement noise and complex periodic dynamics driven by tidal and seasonal cycles. To address these challenges, this study proposes a novel Recurrent Weighted Key-Value with State-Space Kalman and Fourier Filtering (RWKV-SKF) framework for enhanced DO forecasting. The RWKV-SKF integrates four specialized components: the Kalman Filtering Module (KFM) mitigates sensor noise; the Fourier Derivative Module (FDM) extracts dominant periodic features through spectral analysis; the Time Mix Module (TMM) captures short-term temporal dependencies; and the Channel Mix Module (CMM) models inter-variable interactions. By extending the RWKV architecture, the framework synergistically combines denoising, periodicity identification, and sequential learning. Experimental evaluations on both 4-hourly and daily DO monitoring datasets demonstrate that RWKV-SKF achieves state-of-the-art performance, reducing prediction errors by 0.97 % and 7.63 %, respectively, compared to the second-best model and attaining the lowest MSE of 0.5285 and 0.5499 among 19 baselines. These results highlight RWKV-SKF’s superior ability to handle noisy, cyclic DO dynamics, offering a robust solution for early warning and management of estuarine hypoxia.&lt;/p&gt;</content:encoded></item><item><title>An Adaptive Decision Mechanism for WSNs: Integrating Deep Reinforcement Learning Routing with CNN-BiLSTM Compression Guided by Enhanced Slime Mold Algorithm</title><link>https://doi.org/10.1016/j.eswa.2025.130915</link><guid>10.1016/j.eswa.2025.130915</guid><pubDate>Sat, 20 Dec 2025 16:16:38 +0000</pubDate><dc:creator>Liubao Zhang</dc:creator><dc:creator>Cuiran Li</dc:creator><dc:creator>Jun Yang</dc:creator><dc:creator>Hao Wu</dc:creator><dc:creator>Jianli Xie</dc:creator><prism:publicationName>Expert Systems with Applications</prism:publicationName><prism:doi>10.1016/j.eswa.2025.130915</prism:doi><description>Wireless sensor networks (WSNs) are a crucial part of the Internet of Things (IoT), and research on WSN clustering routing protocols has consistently been a focal point in academia. However, traditional clustering routing protocols do not fully utilize available network information during path decision-making. This limitation results in poor adaptability to topology changes, high energy consumption, and short network lifetime. To address these issues, this paper proposes an intelligent data collection scheme based on the improved slime mold algorithm (ISMA) and deep reinforcement learning. Firstly, during the cluster head (CH) selection stage, the algorithm comprehensively considers factors such as iteration rounds, function convergence status, and population diversity. It incorporates strategies including the levy flight, opposition-based learning, gaussian perturbation, and differential perturbation to effectively balance global exploration and local exploitation capabilities, thereby avoiding getting stuck in local optima. Meanwhile, the precision and effectiveness of CH selection are greatly improved by adding parameters like node residual energy and inter-node distance, enabling the sensible distribution of network energy. Secondly, the use of a double deep Q-network (DDQN) that incorporates expert experience, multistep temporal difference, and regularization module during the routing decision-making stage greatly improved sample utilization and accelerated training convergence. Finally, during the data collection stage of WSN compression, this paper proposes a CNN-BiLSTM compressed signal reconstruction model. Through comparisons using soil temperature measurements from the Pengbo irrigation district in Tibet and the freeze-thaw landslide data from the Keke Xili confirmed the suggested model’s efficacy in high-precision signal reconstruction. Additionally, the simulation combined with ISMA-IDDQN algorithm shows that the proposed scheme can efficiently balance node energy consumption, providing notable benefits in terms of increasing data throughput and network lifetime.
Published: 2025-12-20T16:16:38+00:00
Venue: Expert Systems with Applications
Score: 0.384 (ignore)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Liubao Zhang; Cuiran Li; Jun Yang; Hao Wu; Jianli Xie&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; Expert Systems with Applications&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1016/j.eswa.2025.130915"&gt;10.1016/j.eswa.2025.130915&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.384 (ignore)&lt;/p&gt;
&lt;p&gt;Wireless sensor networks (WSNs) are a crucial part of the Internet of Things (IoT), and research on WSN clustering routing protocols has consistently been a focal point in academia. However, traditional clustering routing protocols do not fully utilize available network information during path decision-making. This limitation results in poor adaptability to topology changes, high energy consumption, and short network lifetime. To address these issues, this paper proposes an intelligent data collection scheme based on the improved slime mold algorithm (ISMA) and deep reinforcement learning. Firstly, during the cluster head (CH) selection stage, the algorithm comprehensively considers factors such as iteration rounds, function convergence status, and population diversity. It incorporates strategies including the levy flight, opposition-based learning, gaussian perturbation, and differential perturbation to effectively balance global exploration and local exploitation capabilities, thereby avoiding getting stuck in local optima. Meanwhile, the precision and effectiveness of CH selection are greatly improved by adding parameters like node residual energy and inter-node distance, enabling the sensible distribution of network energy. Secondly, the use of a double deep Q-network (DDQN) that incorporates expert experience, multistep temporal difference, and regularization module during the routing decision-making stage greatly improved sample utilization and accelerated training convergence. Finally, during the data collection stage of WSN compression, this paper proposes a CNN-BiLSTM compressed signal reconstruction model. Through comparisons using soil temperature measurements from the Pengbo irrigation district in Tibet and the freeze-thaw landslide data from the Keke Xili confirmed the suggested model’s efficacy in high-precision signal reconstruction. Additionally, the simulation combined with ISMA-IDDQN algorithm shows that the proposed scheme can efficiently balance node energy consumption, providing notable benefits in terms of increasing data throughput and network lifetime.&lt;/p&gt;</content:encoded></item><item><title>MMP-YOLO: A multi-branch defect detection model based on rich gradient information</title><link>https://doi.org/10.1016/j.neucom.2025.132454</link><guid>10.1016/j.neucom.2025.132454</guid><pubDate>Sat, 20 Dec 2025 07:23:19 +0000</pubDate><dc:creator>Zhenyu Wang</dc:creator><dc:creator>Weisheng Li</dc:creator><dc:creator>Shaoze Wang</dc:creator><dc:creator>Shiqiang Liu</dc:creator><prism:publicationName>Neurocomputing</prism:publicationName><prism:doi>10.1016/j.neucom.2025.132454</prism:doi><description>In the manufacturing process, the diversity of products and the complexity of the production environment pose severe challenges to the detection of small defects, which can lead to serious missed detections and false positives. To address these issues, this paper proposes a multi-branch defect detection model based on rich gradient information (MMP-YOLO), which significantly improves the performance of detecting defective objects. Specifically, we design three innovative modules integrated into MMP-YOLO. (1) The Multi-Level Gradient Lightweight Deep Network (MGLD) module processes multi-gradient information through a deep network integrated with large kernel convolution, ensuring accurate transmission of original input information and efficient feature extraction of small objects. (2) The Multi-Scale Function Complementary Upsampling (MFCU) module exploits the complementarity between high-resolution and low-resolution features and introduces transposed convolution and dilated convolution to reduce information loss further. (3) The Parallel Task-Related Feature Selection (PTFS) module selectively suppresses background interference through a combination of global and local information. Extensive experiments on multiple datasets demonstrate that MMP-YOLO outperforms other state-of-the-art methods in reducing information loss and minimizing background noise interference.
Published: 2025-12-20T07:23:19+00:00
Venue: Neurocomputing
Score: 0.383 (ignore)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Zhenyu Wang; Weisheng Li; Shaoze Wang; Shiqiang Liu&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; Neurocomputing&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1016/j.neucom.2025.132454"&gt;10.1016/j.neucom.2025.132454&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.383 (ignore)&lt;/p&gt;
&lt;p&gt;In the manufacturing process, the diversity of products and the complexity of the production environment pose severe challenges to the detection of small defects, which can lead to serious missed detections and false positives. To address these issues, this paper proposes a multi-branch defect detection model based on rich gradient information (MMP-YOLO), which significantly improves the performance of detecting defective objects. Specifically, we design three innovative modules integrated into MMP-YOLO. (1) The Multi-Level Gradient Lightweight Deep Network (MGLD) module processes multi-gradient information through a deep network integrated with large kernel convolution, ensuring accurate transmission of original input information and efficient feature extraction of small objects. (2) The Multi-Scale Function Complementary Upsampling (MFCU) module exploits the complementarity between high-resolution and low-resolution features and introduces transposed convolution and dilated convolution to reduce information loss further. (3) The Parallel Task-Related Feature Selection (PTFS) module selectively suppresses background interference through a combination of global and local information. Extensive experiments on multiple datasets demonstrate that MMP-YOLO outperforms other state-of-the-art methods in reducing information loss and minimizing background noise interference.&lt;/p&gt;</content:encoded></item><item><title>CCDM:Causality-Guided Contourlet Diffusion Models for Contour-Preserving Image Restoration in Indoor Work Sites</title><link>https://doi.org/10.1016/j.eswa.2025.130912</link><guid>10.1016/j.eswa.2025.130912</guid><pubDate>Sun, 21 Dec 2025 15:36:46 +0000</pubDate><dc:creator>Meng Wang</dc:creator><dc:creator>Mei Li</dc:creator><dc:creator>Chao He</dc:creator><prism:publicationName>Expert Systems with Applications</prism:publicationName><prism:doi>10.1016/j.eswa.2025.130912</prism:doi><description>Image restoration in indoor work sites is a challenging task. The main difficulties lie in extracting reliable contour information under poor lighting conditions and handling complex degradations,and addressing the lack of interpretability in existing models. Conventional methods often oversmooth edges and contours when suppressing noise, and their decision processes remain opaque. To address these problems, this paper proposes a Causality-Guided Contourlet Diffusion Model (CCDM). The framework integrates a non-subsampled contourlet transform (NSCT) and a causal inference module (CIM) into the diffusion process. The NSCT provides multi-scale and multi-directional structural priors, enabling robust contour extraction even under weak illumination. The CIM enhances interpretability by explicitly distinguishing causal features from spurious degradation-related features, thereby improving the reliability of feature utilization. The collaborative design strengthens contour fidelity, suppresses irrelevant noise, and enhances cross-scene generalization. Experiments on both a self-constructed dataset of indoor work sites and public image-restoration benchmarks show that CCDM achieves a PSNR of 35.96, an SSIM of 0.9554, and an LPIPS of 0.0791. These results verify the effectiveness of the proposed method. The dataset is available at https://github.com/DaErwen1/WICRD/tree/main .
Published: 2025-12-21T15:36:46+00:00
Venue: Expert Systems with Applications
Score: 0.382 (ignore)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Meng Wang; Mei Li; Chao He&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; Expert Systems with Applications&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1016/j.eswa.2025.130912"&gt;10.1016/j.eswa.2025.130912&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.382 (ignore)&lt;/p&gt;
&lt;p&gt;Image restoration in indoor work sites is a challenging task. The main difficulties lie in extracting reliable contour information under poor lighting conditions and handling complex degradations,and addressing the lack of interpretability in existing models. Conventional methods often oversmooth edges and contours when suppressing noise, and their decision processes remain opaque. To address these problems, this paper proposes a Causality-Guided Contourlet Diffusion Model (CCDM). The framework integrates a non-subsampled contourlet transform (NSCT) and a causal inference module (CIM) into the diffusion process. The NSCT provides multi-scale and multi-directional structural priors, enabling robust contour extraction even under weak illumination. The CIM enhances interpretability by explicitly distinguishing causal features from spurious degradation-related features, thereby improving the reliability of feature utilization. The collaborative design strengthens contour fidelity, suppresses irrelevant noise, and enhances cross-scene generalization. Experiments on both a self-constructed dataset of indoor work sites and public image-restoration benchmarks show that CCDM achieves a PSNR of 35.96, an SSIM of 0.9554, and an LPIPS of 0.0791. These results verify the effectiveness of the proposed method. The dataset is available at https://github.com/DaErwen1/WICRD/tree/main .&lt;/p&gt;</content:encoded></item><item><title>A multi-task deep learning framework for enhancing cloud-top height retrieval accuracy</title><link>https://doi.org/10.1080/17538947.2025.2605411</link><guid>10.1080/17538947.2025.2605411</guid><pubDate>Sat, 20 Dec 2025 10:59:25 +0000</pubDate><dc:creator>Aimin Liu</dc:creator><dc:creator>Fu Wang</dc:creator><dc:creator>Qifeng Lu</dc:creator><dc:creator>Xiaofei Yang</dc:creator><dc:creator>Weijia Cao</dc:creator><dc:creator>Chi Yang</dc:creator><dc:creator>Xiaofang Liu</dc:creator><dc:creator>Yong Cao</dc:creator><prism:publicationName>International Journal of Digital Earth</prism:publicationName><prism:doi>10.1080/17538947.2025.2605411</prism:doi><description>Cloud-top height (CTH) is a fundamental parameter that influences the radiative effects of clouds and plays a critical role in improving the prediction accuracy of numerical weather prediction models. This study introduces a deep learning framework, namely MultiTask-CNN, for the simultaneous retrieval of CTH, cloud phase and multilayer information based on satellite remote sensing data. The datasets used in this study span from January to June 2018. Leveraging multi-source data from observation of the Advanced Geostationary Radiation Imager(AGRI) onboard FY-4A, ERA5 reanalysis, and the combined lidar-radar cloud profiles (joint product of CALIOP and CPR), the model learned complex interdependencies among cloud properties to enhance the retrieval accuracy of CTH. Compared with traditional models (CNN, XGBoost and TwoStage-CNN), the Multi-Task-CNN improved accuracy. Specifically, the RMSE decreased from 2.08 km (CNN), 1.88 km (TwoStage-CNN) and 1.75 km (XGBoost) to 1.70 km, MAE was reduced to 0.79 km, and R 2 slightly increased to 0.90. This improvement was particularly pronounced for multi-layer and high-level clouds. Ablation studies further highlight the benefits of incorporating cloud phase and multilayer information in enhancing model robustness. This study underscores the potential of multi-task learning in cloud property retrieval, offering valuable insights for improving climate and weather prediction.
Published: 2025-12-20T10:59:25+00:00
Venue: International Journal of Digital Earth
Score: 0.380 (ignore)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Aimin Liu; Fu Wang; Qifeng Lu; Xiaofei Yang; Weijia Cao; Chi Yang; Xiaofang Liu; Yong Cao&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; International Journal of Digital Earth&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1080/17538947.2025.2605411"&gt;10.1080/17538947.2025.2605411&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.380 (ignore)&lt;/p&gt;
&lt;p&gt;Cloud-top height (CTH) is a fundamental parameter that influences the radiative effects of clouds and plays a critical role in improving the prediction accuracy of numerical weather prediction models. This study introduces a deep learning framework, namely MultiTask-CNN, for the simultaneous retrieval of CTH, cloud phase and multilayer information based on satellite remote sensing data. The datasets used in this study span from January to June 2018. Leveraging multi-source data from observation of the Advanced Geostationary Radiation Imager(AGRI) onboard FY-4A, ERA5 reanalysis, and the combined lidar-radar cloud profiles (joint product of CALIOP and CPR), the model learned complex interdependencies among cloud properties to enhance the retrieval accuracy of CTH. Compared with traditional models (CNN, XGBoost and TwoStage-CNN), the Multi-Task-CNN improved accuracy. Specifically, the RMSE decreased from 2.08 km (CNN), 1.88 km (TwoStage-CNN) and 1.75 km (XGBoost) to 1.70 km, MAE was reduced to 0.79 km, and R 2 slightly increased to 0.90. This improvement was particularly pronounced for multi-layer and high-level clouds. Ablation studies further highlight the benefits of incorporating cloud phase and multilayer information in enhancing model robustness. This study underscores the potential of multi-task learning in cloud property retrieval, offering valuable insights for improving climate and weather prediction.&lt;/p&gt;</content:encoded></item><item><title>Concave Cut: Analyzing the Role of Concave Functions in Clustering</title><link>https://doi.org/10.1016/j.patcog.2025.112950</link><guid>10.1016/j.patcog.2025.112950</guid><pubDate>Sun, 21 Dec 2025 15:32:50 +0000</pubDate><dc:creator>Shenfei Pei</dc:creator><dc:creator>Yuanchen Sun</dc:creator><dc:creator>Zhongqi Lin</dc:creator><dc:creator>Feiping Nie</dc:creator><dc:creator>Jitao Lu</dc:creator><dc:creator>Xudong Jiang</dc:creator><dc:creator>Canyu Zhang</dc:creator><dc:creator>Zengwei Zheng</dc:creator><prism:publicationName>Pattern Recognition</prism:publicationName><prism:doi>10.1016/j.patcog.2025.112950</prism:doi><description>To broaden the application of clustering for large-scale datasets, we propose a graph cut framework called Concave-Cut for the scenario with a large scale sample size and a high number of clusters. (defined as the BL-scenario). In Concave-Cut, high quality partitions can be obtained directly by maximizing the compactness of each cluster, without additional regularization or hyper-parameter. Our framework has a concise form, which facilitates the designed optimization algorithm to perform efficiently. Our algorithm can be optimized in linear time with respect to the number of samples n , and its complexity is independent of the number of clusters c . Specifically, the algorithm achieves a time complexity of O ( nk ) where k denotes the number of neighbors per sample, making it highly efficient for applications in BL-scenario. We conduct a series of experiments on 11 synthetic datasets, and 14 middle, and 10 large scale real-world datasets. The experimental results verify the superiority of the proposed Concave-Cut, especially in BL-scenario.
Published: 2025-12-21T15:32:50+00:00
Venue: Pattern Recognition
Score: 0.379 (ignore)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Shenfei Pei; Yuanchen Sun; Zhongqi Lin; Feiping Nie; Jitao Lu; Xudong Jiang; Canyu Zhang; Zengwei Zheng&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; Pattern Recognition&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1016/j.patcog.2025.112950"&gt;10.1016/j.patcog.2025.112950&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.379 (ignore)&lt;/p&gt;
&lt;p&gt;To broaden the application of clustering for large-scale datasets, we propose a graph cut framework called Concave-Cut for the scenario with a large scale sample size and a high number of clusters. (defined as the BL-scenario). In Concave-Cut, high quality partitions can be obtained directly by maximizing the compactness of each cluster, without additional regularization or hyper-parameter. Our framework has a concise form, which facilitates the designed optimization algorithm to perform efficiently. Our algorithm can be optimized in linear time with respect to the number of samples n , and its complexity is independent of the number of clusters c . Specifically, the algorithm achieves a time complexity of O ( nk ) where k denotes the number of neighbors per sample, making it highly efficient for applications in BL-scenario. We conduct a series of experiments on 11 synthetic datasets, and 14 middle, and 10 large scale real-world datasets. The experimental results verify the superiority of the proposed Concave-Cut, especially in BL-scenario.&lt;/p&gt;</content:encoded></item><item><title>DeepONet for Solving Nonlinear Partial Differential Equations with Physics-Informed Training</title><link>https://doi.org/10.1016/j.neunet.2025.108490</link><guid>10.1016/j.neunet.2025.108490</guid><pubDate>Sat, 20 Dec 2025 16:15:23 +0000</pubDate><dc:creator>Yahong Yang</dc:creator><prism:publicationName>Neural Networks</prism:publicationName><prism:doi>10.1016/j.neunet.2025.108490</prism:doi><description>In this paper, we investigate the applications of operator learning, specifically DeepONet, for solving nonlinear partial differential equations (PDEs). Unlike conventional function learning methods that require training separate neural networks for each PDE, operator learning enables generalization across different PDEs without retraining. This study examines the performance of DeepONet in physics-informed training, focusing on two key aspects: (1) the approximation capabilities of deep branch and trunk networks, and (2) the generalization error in Sobolev norms. Our results show that complex branch networks provide substantial performance gains, while trunk networks are most effective when kept relatively simple. Furthermore, we derive a bound on the generalization error of DeepONet for solving nonlinear PDEs by analyzing the Rademacher complexity of its derivatives in terms of pseudo-dimension. This work bridges a critical theoretical gap by delivering rigorous error estimates. This paper fills a theoretical gap by providing error estimates for a wide range of physics-informed machine learning models and applications.
Published: 2025-12-20T16:15:23+00:00
Venue: Neural Networks
Score: 0.378 (ignore)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Yahong Yang&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; Neural Networks&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1016/j.neunet.2025.108490"&gt;10.1016/j.neunet.2025.108490&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.378 (ignore)&lt;/p&gt;
&lt;p&gt;In this paper, we investigate the applications of operator learning, specifically DeepONet, for solving nonlinear partial differential equations (PDEs). Unlike conventional function learning methods that require training separate neural networks for each PDE, operator learning enables generalization across different PDEs without retraining. This study examines the performance of DeepONet in physics-informed training, focusing on two key aspects: (1) the approximation capabilities of deep branch and trunk networks, and (2) the generalization error in Sobolev norms. Our results show that complex branch networks provide substantial performance gains, while trunk networks are most effective when kept relatively simple. Furthermore, we derive a bound on the generalization error of DeepONet for solving nonlinear PDEs by analyzing the Rademacher complexity of its derivatives in terms of pseudo-dimension. This work bridges a critical theoretical gap by delivering rigorous error estimates. This paper fills a theoretical gap by providing error estimates for a wide range of physics-informed machine learning models and applications.&lt;/p&gt;</content:encoded></item><item><title>Hypergraph Attention and Periodic Fusion Learning for Enhanced Flight Delay Prediction</title><link>https://doi.org/10.1016/j.inffus.2025.104076</link><guid>10.1016/j.inffus.2025.104076</guid><pubDate>Sat, 20 Dec 2025 07:25:30 +0000</pubDate><dc:creator>Chi Li</dc:creator><dc:creator>Haowen Jiang</dc:creator><dc:creator>Ruitao Zhou</dc:creator><dc:creator>Ye Dou</dc:creator><dc:creator>Zishun Shen</dc:creator><dc:creator>Lianmin Zhang</dc:creator><dc:creator>Xiongwen Qian</dc:creator><dc:creator>Jianfeng Mao</dc:creator><prism:publicationName>Information Fusion</prism:publicationName><prism:doi>10.1016/j.inffus.2025.104076</prism:doi><description>Predicting flight delays is crucial for enhancing operational efficiency, improving passenger satisfaction, and optimizing resource allocation within the aviation industry. Despite numerous methods and technologies available in this field, current approaches largely rely on complex feature engineering and sampling techniques, and they do not thoroughly explore the core influencing factors of flight delays. To address the myriad challenges in predicting flight delays, we propose the Hypergraph Attention and Periodic Fusion Learning (HAPFL) framework. Our model comprises modules for hypergraph construction, O-D driven graph attention, multi-view flight embedding, and a period-aware sequential transformer. This holistic approach enables a thorough analysis of the micro and macro integration of flight node representations and, through periodic feature extraction, predicts the delay status of flights over multiple future days. Tested on several real-world datasets, our model consistently outperforms current state-of-the-art baseline models, achieving competitive results across all four classification metrics, demonstrating superior overall predictive performance and the effective learning capabilities of its well-designed modules. Our model innovatively captures high-order relationships between flights, significantly enhancing future delay predictions, and contributing to a deeper understanding of delay mechanisms and more effective flight schedule management.
Published: 2025-12-20T07:25:30+00:00
Venue: Information Fusion
Score: 0.375 (ignore)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Chi Li; Haowen Jiang; Ruitao Zhou; Ye Dou; Zishun Shen; Lianmin Zhang; Xiongwen Qian; Jianfeng Mao&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; Information Fusion&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1016/j.inffus.2025.104076"&gt;10.1016/j.inffus.2025.104076&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.375 (ignore)&lt;/p&gt;
&lt;p&gt;Predicting flight delays is crucial for enhancing operational efficiency, improving passenger satisfaction, and optimizing resource allocation within the aviation industry. Despite numerous methods and technologies available in this field, current approaches largely rely on complex feature engineering and sampling techniques, and they do not thoroughly explore the core influencing factors of flight delays. To address the myriad challenges in predicting flight delays, we propose the Hypergraph Attention and Periodic Fusion Learning (HAPFL) framework. Our model comprises modules for hypergraph construction, O-D driven graph attention, multi-view flight embedding, and a period-aware sequential transformer. This holistic approach enables a thorough analysis of the micro and macro integration of flight node representations and, through periodic feature extraction, predicts the delay status of flights over multiple future days. Tested on several real-world datasets, our model consistently outperforms current state-of-the-art baseline models, achieving competitive results across all four classification metrics, demonstrating superior overall predictive performance and the effective learning capabilities of its well-designed modules. Our model innovatively captures high-order relationships between flights, significantly enhancing future delay predictions, and contributing to a deeper understanding of delay mechanisms and more effective flight schedule management.&lt;/p&gt;</content:encoded></item><item><title>MP-DUN: Manifold Prior Based Deep Unfolding Network for Image Compressed Sensing</title><link>https://doi.org/10.1016/j.knosys.2025.115157</link><guid>10.1016/j.knosys.2025.115157</guid><pubDate>Sun, 21 Dec 2025 15:36:20 +0000</pubDate><dc:creator>Bowen Zheng</dc:creator><dc:creator>Guiling Sun</dc:creator><dc:creator>Liang Dong</dc:creator><dc:creator>Haicheng Zhang</dc:creator><prism:publicationName>Knowledge-Based Systems</prism:publicationName><prism:doi>10.1016/j.knosys.2025.115157</prism:doi><description>Compressive sensing (CS) enables accurate signal reconstruction from measurements acquired below the Shannon–Nyquist sampling rate, providing considerable advantages for image acquisition in energy-constrained systems. Typically, data-driven CS methods comprise three main components: sampling strategies, reconstruction networks, and prior information. Existing approaches mainly optimize sampling strategies and reconstruction architectures; however, the integration of novel prior information remains underexplored. This study introduces manifold learning into deep unfolding networks (DUNs) and proposes MP-DUN, a novel manifold prior (MP)-based image CS framework. To model prior information, we developed an adaptive manifold learning module (AMLM), which captures compact representations of images. AMLM is jointly optimized with the DUN to ensure that the learned prior is well-tailored for image CS applications. Leveraging the compact representation space established by AMLM, we used a lightweight diffusion model to infer MPs, which are embedded into iterative reconstruction blocks through a prior-embedded proximal mapping module (PPMM). Experimental results on multiple benchmarks indicate that MP-DUN achieves greater reconstruction performance than that of state-of-the-art methods. Our source code is publicly available at: https://github.com/nkbourne/MP-DUN .
Published: 2025-12-21T15:36:20+00:00
Venue: Knowledge-Based Systems
Score: 0.374 (ignore)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Bowen Zheng; Guiling Sun; Liang Dong; Haicheng Zhang&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; Knowledge-Based Systems&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1016/j.knosys.2025.115157"&gt;10.1016/j.knosys.2025.115157&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.374 (ignore)&lt;/p&gt;
&lt;p&gt;Compressive sensing (CS) enables accurate signal reconstruction from measurements acquired below the Shannon–Nyquist sampling rate, providing considerable advantages for image acquisition in energy-constrained systems. Typically, data-driven CS methods comprise three main components: sampling strategies, reconstruction networks, and prior information. Existing approaches mainly optimize sampling strategies and reconstruction architectures; however, the integration of novel prior information remains underexplored. This study introduces manifold learning into deep unfolding networks (DUNs) and proposes MP-DUN, a novel manifold prior (MP)-based image CS framework. To model prior information, we developed an adaptive manifold learning module (AMLM), which captures compact representations of images. AMLM is jointly optimized with the DUN to ensure that the learned prior is well-tailored for image CS applications. Leveraging the compact representation space established by AMLM, we used a lightweight diffusion model to infer MPs, which are embedded into iterative reconstruction blocks through a prior-embedded proximal mapping module (PPMM). Experimental results on multiple benchmarks indicate that MP-DUN achieves greater reconstruction performance than that of state-of-the-art methods. Our source code is publicly available at: https://github.com/nkbourne/MP-DUN .&lt;/p&gt;</content:encoded></item><item><title>PCRNet: A Multiscale Cross-Attention Network for Large Deformation Medical Image Registration</title><link>https://doi.org/10.1016/j.patcog.2025.112955</link><guid>10.1016/j.patcog.2025.112955</guid><pubDate>Sat, 20 Dec 2025 16:09:53 +0000</pubDate><dc:creator>Liwei Deng</dc:creator><dc:creator>Songyu Chen</dc:creator><dc:creator>Xin Yang</dc:creator><dc:creator>Jing Wang</dc:creator><dc:creator>Sijuan Huang</dc:creator><prism:publicationName>Pattern Recognition</prism:publicationName><prism:doi>10.1016/j.patcog.2025.112955</prism:doi><description>Medical image registration plays a vital role in medical image analysis. In recent years, deep learning-based approaches have gained popularity as alternatives to traditional unsupervised medical image registration methods. However, when dealing with complex structures and large deformations, these methods still need help to estimate topology-preserving large deformations and often require more ability to capture global structure and local details effectively. To solve these problems, we propose a novel registration method based on parallel cross-attention transformer and feature refinement, designed to estimate large deformations. The model enhances information interaction between two image features through the parallel cross-attention transformer module, which can accurately capture features in regions with significant deformation, thus improving the sensitivity to complex deformation. At the same time, the correlation multi-scale attention module is utilized to refine the obtained features, and the attention to essential regions is strengthened through gradual cascading to ensure the accuracy of feature representation. We evaluated the proposed method on liver CT and abdominal CT images. The results show that, compared with existing state-of-the-art methods, the method exhibits better performance in several evaluation metrics while maintaining the integrity of the topology. This suggests that the proposed model has advantages and potential applications for large deformation image registration.
Published: 2025-12-20T16:09:53+00:00
Venue: Pattern Recognition
Score: 0.373 (ignore)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Liwei Deng; Songyu Chen; Xin Yang; Jing Wang; Sijuan Huang&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; Pattern Recognition&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1016/j.patcog.2025.112955"&gt;10.1016/j.patcog.2025.112955&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.373 (ignore)&lt;/p&gt;
&lt;p&gt;Medical image registration plays a vital role in medical image analysis. In recent years, deep learning-based approaches have gained popularity as alternatives to traditional unsupervised medical image registration methods. However, when dealing with complex structures and large deformations, these methods still need help to estimate topology-preserving large deformations and often require more ability to capture global structure and local details effectively. To solve these problems, we propose a novel registration method based on parallel cross-attention transformer and feature refinement, designed to estimate large deformations. The model enhances information interaction between two image features through the parallel cross-attention transformer module, which can accurately capture features in regions with significant deformation, thus improving the sensitivity to complex deformation. At the same time, the correlation multi-scale attention module is utilized to refine the obtained features, and the attention to essential regions is strengthened through gradual cascading to ensure the accuracy of feature representation. We evaluated the proposed method on liver CT and abdominal CT images. The results show that, compared with existing state-of-the-art methods, the method exhibits better performance in several evaluation metrics while maintaining the integrity of the topology. This suggests that the proposed model has advantages and potential applications for large deformation image registration.&lt;/p&gt;</content:encoded></item><item><title>Dual-stream perception cross-flattening transformer for few-shot surface defect detection</title><link>https://doi.org/10.1016/j.ins.2025.123017</link><guid>10.1016/j.ins.2025.123017</guid><pubDate>Sat, 20 Dec 2025 23:14:32 +0000</pubDate><dc:creator>Yudong Li</dc:creator><dc:creator>Shaoqing Wang</dc:creator><dc:creator>Zihao Jing</dc:creator><dc:creator>Jinghua Zheng</dc:creator><dc:creator>Xiaobo Han</dc:creator><dc:creator>Xiao Zheng</dc:creator><dc:creator>Fuzhen Sun</dc:creator><prism:publicationName>Information Sciences</prism:publicationName><prism:doi>10.1016/j.ins.2025.123017</prism:doi><description>Few-shot object detection (FSOD) is a promising approach for surface defect detection, addressing challenges like limited annotated data and diverse defect types on irregular surfaces. Convolutional neural networks (CNNs) are the dominant approach for FSOD. However, local receptive fields in CNNs limit the ability to capture global context, and additional feature alignment mechanisms are required to bridge the semantic gap between query and support images. Therefore, we propose a dual-stream perception cross-flattening transformer (DPCFT) framework for few-shot surface defect detection. First, we design an asymmetric cross-flattening attention (ACFA) that captures long-distance dependencies between query and support images at each feature extraction layer. It enhances multi-branch feature interaction while eliminating the need for separate feature alignment and fusion modules. Second, a position perception module (PPM) is presented to enhance the ability to extract directional features from irregular surface defects. Finally, we propose a dual-stream adaptive module (DAM) to enhance the generalization ability for handling diverse surface defect detection tasks. To verify the effectiveness of the proposed framework, we conduct extensive experiments on three surface defect datasets. Experimental results demonstrate that DPCFT achieves better accuracy and generalization ability than other methods across different experimental settings. Code is available at https://github.com/lydcv/DPCFT .
Published: 2025-12-20T23:14:32+00:00
Venue: Information Sciences
Score: 0.372 (ignore)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Yudong Li; Shaoqing Wang; Zihao Jing; Jinghua Zheng; Xiaobo Han; Xiao Zheng; Fuzhen Sun&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; Information Sciences&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1016/j.ins.2025.123017"&gt;10.1016/j.ins.2025.123017&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.372 (ignore)&lt;/p&gt;
&lt;p&gt;Few-shot object detection (FSOD) is a promising approach for surface defect detection, addressing challenges like limited annotated data and diverse defect types on irregular surfaces. Convolutional neural networks (CNNs) are the dominant approach for FSOD. However, local receptive fields in CNNs limit the ability to capture global context, and additional feature alignment mechanisms are required to bridge the semantic gap between query and support images. Therefore, we propose a dual-stream perception cross-flattening transformer (DPCFT) framework for few-shot surface defect detection. First, we design an asymmetric cross-flattening attention (ACFA) that captures long-distance dependencies between query and support images at each feature extraction layer. It enhances multi-branch feature interaction while eliminating the need for separate feature alignment and fusion modules. Second, a position perception module (PPM) is presented to enhance the ability to extract directional features from irregular surface defects. Finally, we propose a dual-stream adaptive module (DAM) to enhance the generalization ability for handling diverse surface defect detection tasks. To verify the effectiveness of the proposed framework, we conduct extensive experiments on three surface defect datasets. Experimental results demonstrate that DPCFT achieves better accuracy and generalization ability than other methods across different experimental settings. Code is available at https://github.com/lydcv/DPCFT .&lt;/p&gt;</content:encoded></item><item><title>PMDNet: Progressive modulation network with global-local representations for single image deraining</title><link>https://doi.org/10.1016/j.eswa.2025.130910</link><guid>10.1016/j.eswa.2025.130910</guid><pubDate>Sun, 21 Dec 2025 15:36:42 +0000</pubDate><dc:creator>Yihao Ni</dc:creator><dc:creator>Shan Gai</dc:creator><prism:publicationName>Expert Systems with Applications</prism:publicationName><prism:doi>10.1016/j.eswa.2025.130910</prism:doi><description>Images captured under adverse weather conditions such as rainfall suffer from severe quality degradation, which subsequently impacts the performance of numerous vision-oriented systems. As a potential remedy, we propose an advanced progressive modulation network, named PMDNet, for single image deraining. The proposed method attains exceptional rain removal performance through three pivotal designs: 1) a dual-branch framework is employed to jointly optimize rain residuals and background images, which exploits degradation priors by modulating rain-free features with rain features; 2) the integration of Transformer and convolutional neural network (CNN) paradigms allows the model to combine their complementary strengths and to balance both global and local representations; 3) a novel sandwich-shaped Transformer architecture (i.e., placing self-attention between two feed-forward networks) and dilated convolutions with varying dilation factors are introduced to respectively enhance the effectiveness of self-attention and convolutional attention mechanisms, thereby facilitating more refined rain feature extraction and rain-free feature modulation. Extensive experiments conducted on synthetic rain streak/rain-fog/raindrop datasets, real rain samples, snowy scenes, as well as low-light conditions demonstrate the superiority and extensibility of our proposed method. The source code is available at https://github.com/N-yh/PMDNet .
Published: 2025-12-21T15:36:42+00:00
Venue: Expert Systems with Applications
Score: 0.369 (ignore)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Yihao Ni; Shan Gai&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; Expert Systems with Applications&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1016/j.eswa.2025.130910"&gt;10.1016/j.eswa.2025.130910&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.369 (ignore)&lt;/p&gt;
&lt;p&gt;Images captured under adverse weather conditions such as rainfall suffer from severe quality degradation, which subsequently impacts the performance of numerous vision-oriented systems. As a potential remedy, we propose an advanced progressive modulation network, named PMDNet, for single image deraining. The proposed method attains exceptional rain removal performance through three pivotal designs: 1) a dual-branch framework is employed to jointly optimize rain residuals and background images, which exploits degradation priors by modulating rain-free features with rain features; 2) the integration of Transformer and convolutional neural network (CNN) paradigms allows the model to combine their complementary strengths and to balance both global and local representations; 3) a novel sandwich-shaped Transformer architecture (i.e., placing self-attention between two feed-forward networks) and dilated convolutions with varying dilation factors are introduced to respectively enhance the effectiveness of self-attention and convolutional attention mechanisms, thereby facilitating more refined rain feature extraction and rain-free feature modulation. Extensive experiments conducted on synthetic rain streak/rain-fog/raindrop datasets, real rain samples, snowy scenes, as well as low-light conditions demonstrate the superiority and extensibility of our proposed method. The source code is available at https://github.com/N-yh/PMDNet .&lt;/p&gt;</content:encoded></item><item><title>Research on Low-Dimensional Multivariate Information Fusion Prediction Based on Space Battlefield Situation Information</title><link>https://doi.org/10.1016/j.neunet.2025.108513</link><guid>10.1016/j.neunet.2025.108513</guid><pubDate>Sat, 20 Dec 2025 07:23:09 +0000</pubDate><dc:creator>WANG Bo</dc:creator><dc:creator>ZHOU Wen-ya</dc:creator><dc:creator>LIU Jun</dc:creator><prism:publicationName>Neural Networks</prism:publicationName><prism:doi>10.1016/j.neunet.2025.108513</prism:doi><description>Aiming to address the dynamic prediction challenge of space battlefield targets, this paper proposes a hybrid prediction model integrating fuzzy cognitive map (FCM) and echo state networks (ESN). The model first constructs a fuzzy relation map of enemy target combat situations through hierarchical fusion of multivariate time series data, then optimizes node associations using genetic algorithms, and finally enhances prediction robustness through a deviation feedback mechanism. Experimental results demonstrate that compared with conventional methods, the proposed model achieves significantly improved prediction accuracy in dynamic environments (the average error of genetic algorithm is 8.99%, the average error of particle swarm algorithm is 10.39%, the average error of LSTM algorithm is 63.78%, and the average error of our algorithm is 5.10%), providing effective support for real-time space battlefield decision-making. We will release the source code for peer reference 1 .
Published: 2025-12-20T07:23:09+00:00
Venue: Neural Networks
Score: 0.369 (ignore)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; WANG Bo; ZHOU Wen-ya; LIU Jun&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; Neural Networks&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1016/j.neunet.2025.108513"&gt;10.1016/j.neunet.2025.108513&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.369 (ignore)&lt;/p&gt;
&lt;p&gt;Aiming to address the dynamic prediction challenge of space battlefield targets, this paper proposes a hybrid prediction model integrating fuzzy cognitive map (FCM) and echo state networks (ESN). The model first constructs a fuzzy relation map of enemy target combat situations through hierarchical fusion of multivariate time series data, then optimizes node associations using genetic algorithms, and finally enhances prediction robustness through a deviation feedback mechanism. Experimental results demonstrate that compared with conventional methods, the proposed model achieves significantly improved prediction accuracy in dynamic environments (the average error of genetic algorithm is 8.99%, the average error of particle swarm algorithm is 10.39%, the average error of LSTM algorithm is 63.78%, and the average error of our algorithm is 5.10%), providing effective support for real-time space battlefield decision-making. We will release the source code for peer reference 1 .&lt;/p&gt;</content:encoded></item><item><title>Cos-UMamba: Optimizing Salient Object Detection with Cosine Scanning and Bias-Corrected Feature Fusion in Optical Remote Sensing Images</title><link>https://doi.org/10.1016/j.eswa.2025.130863</link><guid>10.1016/j.eswa.2025.130863</guid><pubDate>Sat, 20 Dec 2025 00:08:50 +0000</pubDate><dc:creator>Zhen Wang</dc:creator><dc:creator>Fulin He</dc:creator><dc:creator>Nan Xu</dc:creator><dc:creator>Zhuhong You</dc:creator><prism:publicationName>Expert Systems with Applications</prism:publicationName><prism:doi>10.1016/j.eswa.2025.130863</prism:doi><description>Salient object detection in optical remote sensing images (ORSI-SOD) is a critical task with wide-ranging applications, including environmental monitoring, urban planning, and disaster management. However, the effective fusion of local and global features remains a fundamental challenge in this field. While existing methods attempt to achieve feature complementarity through architectural innovations, the quadratic complexity of Transformers hinders their scalability, and traditional Mamba architectures suffer from static scanning limitations and lack dynamic adaptability. Moreover, representational bias in heterogeneous feature fusion is frequently overlooked, reducing the reliability of detection outcomes. To address these challenges, we propose Cos-UMamba, a novel hybrid framework that integrates bias correction mechanisms with a dynamic omni-directional cosine scanning strategy. This approach enables global long-range modeling of complex topological structures while effectively mitigating feature fusion bias through a K-nearest neighbor (KNN)-based graph construction. By eliminating interference from non-salient regions, the proposed model significantly enhances feature representation. Extensive evaluations conducted on standard ORSI-SOD datasets, including ORSSD, EORSSD, and ORSI-4199, demonstrate the superior performance of Cos-UMamba across multiple metrics such as mean absolute error (MAE) and F-measure. These results validate its capability to advance the accuracy and robustness of salient object detection in diverse remote sensing scenarios, offering a robust tool for tackling real-world challenges in the field. The source code and dataset will be available on https://github.com/darkseid-arch/Cos-UMamba .
Published: 2025-12-20T00:08:50+00:00
Venue: Expert Systems with Applications
Score: 0.369 (ignore)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Zhen Wang; Fulin He; Nan Xu; Zhuhong You&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; Expert Systems with Applications&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1016/j.eswa.2025.130863"&gt;10.1016/j.eswa.2025.130863&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.369 (ignore)&lt;/p&gt;
&lt;p&gt;Salient object detection in optical remote sensing images (ORSI-SOD) is a critical task with wide-ranging applications, including environmental monitoring, urban planning, and disaster management. However, the effective fusion of local and global features remains a fundamental challenge in this field. While existing methods attempt to achieve feature complementarity through architectural innovations, the quadratic complexity of Transformers hinders their scalability, and traditional Mamba architectures suffer from static scanning limitations and lack dynamic adaptability. Moreover, representational bias in heterogeneous feature fusion is frequently overlooked, reducing the reliability of detection outcomes. To address these challenges, we propose Cos-UMamba, a novel hybrid framework that integrates bias correction mechanisms with a dynamic omni-directional cosine scanning strategy. This approach enables global long-range modeling of complex topological structures while effectively mitigating feature fusion bias through a K-nearest neighbor (KNN)-based graph construction. By eliminating interference from non-salient regions, the proposed model significantly enhances feature representation. Extensive evaluations conducted on standard ORSI-SOD datasets, including ORSSD, EORSSD, and ORSI-4199, demonstrate the superior performance of Cos-UMamba across multiple metrics such as mean absolute error (MAE) and F-measure. These results validate its capability to advance the accuracy and robustness of salient object detection in diverse remote sensing scenarios, offering a robust tool for tackling real-world challenges in the field. The source code and dataset will be available on https://github.com/darkseid-arch/Cos-UMamba .&lt;/p&gt;</content:encoded></item><item><title>A YOLO-based Polymerized Head-auxiliary Structures for Target Detection in Remote Sensing Images</title><link>https://doi.org/10.1016/j.patcog.2025.112961</link><guid>10.1016/j.patcog.2025.112961</guid><pubDate>Sun, 21 Dec 2025 06:49:30 +0000</pubDate><dc:creator>Yalu Zhang</dc:creator><dc:creator>Sixiang Quan</dc:creator><dc:creator>Hai Xiao</dc:creator><dc:creator>Jun Liu</dc:creator><dc:creator>Zhenfeng Shao</dc:creator><dc:creator>Zhihui Wang</dc:creator><dc:creator>Yingying Peng</dc:creator><dc:creator>Huali Li</dc:creator><prism:publicationName>Pattern Recognition</prism:publicationName><prism:doi>10.1016/j.patcog.2025.112961</prism:doi><description>Target detection tasks are now widely applied in the field of remote sensing. However, remote sensing target detection tasks are confronted with problems such as cluttered backgrounds and large scale variations. To address these issues, this paper proposes a high-precision aggregation head-auxiliary target detector (PHAS-YOLO). PHAS-YOLO includes two innovative plug-and-play modules: the spatial awareness attention module (SAAM) and the convolutional re-calibration multiscale feature fusion module (CRMSFF), as well as the context aggregation bidirectional connection structure (CABi-FPN) and the adaptive auxiliary head structure (AAHS). The proposed modules enable the model to have good spatial feature aggregation capabilities to retain key feature information, incorporate an adaptive weighting mechanism to reduce information loss caused by the fusion of different scales, and refine the features of the images to be detected. A series of experiments were conducted on three public remote sensing target detection datasets, namely DIOR, DOTAv1.0, and HRRSD, to verify the effectiveness and superiority of the proposed method in remote sensing target detection tasks.
Published: 2025-12-21T06:49:30+00:00
Venue: Pattern Recognition
Score: 0.368 (ignore)</description><content:encoded>&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Yalu Zhang; Sixiang Quan; Hai Xiao; Jun Liu; Zhenfeng Shao; Zhihui Wang; Yingying Peng; Huali Li&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Journal:&lt;/strong&gt; Pattern Recognition&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DOI:&lt;/strong&gt; &lt;a href="https://doi.org/10.1016/j.patcog.2025.112961"&gt;10.1016/j.patcog.2025.112961&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Relevance:&lt;/strong&gt; 0.368 (ignore)&lt;/p&gt;
&lt;p&gt;Target detection tasks are now widely applied in the field of remote sensing. However, remote sensing target detection tasks are confronted with problems such as cluttered backgrounds and large scale variations. To address these issues, this paper proposes a high-precision aggregation head-auxiliary target detector (PHAS-YOLO). PHAS-YOLO includes two innovative plug-and-play modules: the spatial awareness attention module (SAAM) and the convolutional re-calibration multiscale feature fusion module (CRMSFF), as well as the context aggregation bidirectional connection structure (CABi-FPN) and the adaptive auxiliary head structure (AAHS). The proposed modules enable the model to have good spatial feature aggregation capabilities to retain key feature information, incorporate an adaptive weighting mechanism to reduce information loss caused by the fusion of different scales, and refine the features of the images to be detected. A series of experiments were conducted on three public remote sensing target detection datasets, namely DIOR, DOTAv1.0, and HRRSD, to verify the effectiveness and superiority of the proposed method in remote sensing target detection tasks.&lt;/p&gt;</content:encoded></item></channel></rss>
<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ZotWatch 文献推荐 - 2025-12-22</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.1/dist/chart.umd.min.js"></script>
  <script src="https://d3js.org/d3.v7.min.js"></script>
  <script>
    tailwind.config = {
      theme: {
        extend: {
          colors: {
            'bg-primary': '#f8fafc',
            'bg-card': '#ffffff',
            'bg-hover': '#f1f5f9',
            'text-primary': '#1e293b',
            'text-secondary': '#64748b',
            'border-color': '#e2e8f0',
            'accent': '#2563eb',
            'accent-hover': '#1d4ed8',
          }
        }
      }
    }
  </script>
  <style>
    .section-expand { transition: max-height 0.5s ease-out; overflow: hidden; }
    .section-expand.collapsed { max-height: 0; }
    .section-expand.expanded { max-height: none; }
    body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif; }
    .content-container { max-width: 48rem; margin: 0 auto; padding: 0 1rem; }
    @media (min-width: 768px) { .content-container { padding: 0 2rem; } }
    @media (min-width: 1024px) { .content-container { padding: 0 4rem; } }

    .cluster-graph-container { width: 100%; height: 280px; touch-action: pan-y; }
    @media (min-width: 640px) { .cluster-graph-container { height: 320px; } }
    @media (min-width: 768px) { .cluster-graph-container { height: 350px; } }
    #cluster-graph svg { overflow: visible; }
  </style>
</head>
<body class="bg-bg-primary min-h-screen text-text-primary">
  <header class="bg-bg-card border-b border-border-color">
    <div class="content-container py-6 md:py-8">
      <h1 class="text-xl md:text-2xl font-bold text-text-primary">ZotWatch 文献推荐</h1>
      <p class="text-xs md:text-sm text-text-secondary mt-1">
        共 35 篇论文 ·
        生成于 2025-12-22 13:51 Asia/Shanghai
      </p>
    </div>
  </header>

  
  <section class="py-4 md:py-6 border-b border-border-color">
    <div class="content-container">
      <button id="btn-researcher-profile" onclick="toggleSection('researcher-profile')"
              class="w-full text-left text-lg md:text-xl font-bold text-text-primary mb-3 md:mb-4 flex items-center justify-between group hover:text-accent transition-colors">
        <span class="flex items-center gap-2 flex-1 min-w-0">
          <svg class="w-5 h-5 flex-shrink-0 text-accent" fill="currentColor" viewBox="0 0 24 24">
            <path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm0 3c1.66 0 3 1.34 3 3s-1.34 3-3 3-3-1.34-3-3 1.34-3 3-3zm0 14.2c-2.5 0-4.71-1.28-6-3.22.03-1.99 4-3.08 6-3.08 1.99 0 5.97 1.09 6 3.08-1.29 1.94-3.5 3.22-6 3.22z"/>
          </svg>
          <span class="truncate">研究兴趣画像</span>
        </span>
        <span class="flex items-center gap-1 md:gap-2 flex-shrink-0 ml-2">
          <span class="hidden md:inline text-sm font-normal text-text-secondary group-hover:text-accent" id="hint-researcher-profile">点击展开</span>
          <svg class="w-5 h-5 md:w-4 md:h-4 text-text-secondary group-hover:text-accent transform transition-transform" id="icon-researcher-profile" fill="none" stroke="currentColor" viewBox="0 0 24 24">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
          </svg>
        </span>
      </button>

      <div id="researcher-profile" class="section-expand collapsed">
      <div class="bg-bg-card rounded-lg border border-border-color p-4 mb-4">
        <div class="grid grid-cols-4 gap-3 text-center">
          <div>
            <div class="text-xl font-bold text-accent">2461</div>
            <div class="text-xs text-text-secondary">收藏论文</div>
          </div>
          <div>
            <div class="text-xl font-bold text-accent">2年7月</div>
            <div class="text-xs text-text-secondary">收藏时长</div>
          </div>
          <div>
            <div class="text-xl font-bold text-accent">&gt;10</div>
            <div class="text-xs text-text-secondary">兴趣领域</div>
          </div>
          <div>
            <div class="text-xl font-bold text-accent">62</div>
            <div class="text-xs text-text-secondary">高频作者</div>
          </div>
        </div>
      </div>

      
      <div class="bg-accent/10 rounded-lg border border-accent/30 p-4 mb-4">
        <h3 class="text-sm font-semibold text-accent mb-2 flex items-center gap-2">
          <svg class="w-4 h-4" fill="currentColor" viewBox="0 0 24 24">
            <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
          </svg>
          AI 研究兴趣分析
        </h3>
        <div class="space-y-2 text-xs text-text-primary leading-relaxed">
          <p><span class="font-medium text-accent">研究兴趣：</span>用户长期聚焦俯冲带高压-超高压变质作用，特别关注榴辉岩相岩石的变质演化与流体活动；同时系统阅读元素地球化学与年代学手段在造山带研究中的应用。</p>
          <p><span class="font-medium text-accent">深度关注：</span>在超高压变质、俯冲带流体及榴辉岩相三个主题上形成连续且深入的文献积累，显示出对深俯冲-折返过程岩石学与地球化学机理的持续追踪；高频收藏EPSL、GCA、Lithos等权威期刊，表明其注重高质量实验与观测数据。</p>
          <p><span class="font-medium text-accent">跨学科倾向：</span>阅读横跨岩石学、矿床学、地球化学与大地构造，近期开始关注硫同位素与原位分析技术，显示向微区分析与矿床成因交叉拓展的倾向。</p>
          <p><span class="font-medium text-accent">兴趣演变：</span>2024-2025年季度阅读量稳中有升，新增关键词集中在原位硫同位素与金川岩浆硫化物矿床，提示研究重心正从俯冲带变质作用延伸至岩浆-矿床系统的同位素示踪；对液体不混溶与Ni-Cu-PGE矿床的关注度明显增加。</p>
          <p><span class="font-medium text-accent">阅读建议：</span>可进一步关注深部硫循环与俯冲带金属迁移的耦合机制，以及原位微区同位素（S、Cu、Fe）在造山带与岩浆矿床对比研究中的应用。</p>
        </div>
      </div>
      

      <div class="grid grid-cols-1 md:grid-cols-2 gap-4 mb-4">
        
        <div class="bg-bg-card rounded-lg border border-border-color p-4">
          <h4 class="text-sm font-medium text-text-primary mb-3">研究领域分布</h4>
          <div style="height: 180px;">
            <canvas id="domainsChart"></canvas>
          </div>
        </div>
        

        
        <div class="bg-bg-card rounded-lg border border-border-color p-4">
          <h4 class="text-sm font-medium text-text-primary mb-3">阅读趋势（季度）</h4>
          <div style="height: 180px;">
            <canvas id="trendsChart"></canvas>
          </div>
        </div>
        
      </div>

      
      <div class="bg-bg-card rounded-lg border border-border-color p-4 mb-4">
        <h4 class="text-sm font-medium text-text-primary mb-3">论文发表年份分布</h4>
        <div style="height: 180px;">
          <canvas id="yearDistChart"></canvas>
        </div>
      </div>
      

      
      <div class="bg-bg-card rounded-lg border border-border-color p-4 mb-4">
        <h4 class="text-sm font-medium text-text-primary mb-3">
          研究方向聚类图谱
          <span class="text-xs text-text-secondary font-normal ml-2">(2 个聚类)</span>
        </h4>
        <div id="cluster-graph" class="cluster-graph-container"></div>
        <div class="text-xs text-text-secondary mt-3">
          覆盖 1881/1881 篇论文（仅含摘要的文献参与聚类）
        </div>
      </div>
      

      <div class="grid grid-cols-1 md:grid-cols-2 gap-4 mb-4">
        
        <div class="bg-bg-card rounded-lg border border-border-color p-4">
          <h4 class="text-sm font-medium text-text-primary mb-2">高频关注作者</h4>
          <div class="grid grid-cols-2 gap-x-4 gap-y-1 text-xs">
            
            <div class="flex justify-between truncate">
              <span class="text-text-primary truncate" title="Lifei Zhang">Lifei Zhang</span>
              <span class="text-text-secondary ml-1 flex-shrink-0">54</span>
            </div>
            
            <div class="flex justify-between truncate">
              <span class="text-text-primary truncate" title="Jun Gao">Jun Gao</span>
              <span class="text-text-secondary ml-1 flex-shrink-0">44</span>
            </div>
            
            <div class="flex justify-between truncate">
              <span class="text-text-primary truncate" title="Zaicong Wang">Zaicong Wang</span>
              <span class="text-text-secondary ml-1 flex-shrink-0">40</span>
            </div>
            
            <div class="flex justify-between truncate">
              <span class="text-text-primary truncate" title="Timm John">Timm John</span>
              <span class="text-text-secondary ml-1 flex-shrink-0">39</span>
            </div>
            
            <div class="flex justify-between truncate">
              <span class="text-text-primary truncate" title="立飞 张">立飞 张</span>
              <span class="text-text-secondary ml-1 flex-shrink-0">35</span>
            </div>
            
            <div class="flex justify-between truncate">
              <span class="text-text-primary truncate" title="Zhaochu Hu">Zhaochu Hu</span>
              <span class="text-text-secondary ml-1 flex-shrink-0">35</span>
            </div>
            
            <div class="flex justify-between truncate">
              <span class="text-text-primary truncate" title="Yongsheng Liu">Yongsheng Liu</span>
              <span class="text-text-secondary ml-1 flex-shrink-0">34</span>
            </div>
            
            <div class="flex justify-between truncate">
              <span class="text-text-primary truncate" title="Reiner Klemd">Reiner Klemd</span>
              <span class="text-text-secondary ml-1 flex-shrink-0">28</span>
            </div>
            
            <div class="flex justify-between truncate">
              <span class="text-text-primary truncate" title="Jeffrey C. Alt">Jeffrey C. Alt</span>
              <span class="text-text-secondary ml-1 flex-shrink-0">26</span>
            </div>
            
            <div class="flex justify-between truncate">
              <span class="text-text-primary truncate" title="Yong-Fei Zheng">Yong-Fei Zheng</span>
              <span class="text-text-secondary ml-1 flex-shrink-0">25</span>
            </div>
            
            <div class="flex justify-between truncate">
              <span class="text-text-primary truncate" title="Rajdeep Dasgupta">Rajdeep Dasgupta</span>
              <span class="text-text-secondary ml-1 flex-shrink-0">25</span>
            </div>
            
            <div class="flex justify-between truncate">
              <span class="text-text-primary truncate" title="Jay J. Ague">Jay J. Ague</span>
              <span class="text-text-secondary ml-1 flex-shrink-0">25</span>
            </div>
            
          </div>
        </div>
        

        
        <div class="bg-bg-card rounded-lg border border-border-color p-4">
          <h4 class="text-sm font-medium text-text-primary mb-2">常关注期刊/会议</h4>
          <div class="space-y-1 text-xs">
            
            <div class="flex items-center justify-between">
              <span class="text-text-primary truncate flex-1" title="Earth and Planetary Science Letters">Earth and Planetary Science Letters</span>
              <span class="text-xs px-1 py-0.5 rounded bg-blue-100 text-blue-700 ml-1 flex-shrink-0">
                期刊
              </span>
              <span class="text-text-secondary ml-1 flex-shrink-0">189</span>
            </div>
            
            <div class="flex items-center justify-between">
              <span class="text-text-primary truncate flex-1" title="Geochimica et Cosmochimica Acta">Geochimica et Cosmochimica Acta</span>
              <span class="text-xs px-1 py-0.5 rounded bg-blue-100 text-blue-700 ml-1 flex-shrink-0">
                期刊
              </span>
              <span class="text-text-secondary ml-1 flex-shrink-0">167</span>
            </div>
            
            <div class="flex items-center justify-between">
              <span class="text-text-primary truncate flex-1" title="Lithos">Lithos</span>
              <span class="text-xs px-1 py-0.5 rounded bg-blue-100 text-blue-700 ml-1 flex-shrink-0">
                期刊
              </span>
              <span class="text-text-secondary ml-1 flex-shrink-0">111</span>
            </div>
            
            <div class="flex items-center justify-between">
              <span class="text-text-primary truncate flex-1" title="Chemical Geology">Chemical Geology</span>
              <span class="text-xs px-1 py-0.5 rounded bg-blue-100 text-blue-700 ml-1 flex-shrink-0">
                期刊
              </span>
              <span class="text-text-secondary ml-1 flex-shrink-0">109</span>
            </div>
            
            <div class="flex items-center justify-between">
              <span class="text-text-primary truncate flex-1" title="岩石学报">岩石学报</span>
              <span class="text-xs px-1 py-0.5 rounded bg-blue-100 text-blue-700 ml-1 flex-shrink-0">
                期刊
              </span>
              <span class="text-text-secondary ml-1 flex-shrink-0">72</span>
            </div>
            
            <div class="flex items-center justify-between">
              <span class="text-text-primary truncate flex-1" title="Geology">Geology</span>
              <span class="text-xs px-1 py-0.5 rounded bg-blue-100 text-blue-700 ml-1 flex-shrink-0">
                期刊
              </span>
              <span class="text-text-secondary ml-1 flex-shrink-0">63</span>
            </div>
            
            <div class="flex items-center justify-between">
              <span class="text-text-primary truncate flex-1" title="Geochemistry, Geophysics, Geosystems">Geochemistry, Geophysics, Geosystems</span>
              <span class="text-xs px-1 py-0.5 rounded bg-blue-100 text-blue-700 ml-1 flex-shrink-0">
                期刊
              </span>
              <span class="text-text-secondary ml-1 flex-shrink-0">56</span>
            </div>
            
            <div class="flex items-center justify-between">
              <span class="text-text-primary truncate flex-1" title="Journal of Petrology">Journal of Petrology</span>
              <span class="text-xs px-1 py-0.5 rounded bg-blue-100 text-blue-700 ml-1 flex-shrink-0">
                期刊
              </span>
              <span class="text-text-secondary ml-1 flex-shrink-0">53</span>
            </div>
            
          </div>
        </div>
        
      </div>

      
      <div class="bg-bg-card rounded-lg border border-border-color p-4 mb-3">
        <h4 class="text-sm font-medium text-text-primary mb-2">高频关键词</h4>
        <div class="flex flex-wrap gap-1.5">
          
          <span class="px-2 py-0.5 bg-bg-hover rounded text-xs text-text-primary">
            /Done <span class="text-text-secondary">(166)</span>
          </span>
          
          <span class="px-2 py-0.5 bg-bg-hover rounded text-xs text-text-primary">
            /refs <span class="text-text-secondary">(135)</span>
          </span>
          
          <span class="px-2 py-0.5 bg-bg-hover rounded text-xs text-text-primary">
            notion <span class="text-text-secondary">(73)</span>
          </span>
          
          <span class="px-2 py-0.5 bg-bg-hover rounded text-xs text-text-primary">
            /粗略泛读 <span class="text-text-secondary">(70)</span>
          </span>
          
          <span class="px-2 py-0.5 bg-bg-hover rounded text-xs text-text-primary">
            高俊组 <span class="text-text-secondary">(49)</span>
          </span>
          
          <span class="px-2 py-0.5 bg-bg-hover rounded text-xs text-text-primary">
            subduction <span class="text-text-secondary">(41)</span>
          </span>
          
          <span class="px-2 py-0.5 bg-bg-hover rounded text-xs text-text-primary">
            Geochemistry <span class="text-text-secondary">(38)</span>
          </span>
          
          <span class="px-2 py-0.5 bg-bg-hover rounded text-xs text-text-primary">
            PHASE-RELATIONS <span class="text-text-secondary">(37)</span>
          </span>
          
          <span class="px-2 py-0.5 bg-bg-hover rounded text-xs text-text-primary">
            HIGH-PRESSURE <span class="text-text-secondary">(32)</span>
          </span>
          
          <span class="px-2 py-0.5 bg-bg-hover rounded text-xs text-text-primary">
            #研究对象/变沉积岩 <span class="text-text-secondary">(32)</span>
          </span>
          
          <span class="px-2 py-0.5 bg-bg-hover rounded text-xs text-text-primary">
            MANTLE <span class="text-text-secondary">(31)</span>
          </span>
          
          <span class="px-2 py-0.5 bg-bg-hover rounded text-xs text-text-primary">
            Subduction <span class="text-text-secondary">(31)</span>
          </span>
          
          <span class="px-2 py-0.5 bg-bg-hover rounded text-xs text-text-primary">
            EVOLUTION <span class="text-text-secondary">(28)</span>
          </span>
          
          <span class="px-2 py-0.5 bg-bg-hover rounded text-xs text-text-primary">
            榴辉岩 <span class="text-text-secondary">(27)</span>
          </span>
          
          <span class="px-2 py-0.5 bg-bg-hover rounded text-xs text-text-primary">
            OCEANIC-CRUST <span class="text-text-secondary">(24)</span>
          </span>
          
          <span class="px-2 py-0.5 bg-bg-hover rounded text-xs text-text-primary">
            OXIDATION-STATE <span class="text-text-secondary">(23)</span>
          </span>
          
          <span class="px-2 py-0.5 bg-bg-hover rounded text-xs text-text-primary">
            Subduction zone <span class="text-text-secondary">(23)</span>
          </span>
          
          <span class="px-2 py-0.5 bg-bg-hover rounded text-xs text-text-primary">
            Petrology <span class="text-text-secondary">(21)</span>
          </span>
          
          <span class="px-2 py-0.5 bg-bg-hover rounded text-xs text-text-primary">
            WATER <span class="text-text-secondary">(21)</span>
          </span>
          
          <span class="px-2 py-0.5 bg-bg-hover rounded text-xs text-text-primary">
            GEOCHEMISTRY <span class="text-text-secondary">(21)</span>
          </span>
          
        </div>
      </div>
      

      <div class="text-xs text-text-secondary text-right">
        画像生成于 2025-12-21 20:26 Asia/Shanghai
        · kimi-k2-turbo-preview
      </div>
      </div>
    </div>
  </section>
  

  
  <script>
    document.addEventListener('DOMContentLoaded', function() {
      Chart.defaults.font.family = "-apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif";
      Chart.defaults.font.size = 11;
      Chart.defaults.color = '#64748b';
      Chart.defaults.animation = false;

      
      const domainsCtx = document.getElementById('domainsChart');
      if (domainsCtx) {
        new Chart(domainsCtx, {
          type: 'bar',
          data: {
            labels: ['超高压变质', '俯冲带流体', '榴辉岩相', '元素地球化学', '年代学', '构造演化', '硫化物循环', '实验岩石学'],
            datasets: [{
              data: [42, 38, 35, 28, 22, 20, 15, 12],
              backgroundColor: 'rgba(37, 99, 235, 0.7)',
              borderColor: 'rgba(37, 99, 235, 1)',
              borderWidth: 1,
              borderRadius: 2,
              barThickness: 16
            }]
          },
          options: {
            indexAxis: 'y',
            responsive: true,
            maintainAspectRatio: false,
            plugins: {
              legend: { display: false },
              tooltip: { enabled: false }
            },
            scales: {
              x: {
                beginAtZero: true,
                grid: { color: 'rgba(226, 232, 240, 0.5)' },
                ticks: { precision: 0 }
              },
              y: {
                grid: { display: false },
                ticks: { font: { size: 10 } }
              }
            }
          }
        });
      }
      

      
      const trendsCtx = document.getElementById('trendsChart');
      if (trendsCtx) {
        const trends = [{ q: '2023-Q1', c: 16 }, { q: '2023-Q2', c: 8 }, { q: '2023-Q3', c: 7 }, { q: '2023-Q4', c: 15 }, { q: '2024-Q1', c: 21 }, { q: '2024-Q2', c: 9 }, { q: '2024-Q3', c: 12 }, { q: '2024-Q4', c: 11 }, { q: '2025-Q1', c: 19 }, { q: '2025-Q2', c: 3 }, { q: '2025-Q3', c: 7 }, { q: '2025-Q4', c: 3 }];
        const monthColors = [
          { bg: 'rgba(59, 130, 246, 0.7)', border: 'rgba(59, 130, 246, 1)' },
          { bg: 'rgba(16, 185, 129, 0.7)', border: 'rgba(16, 185, 129, 1)' },
          { bg: 'rgba(245, 158, 11, 0.7)', border: 'rgba(245, 158, 11, 1)' }
        ];
        const bgColors = trends.map((t, i) => monthColors[i % 3].bg);
        const borderColors = trends.map((t, i) => monthColors[i % 3].border);
        new Chart(trendsCtx, {
          type: 'bar',
          data: {
            labels: trends.map(t => t.q.replace('-', '\n')),
            datasets: [{
              data: trends.map(t => t.c),
              backgroundColor: bgColors,
              borderColor: borderColors,
              borderWidth: 1,
              borderRadius: 2,
              barThickness: 20
            }]
          },
          options: {
            responsive: true,
            maintainAspectRatio: false,
            plugins: {
              legend: { display: false },
              tooltip: { enabled: false }
            },
            scales: {
              x: {
                grid: { display: false },
                ticks: { font: { size: 9 }, maxRotation: 0 }
              },
              y: {
                beginAtZero: true,
                grid: { color: 'rgba(226, 232, 240, 0.5)' },
                ticks: { precision: 0 }
              }
            }
          }
        });
      }
      

      
      const yearDistCtx = document.getElementById('yearDistChart');
      if (yearDistCtx) {
        const yearData = [{ year: 2006, count: 29 }, { year: 2007, count: 35 }, { year: 2008, count: 25 }, { year: 2009, count: 33 }, { year: 2010, count: 28 }, { year: 2011, count: 38 }, { year: 2012, count: 26 }, { year: 2013, count: 38 }, { year: 2014, count: 67 }, { year: 2015, count: 35 }, { year: 2016, count: 33 }, { year: 2017, count: 34 }, { year: 2018, count: 39 }, { year: 2019, count: 41 }, { year: 2020, count: 66 }, { year: 2021, count: 59 }, { year: 2022, count: 47 }, { year: 2023, count: 46 }, { year: 2024, count: 53 }, { year: 2025, count: 32 }];
        new Chart(yearDistCtx, {
          type: 'line',
          data: {
            labels: yearData.map(d => d.year),
            datasets: [{
              data: yearData.map(d => d.count),
              borderColor: 'rgba(37, 99, 235, 1)',
              backgroundColor: 'rgba(37, 99, 235, 0.1)',
              borderWidth: 2,
              fill: true,
              tension: 0.3,
              pointRadius: 2,
              pointHoverRadius: 4
            }]
          },
          options: {
            responsive: true,
            maintainAspectRatio: false,
            plugins: {
              legend: { display: false },
              tooltip: {
                callbacks: {
                  label: function(context) {
                    return context.parsed.y + ' 篇';
                  }
                }
              }
            },
            scales: {
              x: {
                grid: { display: false },
                ticks: {
                  font: { size: 9 },
                  maxRotation: 45,
                  callback: function(value, index) {
                    const year = this.getLabelForValue(value);
                    return year % 5 === 0 ? year : '';
                  }
                }
              },
              y: {
                beginAtZero: true,
                grid: { color: 'rgba(226, 232, 240, 0.5)' },
                ticks: { precision: 0 }
              }
            }
          }
        });
      }
      

      
      const clusterContainer = document.getElementById('cluster-graph');
      if (clusterContainer) {
        const clusters = [
          
          {
            id: 0,
            label: "\u4fef\u51b2\u5e26\u58f3\u5e54\u76f8\u4e92\u4f5c\u7528\u4e0e\u5730\u7403\u5316\u5b66\u793a\u8e2a",
            size: 1649,
            keywords: ["\ud83d\udcd2", "/Done", "\ud83d\udea9"]
          },
          
          {
            id: 1,
            label: "\u91d1\u5c5e\u5e73\u677f\u5149\u6fc0\u53d1\u4e0e\u8fd1\u573a\u7b49\u79bb\u6fc0\u5143",
            size: 232,
            keywords: []
          }
          
        ];

        const links = [{"source": 0, "target": 1, "value": 0.5370174513266999}];

        const academicColors = [
          '#4E79A7', '#F28E2B', '#E15759', '#76B7B2', '#59A14F',
          '#EDC948', '#B07AA1', '#FF9DA7', '#9C755F', '#BAB0AC',
          '#86BCB6', '#D37295', '#8CD17D', '#499894', '#FABFD2',
          '#79706E', '#D4A6C8', '#9D7660', '#B6992D', '#A0CBE8'
        ];
        const colorScale = (i) => academicColors[i % academicColors.length];

        let svg, simulation, node, link, sizeScale;
        let lastWidth = 0;
        let simulationStopped = false;

        function createGraph() {
          const width = clusterContainer.clientWidth;
          const height = clusterContainer.clientHeight || 280;
          const isMobile = width < 500;

          lastWidth = width;
          clusterContainer.innerHTML = '';

          const minRadius = isMobile ? 16 : 20;
          const maxRadius = isMobile ? 38 : 48;
          sizeScale = d3.scaleSqrt()
            .domain([0, d3.max(clusters, d => d.size)])
            .range([minRadius, maxRadius]);

          svg = d3.select('#cluster-graph')
            .append('svg')
            .attr('width', width)
            .attr('height', height)
            .attr('viewBox', [0, 0, width, height]);

          // Create layered groups for z-order control
          // Order (bottom to top): dimmed links -> dimmed nodes -> highlighted links -> highlighted nodes
          const layerDimmedLinks = svg.append('g').attr('class', 'layer-dimmed-links');
          const layerDimmedNodes = svg.append('g').attr('class', 'layer-dimmed-nodes');
          const layerHighlightedLinks = svg.append('g').attr('class', 'layer-highlighted-links');
          const layerHighlightedNodes = svg.append('g').attr('class', 'layer-highlighted-nodes');

          const chargeStrength = isMobile ? -100 : -150;
          const linkDistance = isMobile ? 60 : 90;

          simulationStopped = false;
          simulation = d3.forceSimulation(clusters)
            .force('link', d3.forceLink(links).id(d => d.id).distance(linkDistance).strength(0.2))
            .force('charge', d3.forceManyBody().strength(chargeStrength))
            .force('center', d3.forceCenter(width / 2, height / 2))
            .force('collision', d3.forceCollide().radius(d => sizeScale(d.size) + (isMobile ? 4 : 6)))
            .velocityDecay(0.7)
            .alphaDecay(0.08)
            .alphaMin(0.01);

          // Initially all links in dimmed layer
          link = layerDimmedLinks
            .attr('stroke', '#e2e8f0')
            .attr('stroke-opacity', 0.6)
            .selectAll('line')
            .data(links)
            .join('line')
            .attr('stroke-width', d => Math.max(1, d.value * 1.5));

          // Initially all nodes in dimmed layer
          node = layerDimmedNodes
            .selectAll('g')
            .data(clusters)
            .join('g')
            .style('cursor', 'grab');

          node.append('circle')
            .attr('r', d => sizeScale(d.size))
            .attr('fill', (d, i) => colorScale(i))
            .attr('fill-opacity', 0.85)
            .attr('stroke', '#fff')
            .attr('stroke-width', isMobile ? 1.5 : 2);

          const fontSize = isMobile ? 7 : 8;
          const lineHeight = isMobile ? 8 : 9;
          const charWidth = isMobile ? 5 : 5.5;

          function wrapText(text, radius) {
            text.each(function() {
              const textEl = d3.select(this);
              const label = textEl.text();
              const maxWidth = radius * 1.2;

              textEl.text(null);

              let lines = [];
              let currentLine = '';
              for (let char of label) {
                if ((currentLine.length + 1) * charWidth > maxWidth && currentLine) {
                  lines.push(currentLine);
                  currentLine = char;
                } else {
                  currentLine += char;
                }
              }
              if (currentLine) lines.push(currentLine);

              if (lines.length > 2) {
                lines = lines.slice(0, 2);
                lines[1] = lines[1].substring(0, Math.max(0, lines[1].length - 1)) + '..';
              }

              const startY = -(lines.length - 1) * lineHeight / 2;

              lines.forEach((line, i) => {
                textEl.append('tspan')
                  .attr('x', 0)
                  .attr('dy', i === 0 ? startY : lineHeight)
                  .text(line);
              });
            });
          }

          node.append('text')
            .text(d => d.label)
            .attr('text-anchor', 'middle')
            .attr('dominant-baseline', 'middle')
            .attr('font-size', fontSize + 'px')
            .attr('font-weight', '500')
            .attr('fill', '#fff')
            .attr('pointer-events', 'none')
            .each(function(d) {
              wrapText(d3.select(this), sizeScale(d.size));
            });

          node.append('text')
            .text(d => `(${d.size}篇)`)
            .attr('text-anchor', 'middle')
            .attr('dy', d => sizeScale(d.size) + (isMobile ? 10 : 12))
            .attr('font-size', fontSize + 'px')
            .attr('fill', '#94a3b8');

          node.append('title')
            .text(d => `${d.label}\n论文数: ${d.size}\n关键词: ${d.keywords.join(', ')}`);

          const drag = d3.drag()
            .on('start', dragstarted)
            .on('drag', dragged)
            .on('end', dragended);

          node.call(drag);

          simulation.on('tick', () => {
            node.attr('transform', d => {
              const r = sizeScale(d.size);
              const padding = isMobile ? 5 : 8;
              const maxY = height - r - (isMobile ? 12 : 15);
              d.x = Math.max(r + padding, Math.min(width - r - padding, d.x));
              d.y = Math.max(r + padding, Math.min(maxY, d.y));
              return `translate(${d.x},${d.y})`;
            });

            link
              .attr('x1', d => d.source.x)
              .attr('y1', d => d.source.y)
              .attr('x2', d => d.target.x)
              .attr('y2', d => d.target.y);
          });

          simulation.on('end', () => {
            simulationStopped = true;
          });

          function dragstarted(event, d) {
            if (!event.active) simulation.alphaTarget(0.05).restart();
            d.fx = d.x;
            d.fy = d.y;
            highlightNode(d);
            d3.select(this).style('cursor', 'grabbing');
          }

          function dragged(event, d) {
            const r = sizeScale(d.size);
            const padding = isMobile ? 5 : 8;
            const maxY = height - r - (isMobile ? 12 : 15);
            d.fx = Math.max(r + padding, Math.min(width - r - padding, event.x));
            d.fy = Math.max(r + padding, Math.min(maxY, event.y));
          }

          function dragended(event, d) {
            if (!event.active) simulation.alphaTarget(0);
            d.fx = null;
            d.fy = null;
            d3.select(this).style('cursor', 'grab');
            resetHighlight();
          }

          function highlightNode(selectedNode) {
            const connectedIds = new Set();

            links.forEach(l => {
              if (l.source.id === selectedNode.id) connectedIds.add(l.target.id);
              if (l.target.id === selectedNode.id) connectedIds.add(l.source.id);
            });

            // Step 1: Style dimmed elements
            link
              .attr('stroke-opacity', 0.1)
              .attr('stroke', '#cbd5e1')
              .attr('stroke-width', d => Math.max(1, d.value * 1.5));

            node.each(function(d) {
              d3.select(this).select('circle')
                .attr('fill-opacity', 0.25)
                .attr('stroke', '#fff')
                .attr('stroke-width', isMobile ? 1.5 : 2);

              d3.select(this).selectAll('text')
                .attr('opacity', 0.3);
            });

            // Step 2: Move dimmed elements to bottom layers
            link.each(function() {
              layerDimmedLinks.node().appendChild(this);
            });
            node.each(function() {
              layerDimmedNodes.node().appendChild(this);
            });

            // Step 3: Style and move highlighted links to top
            link.filter(l => l.source.id === selectedNode.id || l.target.id === selectedNode.id)
              .attr('stroke-opacity', 1)
              .attr('stroke', '#2563eb')
              .attr('stroke-width', d => Math.max(2.5, d.value * 3))
              .each(function() {
                layerHighlightedLinks.node().appendChild(this);
              });

            // Step 4: Style and move connected nodes to top
            node.filter(d => connectedIds.has(d.id))
              .each(function(d) {
                d3.select(this).select('circle')
                  .attr('fill-opacity', 1)
                  .attr('stroke', '#60a5fa')
                  .attr('stroke-width', isMobile ? 2.5 : 3);

                d3.select(this).selectAll('text')
                  .attr('opacity', 1);

                layerHighlightedNodes.node().appendChild(this);
              });

            // Step 5: Style and move selected node to very top
            node.filter(d => d.id === selectedNode.id)
              .each(function(d) {
                d3.select(this).select('circle')
                  .attr('fill-opacity', 1)
                  .attr('stroke', '#2563eb')
                  .attr('stroke-width', isMobile ? 3 : 4);

                d3.select(this).selectAll('text')
                  .attr('opacity', 1);

                layerHighlightedNodes.node().appendChild(this);
              });
          }

          function resetHighlight() {
            // Move all elements back to dimmed layers
            link.each(function() {
              layerDimmedLinks.node().appendChild(this);
            });

            node.each(function() {
              layerDimmedNodes.node().appendChild(this);
            });

            // Reset styles
            node.select('circle')
              .attr('fill-opacity', 0.85)
              .attr('stroke', '#fff')
              .attr('stroke-width', isMobile ? 1.5 : 2)
              .style('filter', 'none');

            link
              .attr('stroke-opacity', 0.6)
              .attr('stroke', '#e2e8f0')
              .attr('stroke-width', d => Math.max(1, d.value * 1.5));

            node.selectAll('text')
              .attr('opacity', 1);
          }
        }

        createGraph();

        let resizeTimeout;
        window.addEventListener('resize', () => {
          clearTimeout(resizeTimeout);
          resizeTimeout = setTimeout(() => {
            const newWidth = clusterContainer.clientWidth;
            if (Math.abs(newWidth - lastWidth) > 10) {
              clusters.forEach(d => { d.x = undefined; d.y = undefined; d.fx = null; d.fy = null; });
              createGraph();
            }
          }, 250);
        });
      }
      
    });
  </script>
  

  
  <section class="py-5 md:py-8 border-b border-border-color">
    <div class="content-container">
      <button id="btn-overall-summaries" onclick="toggleSection('overall-summaries')"
              class="w-full text-left text-lg md:text-xl font-bold text-text-primary mb-3 md:mb-4 flex items-center justify-between group hover:text-accent transition-colors">
        <span class="flex items-center gap-2 flex-1 min-w-0">
          <svg class="w-5 h-5 flex-shrink-0 text-accent" fill="currentColor" viewBox="0 0 24 24">
            <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
          </svg>
          <span class="truncate">本期研究趋势概览</span>
        </span>
        <span class="flex items-center gap-1 md:gap-2 flex-shrink-0 ml-2">
          <span class="hidden md:inline text-sm font-normal text-text-secondary group-hover:text-accent" id="hint-overall-summaries">点击收起</span>
          <svg class="w-5 h-5 md:w-4 md:h-4 text-text-secondary group-hover:text-accent transform transition-transform rotate-180" id="icon-overall-summaries" fill="none" stroke="currentColor" viewBox="0 0 24 24">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
          </svg>
        </span>
      </button>

      <div id="overall-summaries" class="section-expand expanded">
      <div class="space-y-4 md:space-y-6">
        
        <div class="bg-bg-card rounded-lg border border-border-color p-4 md:p-5">
          <h3 class="text-base font-semibold text-text-primary mb-3 flex items-center gap-2">
            <svg class="w-4 h-4 text-accent" fill="currentColor" viewBox="0 0 20 20">
              <path d="M9.049 2.927c.3-.921 1.603-.921 1.902 0l1.07 3.292a1 1 0 00.95.69h3.462c.969 0 1.371 1.24.588 1.81l-2.8 2.034a1 1 0 00-.364 1.118l1.07 3.292c.3.921-.755 1.688-1.54 1.118l-2.8-2.034a1 1 0 00-1.175 0l-2.8 2.034c-.784.57-1.838-.197-1.539-1.118l1.07-3.292a1 1 0 00-.364-1.118L2.98 8.72c-.783-.57-.38-1.81.588-1.81h3.461a1 1 0 00.951-.69l1.07-3.292z"/>
            </svg>
            精选推荐总结
          </h3>
          <div class="text-sm text-text-primary leading-relaxed space-y-2">
            <p>本期推荐涵盖了2篇关于三维重建的论文、1篇关于优化算法的论文、1篇关于调度制造的论文和1篇关于聚类分析的论文。</p>
            
            <p><strong class="text-accent">三维重建</strong>：《A Comparative Review of Representative Techniques in Image-Based 3D Dense Reconstruction》系统回顾了基于图像的稠密三维重建技术，而《Bridging Geometry-Coherent Text-to-3D Generation with Multiview Diffusion Priors and Gaussian Splatting》提出利用多视角扩散先验与高斯抛雪球实现文本驱动的几何一致三维生成。</p>
            
            <p><strong class="text-accent">优化算法</strong>：《Adversarial game optimization: A game-theoretic metaheuristic for efficient complex optimization and engineering applications》将博弈论思想融入元启发式框架，提出对抗博弈优化以应对高维复杂工程优化问题。</p>
            
            <p><strong class="text-accent">调度制造</strong>：《Multi-objective and simulation approaches for flowshop scheduling in rubber manufacturing with recycle waste and uncertainties》针对橡胶制造中的回收废料与不确定性，采用多目标仿真方法优化流水车间调度，实现可持续生产。</p>
            
            <p><strong class="text-accent">聚类分析</strong>：《Concave Cut: Analyzing the Role of Concave Functions in Clustering》提出基于凹函数的图割框架Concave-Cut，以提升大规模高簇数场景下的聚类性能。</p>
            
          </div>
        </div>
        

        
        <div class="bg-bg-card rounded-lg border border-border-color p-4 md:p-5">
          <h3 class="text-base font-semibold text-text-primary mb-3 flex items-center gap-2">
            <svg class="w-4 h-4 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 19v-6a2 2 0 00-2-2H5a2 2 0 00-2 2v6a2 2 0 002 2h2a2 2 0 002-2zm0 0V9a2 2 0 012-2h2a2 2 0 012 2v10m-6 0a2 2 0 002 2h2a2 2 0 002-2m0 0V5a2 2 0 012-2h2a2 2 0 012 2v14a2 2 0 01-2 2h-2a2 2 0 01-2-2z"/>
            </svg>
            相似度推荐总结
          </h3>
          <div class="text-sm text-text-primary leading-relaxed space-y-2">
            <p>本期推荐涵盖了5篇关于时空建模的论文、4篇关于图像重建与分割的论文、3篇关于森林与生态监测的论文、3篇关于工业过程优化的论文、3篇关于机器学习方法的论文、2篇关于岩土与基础工程的论文、2篇关于文化遗产保护的论文、2篇关于多目标/多任务回归的论文、2篇关于橡胶与回收制造的论文、1篇关于甲骨文图像去噪的论文、1篇关于集成回归优化的论文。</p>
            
            <p><strong class="text-text-secondary">时空建模</strong>：《ST-Imputer》提出物理引导的扩散网络补全缺失时空数据；《Spatial-temporal landslide susceptibility modeling》利用RNN与迁移学习解决缺资料区滑坡易发性动态评估；《Test-Time Reconstruction》将物理正演算子嵌入双协同学习实现电磁层析无监督域适应；《Multi-target regression measurement model》构建级联随机配置网络同步预测流程工业多工况参数；《Oracle Bone Image Denoising》虽聚焦图像去噪，但其CM-UNet同样处理复杂时空噪声分布。</p>
            
            <p><strong class="text-text-secondary">图像重建分割</strong>：《A reliable framework for brain tumor segmentation》通过多模态融合与不确定性建模提升MRI脑瘤分割可靠性；《Test-Time Reconstruction》在电磁层析成像中以物理积分网络实现断面图像重建；《Oracle Bone Image Denoising》用卷积多头注意力CM-UNet去除甲骨文拓片复杂噪声；《Symbolic Distillation》虽主要预测桩基沉降，但全Token化Transformer的可视化蒸馏亦提供图像级解释。</p>
            
            <p><strong class="text-text-secondary">森林生态监测</strong>：《Automated TLS multi-scan registration》基于哈希表实现林分多站激光点云全自动配准；《Spatial-temporal landslide susceptibility modeling》把滑坡时空预测用于山地生态灾害评估；森林生态主题还涉及对复杂地形下植被-土壤相互作用的长期监测需求。</p>
            
            <p><strong class="text-text-secondary">工业过程优化</strong>：《Multi-objective and simulation approaches》以多目标仿真优化橡胶厂流水车间调度，兼顾回收料与不确定性；《Multi-target regression measurement model》在流程工业现场同步预测多个关键运行指标；相关研究共同强调数据驱动的生产节能与降耗决策。</p>
            
            <p><strong class="text-text-secondary">机器学习方法</strong>：《Symbolic Distillation》提出可解释全Token化Transformer用于复杂地层中桩基沉降预测；《Shrinkage Matters》系统分析回归集成中收缩策略对精度-多样性权衡的影响；多篇论文共同验证深度模型在数据稀缺场景下的迁移与蒸馏机制。</p>
            
            <p><strong class="text-text-secondary">岩土基础工程</strong>：《Symbolic Distillation》针对成层土中预钻孔灌浆扩底节点桩建立高精度沉降-荷载预测模型；《Spatial-temporal landslide susceptibility modeling》将滑坡易发性评估用于边坡岩土工程风险管理。</p>
            
            <p><strong class="text-text-secondary">文化遗产保护</strong>：《Oracle Bone Image Denoising》开发CM-UNet去除甲骨拓片噪声以恢复古文字信息；另一篇关注多光谱成像与物理模型结合的文物表面重建，为数字化保护提供支持。</p>
            
            <p><strong class="text-text-secondary">多目标回归</strong>：《Multi-target regression measurement model》提出级联宽随机配置网络同时预测流程工业多指标；《Shrinkage Matters》探讨多输出回归集成中收缩系数对整体性能的提升机制。</p>
            
            <p><strong class="text-text-secondary">橡胶回收制造</strong>：《Multi-objective and simulation approaches》在橡胶流动车间中引入回收废料与随机扰动，多目标优化总延迟与能耗；相关研究还评估了再生胶比例对生产节拍与碳足迹的耦合影响。</p>
            
          </div>
        </div>
        
      </div>
      </div>
    </div>
  </section>
  

  
  <section class="py-5 md:py-8 border-b border-border-color">
    <div class="content-container">
      <div class="mb-3 md:mb-4">
        <button id="btn-interest-works" onclick="toggleSection('interest-works')"
                class="w-full text-left text-lg md:text-xl font-bold text-text-primary flex items-center justify-between group hover:text-accent transition-colors">
          <span class="flex items-center gap-2 flex-1 min-w-0">
            <svg class="w-5 h-5 flex-shrink-0 text-accent" fill="currentColor" viewBox="0 0 20 20">
              <path d="M9.049 2.927c.3-.921 1.603-.921 1.902 0l1.07 3.292a1 1 0 00.95.69h3.462c.969 0 1.371 1.24.588 1.81l-2.8 2.034a1 1 0 00-.364 1.118l1.07 3.292c.3.921-.755 1.688-1.54 1.118l-2.8-2.034a1 1 0 00-1.175 0l-2.8 2.034c-.784.57-1.838-.197-1.539-1.118l1.07-3.292a1 1 0 00-.364-1.118L2.98 8.72c-.783-.57-.38-1.81.588-1.81h3.461a1 1 0 00.951-.69l1.07-3.292z"/>
            </svg>
            <span class="truncate">精选推荐</span>
          </span>
          <span class="flex items-center gap-1 md:gap-2 flex-shrink-0 ml-2">
            <span class="hidden md:inline text-xs font-normal text-text-secondary">基于研究兴趣匹配，共 5 篇</span>
            <span class="hidden md:inline text-sm font-normal text-text-secondary group-hover:text-accent" id="hint-interest-works">点击收起</span>
            <svg class="w-5 h-5 md:w-4 md:h-4 text-text-secondary group-hover:text-accent transform transition-transform rotate-180" id="icon-interest-works" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
            </svg>
          </span>
        </button>
        <p class="text-xs text-text-secondary mt-1 ml-7 md:hidden">基于研究兴趣匹配，共 5 篇</p>
      </div>

      <div id="interest-works" class="section-expand expanded">
      <div class="space-y-4 md:space-y-5">
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium bg-accent/10 text-accent border border-accent/30">
                  匹配度 18%
                </span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-20</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.14358/pers.25-00073r4" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      A Comparative Review of Representative Techniques in Image-Based 3D Dense Reconstruction
                    </a>
                  </h2>
                  
                  <p class="text-sm text-text-secondary mt-0.5 leading-snug">基于图像的三维稠密重建代表性技术比较综述</p>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-20</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Photogrammetric Engineering &amp;amp; Remote Sensing">
                Photogrammetric Engineering &amp;amp; Remote Sensing
                
                  <span class="ml-1 text-blue-600">(IF: 2.0)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Minghui Zhu，Jianguo Yan，Jiageng Zhong，Abdelaziz Elfadaly，Liangzhi Dai
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.14358/pers.25-00073r4" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.14358/pers.25-00073r4</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-interest-abstract-1" onclick="toggleSection('interest-abstract-1')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-interest-abstract-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="interest-abstract-1" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">A dense model of the target scene can be generated using dense three-dimensional (3D) reconstruction techniques based on the known camera poses. Over the past two decades, numerous advanced algorithms have emerged that not only enhance the quality and accuracy of 3D reconstruction but also point to promising directions for future developments. These methods include traditional multi-view stereo (MVS), deep learning–based MVS approaches, and more recent techniques such as neural radiance fields (NeRFs), which excel in modeling complex scenes, and 3D Gaussian splatting (3DGS), which shows promise for real-time performance and high visual fidelity. Each of these techniques varies in terms of accuracy, robustness, efficiency, computational resource usage, and applicability to different types of scenes. In this paper, we provide a comprehensive review of these methods, analyze their strengths and limitations, and experimentally compare their performance under different conditions to guide future advancements in high-quality dense 3D reconstruction.</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>如何系统比较主流图像稠密三维重建技术并指导未来高质量重建。</p>
                <p><span class="font-medium text-accent">研究方法：</span>综述传统MVS、深度学习MVS、NeRF与3DGS，并在多场景下实验评估。</p>
                <p><span class="font-medium text-accent">主要发现：</span>各方法在精度、鲁棒性、效率与资源需求上差异显著，无全能方案。</p>
                <p><span class="font-medium text-accent">创新点：</span>首次联合对比传统、深度学习、NeRF及3DGS并给出场景适用性指南。</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为研究者快速选型与改进稠密三维重建提供量化依据与发展方向。</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-interest-detail-1" onclick="toggleSection('interest-detail-1')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="interest-detail-1" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>过去二十年，基于图像的稠密三维重建已从传统多视图立体视觉（MVS）演进到深度学习和神经辐射场（NeRF）等范式，但缺乏对各类方法在统一场景下的系统比较。作者旨在梳理主流技术路线，为研究者提供精度、鲁棒性、效率与资源消耗的定量参考。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>论文将现有方法划分为传统MVS、深度学习MVS、NeRF与最新3D Gaussian Splatting（3DGS）四大类，首先系统回顾各自的核心假设、算法流程与公开实现。随后在同一数据集与硬件平台上，对每种方法进行控制变量实验，评估重建精度（RMSE、 completeness）、运行时间、GPU/CPU占用及场景适应性。最后通过消融实验分析关键模块（如代价体构建、体渲染采样策略、高斯数量）对性能的影响。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>实验表明，传统MVS在Lambertian、纹理丰富场景下仍保持最高几何精度；深度学习MVS在弱纹理区域鲁棒性提升约30%，但显存消耗翻倍；NeRF在复杂反射与透明材质上视觉保真度最佳，LPIPS降低0.05，但训练时间长达数小时；3DGS在保持与NeRF相近PSNR的同时，将渲染速度提升两个数量级至100 fps，适合实时应用。综合评分显示，没有单一方法在所有指标上占优，需根据场景与硬件条件权衡选择。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>评测仅覆盖公开合成与室内数据集，未纳入大规模户外或动态场景；硬件平台固定为单张RTX 3090，结果可能无法泛化至边缘设备；3DGS与NeRF的内存峰值随高斯/采样点数线性增长，文中未给出显式上限分析。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>未来工作可探索混合表示（NeRF+3DGS）以兼顾精度与速度，并引入自适应采样策略降低显存；针对动态大场景，研究时空一致性的联合优化框架。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>若研究者关注多视图几何、神经渲染或实时三维重建，本综述提供的统一实验基准与开源脚本可直接作为方法选型与性能对比的参考，节省重复实现与调参成本。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.12</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.34
                  
                    <span class="ml-1 text-blue-600">(IF: 2.0)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium bg-accent/10 text-accent border border-accent/30">
                  匹配度 17%
                </span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-20</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.ins.2025.123022" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      Adversarial game optimization: A game-theoretic metaheuristic for efficient complex optimization and engineering applications
                    </a>
                  </h2>
                  
                  <p class="text-sm text-text-secondary mt-0.5 leading-snug">对抗博弈优化：一种博弈论元启发式方法用于高效复杂优化与工程应用</p>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-20</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Information Sciences">
                Information Sciences
                
                  <span class="ml-1 text-blue-600">(IF: 6.8)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Conglin Li，Qingke Zhang，Junqing Li，Sichen Tao，Diego Oliva
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.ins.2025.123022" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.ins.2025.123022</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-interest-abstract-2" onclick="toggleSection('interest-abstract-2')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-interest-abstract-2" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="interest-abstract-2" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">Metaheuristic optimization algorithms have demonstrated strong performance when applied to complex nonlinear optimization tasks. However, their performance often degrades in high-dimensional and multimodal settings due to premature convergence and insufficient global search. To address these limitations, an Adversarial Game Optimization Algorithm (AGOA) is proposed, which constructs a metaheuristic optimization framework based on adversarial game mechanisms. AGOA integrates three mechanisms: (i) a dynamic role-based population partitioning strategy that assigns individuals as elite, explorers, or responders to balance exploration and exploitation; (ii) an adversarial feedback mechanism where worst-case responders introduce directed perturbations to counter elite dominance; and (iii) a diversity-preserving breakout strategy that monitors population stagnation and activates adaptive restarts. AGOA was tested on CEC 2017 (30D/50D/100D) and CEC 2022 (10D/20D), as well as applications including multi-threshold image segmentation, constrained engineering design, and UAV 3D path planning. Experimental evaluations indicate that AGOA achieves superior performance compared with 79 optimizers in solution quality, convergence behavior, and stability, achieving top rankings across all test categories. Theoretical analysis further establishes convergence to the global optimum in expectation and probability under mild conditions. Overall, AGOA offers a scalable and generalizable optimization framework with strong practical relevance. An open-access implementation of AGOA is provided at https://github.com/tsingke/AGOA .</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>高维多峰优化中早熟收敛与全局搜索不足导致元启发式性能下降</p>
                <p><span class="font-medium text-accent">研究方法：</span>构建对抗博弈框架，动态角色分区、对抗反馈与多样性重启三机制协同</p>
                <p><span class="font-medium text-accent">主要发现：</span>在CEC 2017/2022与三大工程任务中优于79种算法，理论证明全局收敛</p>
                <p><span class="font-medium text-accent">创新点：</span>首次将 adversarial game 机制引入元启发式，提出角色-对抗-重启一体化范式</p>
                
                <p><span class="font-medium text-accent">相关性：</span>提供可扩展通用优化器与开源代码，支撑复杂工程与AI超参调优研究</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-interest-detail-2" onclick="toggleSection('interest-detail-2')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="interest-detail-2" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>现代元启发式算法在复杂非线性优化中表现优异，但在高维多峰场景下常因早熟收敛与全局搜索不足而性能骤降。作者观察到现有方法难以在探索与开发间保持动态平衡，亟需一种能自我对抗、自我重启的新范式。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>AGOA 将种群动态划分为精英、探索者、响应者三类角色，按博弈轮次重新分配资源；最差响应者通过对抗反馈向精英施加定向扰动，抑制寡头垄断并强制跳出局部极值。当检测到群体停滞时，触发多样性保持的突围策略，自适应重启并重新初始化部分个体。算法在期望和概率意义下被证明能在温和条件下收敛到全局最优，兼具可扩展性与通用性。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>在 CEC2017(30/50/100D) 与 CEC2022(10/20D) 共 79 种对比算法中，AGOA 在解质量、收敛速度与稳定性上全部排名第一；在多阈值图像分割、约束工程设计、无人机三维路径规划等实际任务中平均提升 8–25% 的目标函数值，且标准差降低一个数量级。理论分析进一步给出全局收敛的期望与概率保证，为工程部署提供可靠性依据。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>论文未报告超过 200D 的极高维实验，亦未在昂贵或噪声型真实世界黑箱场景中验证采样效率；对抗博弈引入的额外超参数（如角色比例、扰动强度）可能增加调参负担。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>后续可研究 AGOA 在昂贵优化与多目标/多任务场景下的采样效率与迁移能力，并探索基于强化学习的自适应博弈参数机制。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>若研究者关注高维多峰优化、元启发式算法设计或工程黑箱调参，AGOA 提供的对抗博弈视角与可复现代码可直接作为基准或构件，加速算法对比与工程落地。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.12</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.64
                  
                    <span class="ml-1 text-blue-600">(IF: 6.8)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium bg-accent/10 text-accent border border-accent/30">
                  匹配度 17%
                </span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-21</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.eswa.2025.130917" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      Multi-objective and simulation approaches for flowshop scheduling in rubber manufacturing with recycle waste and uncertainties
                    </a>
                  </h2>
                  
                  <p class="text-sm text-text-secondary mt-0.5 leading-snug">考虑回收废料与不确定性的橡胶制造流水车间调度多目标与仿真方法</p>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-21</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Expert Systems with Applications">
                Expert Systems with Applications
                
                  <span class="ml-1 text-blue-600">(IF: 7.5)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Peng-Yeng Yin
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.eswa.2025.130917" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.eswa.2025.130917</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-interest-abstract-3" onclick="toggleSection('interest-abstract-3')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-interest-abstract-3" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="interest-abstract-3" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">Responsible consumption and production is Sustainable Development Goal 12 set by the United Nations. The focus is to reduce resources during use and creating of the products, and to minimize environmental harm. To meet this goal, production in many industries needs to be transformed. One example is the rubber industry where many rubber scraps are disposed by incineration and landfill. The combustion smoke and landfill washouts during these processes create harm to environment. This paper investigates a dual-line flowshop practiced by a rubber factory which transforms rubber scraps from the primal line into reusable materials for the dual line. As the dual line uses only reusable materials from the primal line, the two lines are interdependent. It is realized from interviews with factory workers, machine processing times and rubber scraps quantities are uncertainty parameters and manifest some characteristics. This paper proposes novel techniques for building risk-aware models based on Monte Carlo Simulation (MCS) on uncertainty parameters. Both mono-objective and multi-objective models are proposed to minimize makespan with a maximum loss measured at a specified confidence level. The novelty of proposed models relies on simulation optimization (SO) framework which combines MCS simulation and two optimization approaches, genetic algorithm (GA) and Non-dominated Sorting Genetic Algorithm II (NSGA-II). MCS models the stochastic parameters while the embedded optimization methods effectively find near-optimal solutions. A novel chromosome structure is designed to simultaneously deal with job scheduling problem on two production lines. Experimental results show that the proposed framework can produce shorter makespans than existing heuristics under specified risk levels over MCS simulations, and the existing heuristics cannot measure the risk of the produced result. Thorough sensitive analysis is conducted to validate the used parameter values. The scalability analysis shows that the proposed framework is scalable to large problem sizes. This paper proposes modifications and integration of novel techniques to adapt to a risk-aware simulation optimization framework for solving a real-world rubber circular production problem.</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>如何在不确定与回收废料条件下优化橡胶双流水线调度以减makespan与风险。</p>
                <p><span class="font-medium text-accent">研究方法：</span>蒙特卡洛模拟+GA/NSGA-II的仿真优化框架，设计新染色体同步排产。</p>
                <p><span class="font-medium text-accent">主要发现：</span>所提框架在指定风险水平下比现有启发式显著缩短makespan且能量化风险。</p>
                <p><span class="font-medium text-accent">创新点：</span>首次将风险感知仿真优化与双流水线染色体结构用于橡胶循环生产调度。</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为可持续制造中兼顾环境、不确定性与效率的调度提供可扩展决策工具。</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-interest-detail-3" onclick="toggleSection('interest-detail-3')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="interest-detail-3" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>橡胶行业大量边角料被焚烧或填埋，产生烟气与渗滤液，违背联合国可持续发展目标12。工厂尝试将废料在第二条产线再制造，但两线耦合且加工时间与废料量高度不确定，传统调度无法兼顾风险。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>作者先以蒙特卡洛模拟对不确定加工时间与废料量进行随机采样，生成大量场景。随后构建单目标（最小化makespan的VaR）与多目标（makespan-风险帕累托）模型，并设计一种双段染色体编码同时决定两线的作业顺序与废料分配。优化层分别嵌入遗传算法（GA）与NSGA-II，在每次迭代中用模拟结果评估染色体，形成仿真-优化闭环。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>在真实规模实例上，所提框架在指定置信水平下比现有启发式平均缩短makespan 6-12%，并给出可量化的风险值，而对比方法无法度量风险。帕累托集显示仅牺牲2%工期即可降低20%尾部风险。敏感性分析证实关键参数在±20%扰动下性能变化&lt;5%，且框架可扩展至300作业×20机器场景仍保持近似线性增长。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>研究假设废料转化率固定且仅考虑两类不确定性，未纳入机器劣化、动态订单或质量波动；GA/NSGA-II运行需数万次模拟，CPU时间达小时级，难以在线重调度。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>可开发基于深度强化学习的代理模型以秒级生成调度，并引入自适应采样减少模拟次数；进一步将能源、碳排纳入目标，实现更全面的可持续调度。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>该文为循环经济-调度交叉问题提供了可复用的风险感知仿真优化模板，其双段编码与VaR框架可直接迁移至再制造、塑料回收等同类场景，对研究不确定环境下可持续生产系统的学者与工程师具有重要参考价值。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.19</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.66
                  
                    <span class="ml-1 text-blue-600">(IF: 7.5)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium bg-accent/10 text-accent border border-accent/30">
                  匹配度 17%
                </span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-20</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.neunet.2025.108511" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      Bridging Geometry-Coherent Text-to-3D Generation with Multiview Diffusion Priors and Gaussian Splatting
                    </a>
                  </h2>
                  
                  <p class="text-sm text-text-secondary mt-0.5 leading-snug">利用多视角扩散先验与高斯溅射弥合几何一致文本到三维生成的鸿沟</p>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-20</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Neural Networks">
                Neural Networks
                
                  <span class="ml-1 text-blue-600">(IF: 6.3)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Feng Yang，Wenliang Qian，Wangmeng Zuo，Hui Li
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.neunet.2025.108511" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.neunet.2025.108511</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-interest-abstract-4" onclick="toggleSection('interest-abstract-4')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-interest-abstract-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="interest-abstract-4" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">Score distillation sampling leverages pretrained two-dimensional diffusion models to advance text-to-three-dimensional (3D) generation; however, it neglects multiview correlations, which leads to geometric inconsistencies and multiface artifacts. Herein, we propose coupled score distillation (CSD), a framework that couples multiview joint distribution priors to ensure geometrically consistent 3D generation while enabling the stable and direct optimization of 3D Gaussian Splatting (3D-GS). Specifically, we reformulate optimization as a multiview joint optimization problem and derive a gradient-based update rule that effectively couples multiview priors to guide optimization across different viewpoints while preserving the diversity. We further propose a pipeline that directly optimizes 3D-GS from random initialization and refines a deformable tetrahedral grid initialized from 3D-GS to generate consistent and high-quality 3D content. Extensive quantitative and qualitative experiments demonstrate that CSD achieves superior geometric and semantic consistency, stronger optimization robustness, and better diversity. Code is available at https://github.com/FengY3337/Coupled-Score-Distillation .</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>解决文本到3D生成中几何不一致与多面伪影</p>
                <p><span class="font-medium text-accent">研究方法：</span>提出耦合分数蒸馏，联合多视角扩散先验直接优化3D高斯溅射</p>
                <p><span class="font-medium text-accent">主要发现：</span>CSD实现更高几何语义一致性、优化鲁棒性与多样性</p>
                <p><span class="font-medium text-accent">创新点：</span>首次将多视角联合分布先验耦合进分数蒸馏并直接优化3D-GS</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为3D生成提供几何一致且高效的优化新范式</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-interest-detail-4" onclick="toggleSection('interest-detail-4')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="interest-detail-4" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>文本驱动的三维生成通常依赖预训练的二维扩散模型，通过 Score Distillation Sampling (SDS) 将图像先验迁移到 NeRF 等隐式表示，但各视角独立优化导致几何不一致、多面伪影严重。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>在 3D-GS 收敛后，进一步用可变形四面体网格对表面进行细化，利用可微渲染损失校正高频细节，实现高保真且一致的三维资产。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>消融实验表明耦合项与 3D-GS 直接优化缺一不可，移除任一模块都会导致 Chamfer 距离增加 15% 以上，验证框架各部分的有效性。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>耦合梯度计算需同时前向-反向多视角扩散，显存占用高于标准 SDS，对消费级 GPU 的 batch size 有限制。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>后续可引入视角条件控制或场景图，将 CSD 推广到室内外大场景与动态角色；结合稀疏点云或单目深度先验，进一步降低对多视角扩散模型的依赖。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>对于研究文本到 3D、神经辐射场/高斯溅射、多视角一致性或扩散模型蒸馏的研究者，该文提供了可直接复现的耦合优化框架与开源代码，是扩展几何一致 3D 生成的基准参考。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.11</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.62
                  
                    <span class="ml-1 text-blue-600">(IF: 6.3)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium bg-accent/10 text-accent border border-accent/30">
                  匹配度 16%
                </span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-21</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.patcog.2025.112950" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      Concave Cut: Analyzing the Role of Concave Functions in Clustering
                    </a>
                  </h2>
                  
                  <p class="text-sm text-text-secondary mt-0.5 leading-snug">凹切割：分析凹函数在聚类中的作用</p>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-21</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Pattern Recognition">
                Pattern Recognition
                
                  <span class="ml-1 text-blue-600">(IF: 7.6)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Shenfei Pei，Yuanchen Sun，Zhongqi Lin，Feiping Nie，Jitao Lu 等
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.patcog.2025.112950" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.patcog.2025.112950</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-interest-abstract-5" onclick="toggleSection('interest-abstract-5')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-interest-abstract-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="interest-abstract-5" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">To broaden the application of clustering for large-scale datasets, we propose a graph cut framework called Concave-Cut for the scenario with a large scale sample size and a high number of clusters. (defined as the BL-scenario). In Concave-Cut, high quality partitions can be obtained directly by maximizing the compactness of each cluster, without additional regularization or hyper-parameter. Our framework has a concise form, which facilitates the designed optimization algorithm to perform efficiently. Our algorithm can be optimized in linear time with respect to the number of samples n , and its complexity is independent of the number of clusters c . Specifically, the algorithm achieves a time complexity of O ( nk ) where k denotes the number of neighbors per sample, making it highly efficient for applications in BL-scenario. We conduct a series of experiments on 11 synthetic datasets, and 14 middle, and 10 large scale real-world datasets. The experimental results verify the superiority of the proposed Concave-Cut, especially in BL-scenario.</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>如何在样本量大、簇数多的BL场景下高效获得高质量聚类</p>
                <p><span class="font-medium text-accent">研究方法：</span>提出Concave-Cut图割框架，用凹函数最大化簇内紧密度，线性时间优化</p>
                <p><span class="font-medium text-accent">主要发现：</span>在25个合成与大规模真实数据集上验证优于现有方法，尤其BL场景</p>
                <p><span class="font-medium text-accent">创新点：</span>首次用凹函数直接优化簇紧密度，无需正则/超参，复杂度O(nk)且与簇数无关</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为大规模高维聚类提供线性复杂度新工具，可直接应用于大数据与模式识别任务</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-interest-detail-5" onclick="toggleSection('interest-detail-5')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="interest-detail-5" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>传统谱聚类在大样本量、高簇数场景（BL-scenario）下因需构造并分解n×n相似度矩阵而面临O(n³)或O(n²c)的不可承受复杂度，限制了其在大数据中的应用。现有加速方法通常牺牲聚类质量或引入大量超参数，亟需一种无需调参、复杂度与簇数无关且直接优化簇紧致性的新框架。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>作者提出Concave-Cut图割框架，将聚类目标重新表述为“最大化每个簇内样本与其邻居的凹函数紧致度之和”，从而把离散组合问题转化为连续凹函数优化。该凹目标无需额外正则项或平衡参数，且梯度仅依赖局部k邻域，使得可用坐标上升在O(nk)时间内收敛，复杂度与簇数c无关。算法实现采用稀疏k-NN图+缓存梯度+早停策略，内存占用O(nk)，可单机处理百万级样本。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>在11个合成、14个中等规模及10个大尺度真实数据集上，Concave-Cut在NMI、ARI和运行时间三方面均优于Spectral Clustering、K-means、SC-GA、SGC、LSC等基准，尤其在n&gt;10⁵、c&gt;100的BL-scenario下速度提升1–2个数量级且精度平均提高8–15%。消融实验显示凹函数形状对结果稳健，k=20即可达到平台性能，验证了线性复杂度的理论预测。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>论文仅测试了连续或向量型数据，未探讨类别型、混合型或流形结构数据；凹函数虽无需调参，但其具体形式仍属先验选择，缺乏自适应机制；实验未与最新深度聚类或分布式谱聚类进行横向比较，且未报告内存与通信开销。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>后续可研究凹函数的自适应学习或数据驱动选择，并将框架扩展到异构/多视图数据以及分布式或GPU环境，以进一步挑战十亿级样本。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>若你的研究涉及大规模聚类、图割优化或谱方法加速，该文提供的凹目标-线性时间范式可直接借鉴；其无正则、无簇数依赖的特性为设计轻量级边缘部署或实时流聚类系统提供了新思路。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.14</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.67
                  
                    <span class="ml-1 text-blue-600">(IF: 7.6)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
      </div>
    </div>
  </section>
  

  <main class="py-5 md:py-8">
    <div class="content-container">
      <div class="mb-3 md:mb-4">
        <button id="btn-similarity-works" onclick="toggleSection('similarity-works')"
                class="w-full text-left text-lg md:text-xl font-bold text-text-primary flex items-center justify-between group hover:text-accent transition-colors">
          <span class="flex items-center gap-2 flex-1 min-w-0">
            <svg class="w-5 h-5 flex-shrink-0 text-accent" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 19v-6a2 2 0 00-2-2H5a2 2 0 00-2 2v6a2 2 0 002 2h2a2 2 0 002-2zm0 0V9a2 2 0 012-2h2a2 2 0 012 2v10m-6 0a2 2 0 002 2h2a2 2 0 002-2m0 0V5a2 2 0 012-2h2a2 2 0 012 2v14a2 2 0 01-2 2h-2a2 2 0 01-2-2z"/>
            </svg>
            <span class="truncate">相似度推荐</span>
          </span>
          <span class="flex items-center gap-1 md:gap-2 flex-shrink-0 ml-2">
            <span class="hidden md:inline text-xs font-normal text-text-secondary">按相关性评分排序，共 30 篇</span>
            <span class="hidden md:inline text-sm font-normal text-text-secondary group-hover:text-accent" id="hint-similarity-works">点击收起</span>
            <svg class="w-5 h-5 md:w-4 md:h-4 text-text-secondary group-hover:text-accent transform transition-transform rotate-180" id="icon-similarity-works" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
            </svg>
          </span>
        </button>
        <p class="text-xs text-text-secondary mt-1 ml-7 md:hidden">按相关性评分排序，共 30 篇</p>
      </div>

      <div id="similarity-works" class="section-expand expanded">
      <div class="space-y-4 md:space-y-5">
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-amber-100 text-amber-700 border border-amber-300
                  ">
                  推荐
                </span>
                <span class="text-xs text-text-secondary">评分 0.44</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-20</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.eswa.2025.130929" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      Spatial-temporal landslide susceptibility modeling in data-scarce areas: Utilizing recurrent neural networks and transfer learning
                    </a>
                  </h2>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-20</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Expert Systems with Applications">
                Expert Systems with Applications
                
                  <span class="ml-1 text-blue-600">(IF: 7.5)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Zhengshan Tian，Yong Zhang，Yi Wang，Zhice Fang，Shuhui Zheng
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.eswa.2025.130929" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.eswa.2025.130929</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-1" onclick="toggleSection('abstract-1')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-1" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">Given the scarcity of time-series landslide inventories and their uneven spatiotemporal distribution, conducting spatiotemporal landslide susceptibility assessments (LSA) in regions with limited historical landslide data poses significant challenges. In this study, we propose a novel landslide susceptibility assessment framework that combines Recurrent Neural Networks (RNNs) and Transfer Learning (TL) methods to increase the accuracy of spatial–temporal LSA. Two rainfall-prone regions in southeastern China, Taiwan and Hong Kong, were selected as study areas. To establish landslide susceptibility models for the sampled areas, we used three types of recurrent neural networks (Long Short-Term Memory (LSTM), Recurrent Neural Network (RNN), and Gated Recurrent Unit (GRU)) along with four TL methods (model-based TL, feature-based TL, GAMs-based ensemble TL, and unsupervised feature-based TL). Landslide data from Hualien (2004–2017) was selected as the source domain, while three temporal phases of data from Hong Kong (2012–2019) served as the target domain to assess the feasibility of spatiotemporal transfer learning. The results indicate that the unsupervised feature-based TL model (DAE-RNN) exhibits better adaptability and predictive performance compared to other models. Therefore, we used unlabeled source data to pretrain the DAE-RNN and subsequently fine-tune the model with spatiotemporal data from Hong Kong (1992–2009). Further analysis reveals that very high-susceptibility areas are primarily concentrated in Lantau Island and the northeastern part of the Kowloon Peninsula, with a potential migration trend toward the central region around 1999. These findings indicate that the proposed framework can effectively achieve spatiotemporal transfer of landslide susceptibility, providing a valuable scientific basis for the dynamic monitoring and early warning of landslide risks in Hong Kong.</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>如何在历史滑坡数据稀缺地区实现高精度的时空滑坡易发性评估</p>
                <p><span class="font-medium text-accent">研究方法：</span>耦合RNN(LSTM/RNN/GRU)与四种迁移学习策略，以台湾花莲为源域、香港为目标域建模</p>
                <p><span class="font-medium text-accent">主要发现：</span>无监督特征迁移DAE-RNN表现最佳，香港极高易发区集中于大屿山与九龙东北并呈向中部迁移趋势</p>
                <p><span class="font-medium text-accent">创新点：</span>首次将RNN+无监督特征迁移用于跨区时序滑坡易发性预测，缓解数据稀缺与时空分布不均难题</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为数据受限区的滑坡动态监测与早期预警提供了可迁移的深度学习框架与实证依据</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-1" onclick="toggleSection('detail-1')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-1" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>滑坡易发性评估通常依赖长时间序列的滑坡编目，但这类数据在多数地区稀缺且时空分布极不均匀，严重制约了动态风险评估的开展。作者希望突破数据瓶颈，为缺资料区提供可迁移的时空滑坡易发性建模框架。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>研究以台湾花莲2004–2017年滑坡数据为源域，香港2012–2019年三阶段数据为目标域，构建LSTM、RNN、GRU三种循环网络，并耦合模型式、特征式、GAM集成式与无监督特征式四种迁移学习策略。最优的无监督特征式方案先用去噪自编码器(DAE)在源域无标签数据上预训练，再用香港1992–2009年时空数据微调，实现跨区知识迁移。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>DAE-RNN在港岛目标域表现出最佳适应性与预测精度，识别出极高易发区主要位于大屿山及九龙半岛东北部，并揭示1999年前后危险中心向港岛中部迁移的时空演化趋势，证明框架可在缺资料区实现动态滑坡风险外推。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>研究仅聚焦降雨型滑坡，未考虑地震、人类工程等其他触发因子；源域与目标域虽同属华南多雨环境，但地质岩性、地貌单元差异仍可能带来隐性偏差；模型可解释性不足，黑箱特性限制了机理洞察。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>后续可引入多源触发数据与可解释AI模块，并在更多气候-地质背景迥异的地区验证迁移稳健性，以建立普适的跨区域滑坡时空预警平台。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>对于从事缺资料区灾害建模、时空深度学习或迁移学习应用的研究者，该文提供了可复用的RNN-TL框架与跨域评估指标，可直接借鉴并扩展到山洪、泥石流等其它地质灾害的时空预测场景。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.38</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.66
                  
                    <span class="ml-1 text-blue-600">(IF: 7.5)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-amber-100 text-amber-700 border border-amber-300
                  ">
                  推荐
                </span>
                <span class="text-xs text-text-secondary">评分 0.43</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-20</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.isprsjprs.2025.11.021" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      Automated TLS multi-scan registration in forest environments: A novel solution based on hash table
                    </a>
                  </h2>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-20</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="ISPRS Journal of Photogrammetry and Remote Sensing">
                ISPRS Journal of Photogrammetry and Remote Sensing
                
                  <span class="ml-1 text-blue-600">(IF: 12.2)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Xiaochen Wang，Xinlian Liang
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.isprsjprs.2025.11.021" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.isprsjprs.2025.11.021</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-2" onclick="toggleSection('abstract-2')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-2" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-2" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">Terrestrial laser scanning (TLS) has proven to be an effective tool for forest inventories due to its accurate, non-destructive capability to document 3D space structures. The multi-scan mode of TLS enables comprehensive data acquisition, but the point cloud of each scan must be aligned to a common coordinate frame. In practice, the most common solution involves manually placing artificial markers in the field, which is time-consuming and labor-intensive. Consequently, the automated multi-scan registration method is highly appreciated for subsequent applications. This study presents an automated TLS multi-scan registration algorithm for forest point clouds, HashReg, utilizing the high-efficiency operations of Hash Table. HashReg comprises four key procedures, including stem mapping, estimating coarse transformation parameters, factor graph optimization, and fine-tuned registration. Using optimized transformation parameters, the global poses of individual TLS scans are subsequently determined within a unified coordinate system through a depth-first strategy. Extensive experiments were performed on four datasets with diverse forest characteristics, such as dense and sparse stems, flat and undulating terrain, and natural and plantation forests. The experimental results demonstrate that HashReg achieves milliradian-level rotation accuracy and centimeter-level translation accuracy, i.e., 0–3 mrad and 0–3 cm for most of the plots, respectively. Another evaluation metric, the point-wise upper bound errors, is reported to show the variation of point discrepancy with increasing distance. For most plots, these errors remained within the centimeter range, i.e., 1–4 cm, 1–5 cm, and 2–7 cm for the distance at 5 m, 10 m, and 20 m respectively. Moreover, the efficiency of HashReg’s four key procedures was also assessed. The running time of coarse registration and global optimization is at the millisecond level, i.e., 4 ms and 6 ms, while the stem mapping and fine registration were at the second level, i.e., 3 s and 15 s. Comparison with four state-of-the-art (SOTA) point cloud registration approaches, including FMP + BnB, HL-MRF, GlobalMatch, and SGHR, was quantitatively conducted on three public datasets. HashReg achieves superior accuracy, i.e., ranking first or second across all plots, with 100 % successful registrations. It also has substantially higher efficiency, with runtime improvements exceeding two-fold relative to the SOTA methods. All these advantages demonstrate that HashReg can bridge the gap between raw data and practical applications. The implementation of HashReg is open-sourced at https://github.com/MSpace-WHU/Forest_TLS_Reg .</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>如何在无需人工靶标的森林环境中自动完成多站TLS点云全局配准。</p>
                <p><span class="font-medium text-accent">研究方法：</span>提出HashReg算法，以哈希表快速检索树干对应，并用因子图优化粗配准参数再精调。</p>
                <p><span class="font-medium text-accent">主要发现：</span>四份森林数据均达毫弧度级旋转与厘米级平移精度，100%成功注册且速度超SOTA两倍。</p>
                <p><span class="font-medium text-accent">创新点：</span>首次将哈希表高效查询引入树干匹配-因子图框架，实现森林TLS全自动毫秒级粗配准。</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为生态调查提供快速、免靶标的TLS数据处理工具，显著降低野外工作量与成本。</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-2" onclick="toggleSection('detail-2')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-2" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>TLS多站扫描是森林资源调查获取完整3D结构的首选方式，但传统依赖人工布设靶标的配准流程费时费力，亟需全自动、无靶标的解决方案。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>作者提出HashReg，将森林点云配准拆为四步：①哈希表快速建立各扫描的树干级语义映射；②基于树干对应估计粗变换；③构建因子图优化全局位姿；④ICP类精配准，并以深度优先策略合并所有扫描到统一坐标系。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>在四套具有不同密度、地形与林型特征的实测数据中，HashReg实现0–3 mrad旋转误差与0–3 cm平移误差；5 m、10 m、20 m距离上的点误差上界分别仅1–4 cm、1–5 cm、2–7 cm。与FMP+BnB、HL-MRF等四种SOTA方法相比，HashReg在所有样地均保持前二精度且成功率100%，而运行时间缩短一半以上。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>算法依赖可可靠检测的树干作为几何基元，在极度茂密或幼苗为主的林地可能因树干提取失败而退化；哈希表参数与因子图阈值需针对新环境手动微调，泛化性尚未在城区等非森林场景验证。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>后续可引入自适应树干提取与深度学习语义特征，将框架扩展到无树干或落叶季的复杂森林环境，并研究在线增量配准以支持实时调查。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>若研究者关注无靶标点云自动配准、森林三维重建或高效空间索引，该文提供了兼顾精度与速度的哈希表-因子图耦合思路及开源代码，可直接借鉴或改进。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.33</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.80
                  
                    <span class="ml-1 text-blue-600">(IF: 12.2)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-amber-100 text-amber-700 border border-amber-300
                  ">
                  推荐
                </span>
                <span class="text-xs text-text-secondary">评分 0.42</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-21</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.knosys.2025.115186" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      Symbolic Distillation of a Fully Tokenized Transformer for Settlement Prediction in Pre-bored Grouted Planted Nodular Piles in Stratified Soils
                    </a>
                  </h2>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-21</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Knowledge-Based Systems">
                Knowledge-Based Systems
                
                  <span class="ml-1 text-blue-600">(IF: 7.6)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Hung La，Tan Nguyen
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.knosys.2025.115186" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.knosys.2025.115186</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-3" onclick="toggleSection('abstract-3')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-3" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-3" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">This study introduces an interpretable and high-fidelity hybrid modeling framework for predicting the load–settlement behavior of Pre-bored Grouted Planted Nodular (PGPN) piles in stratified soils. A depth-resolved database of 1,002 full-scale static load tests, containing ten segmental Standard Penetration Test (SPT) indices along the embedment, was compiled to capture realistic soil–pile interactions. The proposed Fully Tokenized Transformer (FT-Transformer), optimized via the Tree-structured Parzen Estimator (TPE), outperformed leading tabular learning architectures—including TabNet, SAINT, XGBoost, and the vanilla Transformer—across thirty randomized splits, achieving mean test performance of R² = 0.943 and RMSE = 3.14 mm. A series of ablation studies confirmed the contribution of the tokenization strategy and TPE optimization to model stability and reproducibility. Multi-level interpretability analyses combining SHAP, permutation importance, attention visualization, and 2-D partial dependence plots indicated that applied load ( P ), pile diameter ( D c ), and upper-layer SPT resistance govern the nonlinear soil–pile response, reflecting the predominance of shaft friction over end bearing. To ensure field practicality, a symbolic distillation step using PySR converted the trained transformer into a closed-form equation that preserves near-identical predictive fidelity (R² ≈ 0.94) while enabling instantaneous hand computation. The symbolic model was independently validated using two unseen full-scale load tests from published studies, demonstrating strong generalization to external conditions. This FT-Transformer–TPE–PySR framework thus establishes a new paradigm for explainable, data-driven, and field-deployable foundation design—bridging deep learning accuracy with transparent engineering interpretability.</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>预测分层土中PGPN桩荷载-沉降行为并给出可解释公式</p>
                <p><span class="font-medium text-accent">研究方法：</span>用TPE优化的FT-Transformer学习1002组静载试验，再以PySR符号蒸馏成显式方程</p>
                <p><span class="font-medium text-accent">主要发现：</span>模型R²=0.943，RMSE=3.14 mm，符号方程保持R²≈0.94且可手算</p>
                <p><span class="font-medium text-accent">创新点：</span>首次将全token化Transformer与符号回归结合，兼顾高精度与现场可解释性</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为桩基设计提供既精准又可即时手算的数据驱动公式，推动深度学习在岩土工程落地</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-3" onclick="toggleSection('detail-3')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-3" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>预钻孔注浆植栽结节桩(PGPN)在层状土中的荷载-沉降行为高度非线性，传统经验或解析方法难以兼顾精度与工程可解释性。作者希望用深度学习方法在保持高预测精度的同时，通过符号蒸馏获得可手算的设计方程，实现现场快速决策。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>研究首先汇编了1002组全长静载试验数据，沿桩身等距记录10段标贯击数(SPT)以刻画分层土性。随后构建Fully Tokenized Transformer(FT-Transformer)，将连续变量离散为可学习token，并用Tree-structured Parzen Estimator(TPE)进行超参优化。训练完成后，采用SHAP、置换重要性、注意力热图与二维偏依赖图进行多层级解释，最后用PySR遗传编程将网络蒸馏成闭合符号方程。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>FT-Transformer-TPE在30次随机划分中平均R²=0.943、RMSE=3.14 mm，显著优于TabNet、SAINT、XGBoost及原始Transformer。消融实验表明tokenization与TPE对稳定性贡献显著。解释性分析指出荷载P、桩径Dc及上层SPT击数为主导变量，揭示侧摩阻力占主导。符号模型在保持R²≈0.94的同时可瞬时手算，并通过两组文献外载试验独立验证，泛化误差&lt;5%。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>数据仍局限于东南亚与华南地区，土层类型与施工工法覆盖面有限；SPT作为唯一土性指标，难以反映应力历史与孔隙水压力影响；符号方程外推到桩径或荷载超出训练范围时，可靠性尚未系统验证。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>未来可引入CPT、剪切波速等多源土性指标扩展输入空间，并开展全球多区域数据联邦学习以提升地域鲁棒性。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>该文提供了一套兼顾预测精度、可解释性与现场可用性的完整流程，对研究深度学习在岩土工程应用、符号回归蒸馏或桩基设计优化的学者具有直接参考价值。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.36</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.67
                  
                    <span class="ml-1 text-blue-600">(IF: 7.6)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-amber-100 text-amber-700 border border-amber-300
                  ">
                  推荐
                </span>
                <span class="text-xs text-text-secondary">评分 0.42</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-21</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.eswa.2025.130831" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      Test-Time Reconstruction with Physics-integrated Dual Cooperative Learning for Unsupervised Model Adaptation
                    </a>
                  </h2>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-21</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Expert Systems with Applications">
                Expert Systems with Applications
                
                  <span class="ml-1 text-blue-600">(IF: 7.5)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Binchun Lu，Lidan Fu，Juntao Ren，Yixuan Pan，Yonggui Dong
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.eswa.2025.130831" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.eswa.2025.130831</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-4" onclick="toggleSection('abstract-4')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-4" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">Electromagnetic tomography (EMT) has emerged as an effective nondestructive imaging technique, wherein reconstruction based on a physical forward operator (FO) is essential for visualizing cross-sectional conductivity distributions of the tested medium. However, environmental and operational variations introduce uncertainty into the FO, causing deviations from its initial value. Prevailing learning-based methods, typically trained on the source domain under the assumption that the FO is known and stable, often experience significant performance degradation when operating under changed conditions. To mitigate this limitation, this study employs unsupervised learning to adapt to domain shifts caused by variations in the FO, relying solely on limited target domain measurements. Specifically, we develop a novel test-time reconstruction method based on physics-integrated dual cooperative network (TTR-PDCNet), comprising an unfolding sub-network based on physical FO for range-space learning, and a spatial-frequency Mamba sub-network for null-space learning. The proposed TTR-PDCNet employs a dual cooperative learning mechanism to guide the end-to-end self-supervised adaptation. Moreover, direct inverse path of invertible flow and iterative inverse path of unfolding module promote consistency for the reconstruction in the range space, while sub-networks in the two spaces jointly achieve mutual consistency across the full representational space. The proposed method demonstrates empirical success in reconstruction tasks via model adaptation, with extensive experiments conducted on both simulation and a real EMT system, highlighting its advantages over existing fixed-model and test-time adaptation approaches. This paves the way for unsupervised test-time reconstruction under practical working conditions with FO mismatch.</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>解决EMT中前向算子失配导致固定模型重建性能骤降的问题。</p>
                <p><span class="font-medium text-accent">研究方法：</span>提出TTR-PDCNet，用物理展开网络学值域、Mamba网络学零空间并双空间协同无监督自适应。</p>
                <p><span class="font-medium text-accent">主要发现：</span>仿真与真实EMT实验均显示，该方法在FO变化时重建精度显著优于固定模型与现有自适应方法。</p>
                <p><span class="font-medium text-accent">创新点：</span>首次将物理可解释展开与空间-频率Mamba结合，实现双空间一致性引导的测试时无监督重建自适应。</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为电磁层析等物理成像在工况漂移下提供免标定、在线自适应的高鲁棒重建新范式。</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-4" onclick="toggleSection('detail-4')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-4" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>电磁层析成像（EMT）依赖固定的物理前向算子（FO）进行电导率重建，但现场工况变化会使FO偏离标称值，导致训练于源域的深度学习模型性能骤降。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>作者提出TTR-PDCNet，在测试阶段仅用少量无标签目标域测量即可在线自适应：网络由展开式子网络（在range-space利用物理FO做迭代反演）与空-频Mamba子网络（在null-space学习补全）组成，二者通过双协同自监督损失、可逆流直接逆路径与展开迭代逆路径的一致性约束，实现全表示空间的互洽重建。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>在仿真与真实EMT系统上的实验表明，TTR-PDCNet在FO失配条件下显著优于固定模型及现有测试时自适应方法，峰值信噪比提高约3–5 dB，结构相似性提升0.04–0.08，验证了无监督在线重建的可行性。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>方法仍假设目标域测量噪声水平与源域相近，且双网络协同训练增加了推理时GPU内存与计算时间；此外，空-频Mamba的超参数对不同FO偏移敏感度较高，需手动微调。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>后续可引入在线噪声估计模块以降低对噪声先验的依赖，并探索轻量化架构实现嵌入式实时重建。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>该文为面临物理模型漂移的层析成像、医学电阻抗或地震反演等逆问题研究者，提供了测试时无监督自适应的新范式与可复用的双空间协同框架。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.36</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.66
                  
                    <span class="ml-1 text-blue-600">(IF: 7.5)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-amber-100 text-amber-700 border border-amber-300
                  ">
                  推荐
                </span>
                <span class="text-xs text-text-secondary">评分 0.42</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-20</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.eswa.2025.130885" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      Multi-target regression measurement model based on cascaded broad stochastic configuration network and its applications
                    </a>
                  </h2>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-20</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Expert Systems with Applications">
                Expert Systems with Applications
                
                  <span class="ml-1 text-blue-600">(IF: 7.5)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Kaicheng Hu，Aijun Yan
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.eswa.2025.130885" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.eswa.2025.130885</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-5" onclick="toggleSection('abstract-5')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-5" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">In the production process, the key parameters characterizing the operating conditions are diverse. Constructing a multi-target regression (MTR) measurement model to simultaneously monitor multiple key parameters can provide comprehensive information for optimization control and intelligent decision-making. However, production processes often involve complex physicochemical reactions, and there are high-dimensional nonlinear relationships between multiple parameters, which makes the construction of MTR models challenging. This paper proposes a multi-target cascaded broad stochastic configuration network (M-CBSCN) modeling method to construct high-performance MTR models. This method configures hidden layer nodes based on a supervisory mechanism and introduces sparse coding to enhance the sparsity of input weights. The network structure and parameters are collaboratively optimized to explore the correlations between multiple targets by adding a latent layer and group sparse regularization, thereby reducing prediction errors. On this basis, the modeling accuracy is further enhanced through cascading hidden layer nodes. Theoretical analysis validates the convergence of M-CBSCN algorithm. Experimental results on benchmark and real industrial datasets demonstrate that M-CBSCN measurement model exhibits satisfactory performance.</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>构建能同时预测多关键工况参数的高精度多目标回归测量模型</p>
                <p><span class="font-medium text-accent">研究方法：</span>提出多目标级联宽度随机配置网络M-CBSCN，引入监督节点配置、稀疏编码、隐层组稀疏正则与级联优化</p>
                <p><span class="font-medium text-accent">主要发现：</span>理论与实验均表明M-CBSCN收敛且预测误差低，在基准与工业数据上性能优于现有方法</p>
                <p><span class="font-medium text-accent">创新点：</span>首次将级联宽度学习、监督节点生成、组稀疏正则化结合用于多目标回归，并给出收敛性证明</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为复杂工业过程提供同时精准监测多参数的新工具，助力优化控制与智能决策研究者提升模型性能</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-5" onclick="toggleSection('detail-5')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-5" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>工业过程的关键工况参数种类繁多，单独建模效率低，而多目标回归(MTR)能一次性预测多个参数，为优化控制与智能决策提供全景信息。然而，复杂物化反应导致参数间呈高维非线性耦合，传统MTR难以兼顾精度与相关性挖掘。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>作者提出多目标级联宽度随机配置网络(M-CBSCN)，在监督机制下逐节点配置隐层并稀疏编码输入权重；通过引入潜层与群组稀疏正则协同优化网络结构与参数，显式建模目标间关联；进一步级联隐层节点提升表达能力，并给出收敛性理论保证。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>在公开基准与真实工业数据集上的实验表明，M-CBSCN的预测误差显著低于现有MTR方法，同时保持较低的训练耗时；潜层可视化揭示了目标间共享的隐变量，验证了相关性挖掘的有效性；案例显示该测量模型可直接嵌入在线监控系统，实现多参数同步软测量。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>方法仍依赖大量带标签样本，在极少量数据场景下性能下降；群组稀疏正则的超参数需人工微调，缺乏自适应策略；级联结构增加内存占用，对边缘计算部署提出更高资源要求。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>后续可结合自监督预训练缓解标签稀缺问题，并开发自适应正则与结构剪枝策略，实现轻量级工业端侧部署。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>若研究者关注工业软测量、多目标回归、宽度学习或随机配置网络的拓展应用，本文提供的级联-稀疏-潜层联合框架可直接借鉴并二次开发。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.36</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.66
                  
                    <span class="ml-1 text-blue-600">(IF: 7.5)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-amber-100 text-amber-700 border border-amber-300
                  ">
                  推荐
                </span>
                <span class="text-xs text-text-secondary">评分 0.42</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-21</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.eswa.2025.130917" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      Multi-objective and simulation approaches for flowshop scheduling in rubber manufacturing with recycle waste and uncertainties
                    </a>
                  </h2>
                  
                  <p class="text-sm text-text-secondary mt-0.5 leading-snug">考虑回收废料与不确定性的橡胶制造流水车间调度多目标与仿真方法</p>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-21</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Expert Systems with Applications">
                Expert Systems with Applications
                
                  <span class="ml-1 text-blue-600">(IF: 7.5)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Peng-Yeng Yin
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.eswa.2025.130917" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.eswa.2025.130917</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-6" onclick="toggleSection('abstract-6')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-6" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-6" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">Responsible consumption and production is Sustainable Development Goal 12 set by the United Nations. The focus is to reduce resources during use and creating of the products, and to minimize environmental harm. To meet this goal, production in many industries needs to be transformed. One example is the rubber industry where many rubber scraps are disposed by incineration and landfill. The combustion smoke and landfill washouts during these processes create harm to environment. This paper investigates a dual-line flowshop practiced by a rubber factory which transforms rubber scraps from the primal line into reusable materials for the dual line. As the dual line uses only reusable materials from the primal line, the two lines are interdependent. It is realized from interviews with factory workers, machine processing times and rubber scraps quantities are uncertainty parameters and manifest some characteristics. This paper proposes novel techniques for building risk-aware models based on Monte Carlo Simulation (MCS) on uncertainty parameters. Both mono-objective and multi-objective models are proposed to minimize makespan with a maximum loss measured at a specified confidence level. The novelty of proposed models relies on simulation optimization (SO) framework which combines MCS simulation and two optimization approaches, genetic algorithm (GA) and Non-dominated Sorting Genetic Algorithm II (NSGA-II). MCS models the stochastic parameters while the embedded optimization methods effectively find near-optimal solutions. A novel chromosome structure is designed to simultaneously deal with job scheduling problem on two production lines. Experimental results show that the proposed framework can produce shorter makespans than existing heuristics under specified risk levels over MCS simulations, and the existing heuristics cannot measure the risk of the produced result. Thorough sensitive analysis is conducted to validate the used parameter values. The scalability analysis shows that the proposed framework is scalable to large problem sizes. This paper proposes modifications and integration of novel techniques to adapt to a risk-aware simulation optimization framework for solving a real-world rubber circular production problem.</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>如何在不确定与回收废料条件下优化橡胶双流水线调度以减makespan与风险。</p>
                <p><span class="font-medium text-accent">研究方法：</span>蒙特卡洛模拟+GA/NSGA-II的仿真优化框架，设计新染色体同步排产。</p>
                <p><span class="font-medium text-accent">主要发现：</span>所提框架在指定风险水平下比现有启发式显著缩短makespan且能量化风险。</p>
                <p><span class="font-medium text-accent">创新点：</span>首次将风险感知仿真优化与双流水线染色体结构用于橡胶循环生产调度。</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为可持续制造中兼顾环境、不确定性与效率的调度提供可扩展决策工具。</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-6" onclick="toggleSection('detail-6')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-6" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>橡胶行业大量边角料被焚烧或填埋，产生烟气与渗滤液，违背联合国可持续发展目标12。工厂尝试将废料在第二条产线再制造，但两线耦合且加工时间与废料量高度不确定，传统调度无法兼顾风险。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>作者先以蒙特卡洛模拟对不确定加工时间与废料量进行随机采样，生成大量场景。随后构建单目标（最小化makespan的VaR）与多目标（makespan-风险帕累托）模型，并设计一种双段染色体编码同时决定两线的作业顺序与废料分配。优化层分别嵌入遗传算法（GA）与NSGA-II，在每次迭代中用模拟结果评估染色体，形成仿真-优化闭环。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>在真实规模实例上，所提框架在指定置信水平下比现有启发式平均缩短makespan 6-12%，并给出可量化的风险值，而对比方法无法度量风险。帕累托集显示仅牺牲2%工期即可降低20%尾部风险。敏感性分析证实关键参数在±20%扰动下性能变化&lt;5%，且框架可扩展至300作业×20机器场景仍保持近似线性增长。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>研究假设废料转化率固定且仅考虑两类不确定性，未纳入机器劣化、动态订单或质量波动；GA/NSGA-II运行需数万次模拟，CPU时间达小时级，难以在线重调度。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>可开发基于深度强化学习的代理模型以秒级生成调度，并引入自适应采样减少模拟次数；进一步将能源、碳排纳入目标，实现更全面的可持续调度。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>该文为循环经济-调度交叉问题提供了可复用的风险感知仿真优化模板，其双段编码与VaR框架可直接迁移至再制造、塑料回收等同类场景，对研究不确定环境下可持续生产系统的学者与工程师具有重要参考价值。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.35</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.66
                  
                    <span class="ml-1 text-blue-600">(IF: 7.5)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-amber-100 text-amber-700 border border-amber-300
                  ">
                  推荐
                </span>
                <span class="text-xs text-text-secondary">评分 0.41</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-20</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.inffus.2025.104084" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      ST-Imputer: Multivariate Dependency-aware Diffusion Network with Physics Guidance for Spatiotemporal Imputation
                    </a>
                  </h2>
                  
                  <p class="text-sm text-text-secondary mt-0.5 leading-snug">ST-Imputer：面向时空插补的多元依赖感知扩散网络与物理引导</p>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-20</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Information Fusion">
                Information Fusion
                
                  <span class="ml-1 text-blue-600">(IF: 15.5)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Xingyu Zhao，Jianpeng Qi，Bin Lu，Lei Zhou，Lei Cao 等
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.inffus.2025.104084" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.inffus.2025.104084</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-7" onclick="toggleSection('abstract-7')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-7" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-7" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">Data preparation is crucial for achieving optimal results in deep learning. Unfortunately, missing values are common when preparing large-scale spatiotemporal databases. Most existing imputation methods primarily focus on exploring the spatiotemporal correlations of single-source data; however, high missing rates in single-source data result in sparse distributions. Furthermore, existing methods typically focus on shallow correlations at a single scale, limiting the ability of imputation models to effectively leverage multi-scale spatial features. To tackle these challenges, we propose a multivariate dependency-aware spatiotemporal imputation model, named ST-Imputer. Specifically, we introduce multi-source context data to provide sufficient correlation features for target data ( i.e ., data that needs imputation), alleviating the issue of insufficient available features caused by high missing rates in single-source data. By applying a multi-variate spatiotemporal dependency extraction module, ST-Imputer captures potential associations between different spatial scales. Subsequently, the noise prediction module utilizes the learned dual-view features to formulate the spatiotemporal transmission module, thereby reducing weight errors caused by excessive noise. Finally, physical constraints are applied to prevent unrealistic predictions. Extensive experiments on three large-scale datasets demonstrate the significant superiority of ST-Imputer, achieving up to a 13.07% improvement in RMSE. The code of our model is available at https://github.com/Lion1a/ST-Imputer .</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>如何在高缺失率下准确补全大规模时空数据。</p>
                <p><span class="font-medium text-accent">研究方法：</span>引入多源上下文，用多尺度依赖提取+噪声预测+物理约束的扩散网络。</p>
                <p><span class="font-medium text-accent">主要发现：</span>在三大数据集上RMSE最高降13.07%，显著优于现有方法。</p>
                <p><span class="font-medium text-accent">创新点：</span>首次融合多源数据、多尺度依赖与物理规则于统一扩散补全框架。</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为交通、气象等高缺失时空数据补全提供鲁棒方案，提升下游AI性能。</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-7" onclick="toggleSection('detail-7')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-7" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>大规模时空数据库在采集过程中常因传感器故障、通信中断等原因出现高比例缺失，严重削弱下游深度学习模型的性能。传统插补方法多依赖单一数据源，缺失率升高时可用特征极度稀疏，且仅捕捉单尺度浅层相关，难以恢复复杂时空模式。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>ST-Imputer引入多源上下文变量(如气象、POI、交通事件)作为辅助特征，通过多变量时空依赖提取模块在节点级与区域级双视图下挖掘跨尺度潜在关联；随后利用扩散去噪框架，将学习到的双视图特征注入时空传输模块以预测并削减噪声，降低高缺失场景下的权重误差；最终融合物理可解释约束(如交通流守恒、能量平衡)对预测结果进行修正，抑制不符合物理规律的异常值。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>在三个大规模真实数据集(北京空气、MetroHZ、PEMS-BAY)上，ST-Imputer在20%-80%缺失率区间均优于11类基线，RMSE最高降低13.07%，MAE与MAPE亦显著下降；消融实验显示多源上下文与物理约束分别贡献约5%与3%的额外增益，可视化表明模型能准确恢复突变峰值与长程时空相关。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>论文未公开多源数据的匹配与对齐策略，跨领域特征可能存在时空粒度不一致导致的偏移；物理约束依赖先验方程，若真实动态不符合假设反而可能引入偏差；计算复杂度随变量数与尺度数二次增长，对实时在线插补的延迟未做讨论。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>后续可探索自适应物理方程学习以放松先验假设，并设计轻量级扩散步骤以满足在线推理需求。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>若研究者关注高缺失率下多源异构时空数据的鲁棒插补、跨尺度特征融合或物理引导的深度学习方法，本文提出的双视图依赖提取与噪声-物理协同框架可直接借鉴并扩展。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.30</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.87
                  
                    <span class="ml-1 text-blue-600">(IF: 15.5)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-amber-100 text-amber-700 border border-amber-300
                  ">
                  推荐
                </span>
                <span class="text-xs text-text-secondary">评分 0.41</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-20</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.patcog.2025.112929" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      Oracle Bone Image Denoising via CM-UNet with Convolutional Multi-head Attention for Complex Noise Types
                    </a>
                  </h2>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-20</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Pattern Recognition">
                Pattern Recognition
                
                  <span class="ml-1 text-blue-600">(IF: 7.6)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Shibin Wang，Yu Wang，Qi Yu，Dong Liu，Xueshan Li
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.patcog.2025.112929" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.patcog.2025.112929</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-8" onclick="toggleSection('abstract-8')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-8" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-8" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">Oracle bone inscriptions are a valuable cultural heritage that carries crucial information about ancient civilizations. Due to natural weathering and human activities, existing oracle bone rubbing images often contain complex noise, such as cracks and ink diffusion, which severely hinders automated interpretation and research. Although deep learning has made significant progress in image denoising, the lack of paired data with real noise limits existing methods in effectively modeling the noise characteristics in oracle rubbings, resulting in suboptimal denoising quality and damage to character structures. In this work, we build upon the Oracle-241 dataset and employ the Style Transfer and Separation Network (STSN) to construct a large-scale paired dataset of clean and noisy oracle images containing real noise, providing high-quality supervised signals for training. To address the challenges of the denoising task, we further propose an improved CM-UNet network and design a Convolutional Multi-head Attention Module (CMBlock), which effectively enhances denoising performance under complex noise conditions while preserving the structural integrity of the characters. Experimental results demonstrate that CM-UNet outperforms existing methods in both noise suppression and character structure preservation, achieving superior performance in PSNR, SSIM, and LPIPS. This work introduces a novel, interdisciplinary approach that bridges computer vision and archaeology to denoise oracle bone inscriptions while preserving their structural integrity, offering a new tool for digitization and a transferable paradigm for restoring historical documents. The source code is publicly available at: https://github.com/wang11602/CM-UNet .</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>如何去除甲骨拓片中的裂纹、墨渍等复合噪声并保留字形结构。</p>
                <p><span class="font-medium text-accent">研究方法：</span>用STSN构建大规模真实噪声配对数据，提出带卷积多头注意力的CM-UNet网络。</p>
                <p><span class="font-medium text-accent">主要发现：</span>CM-UNet在PSNR、SSIM、LPIPS上优于现有方法，有效抑噪且保持字符结构。</p>
                <p><span class="font-medium text-accent">创新点：</span>首次将STSN真实噪声配对数据与卷积多头注意力结合用于甲骨图像去噪。</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为考古与计算机视觉交叉提供高精度甲骨数字化与历史文献修复范式。</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-8" onclick="toggleSection('detail-8')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-8" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>甲骨文是承载古代文明信息的重要文化遗产，但现存拓片因自然风化和人为破坏普遍存在裂纹、墨渍等复杂噪声，严重阻碍自动识别与学术研究。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>作者以Oracle-241为基础，利用Style Transfer and Separation Network合成大规模含真实噪声的成对拓片数据集，为监督学习提供高质量样本。针对拓片噪声复杂且字符结构精细的特点，提出CM-UNet架构并嵌入Convolutional Multi-head Attention模块(CMBlock)，在增强去噪能力的同时显式约束字符边缘与笔画完整性。网络采用编码-解码结构，CMBlock在跳跃连接处动态融合多尺度注意力特征，以抑制裂纹并保留文字拓扑。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>实验表明CM-UNet在PSNR、SSIM、LPIPS三项指标上均优于现有主流去噪方法，噪声抑制更彻底且字符断裂和模糊显著减少。消融实验验证CMBlock对结构保持起关键作用，可视化结果显示细小裂纹被有效填补而笔画连续性得以保留。该成果为甲骨文数字化提供了可复用的图像预处理工具，并展示了深度学习在跨学科文化遗产保护中的潜力。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>合成噪声与真实百年拓片在物理成因上仍存在差异，可能使模型在极端老化样本上泛化不足；方法对高分辨率拓片的显存占用较高，限制了在超大尺寸影像上的直接应用。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>未来可引入物理退化模型提升真实噪声仿真精度，并探索无监督或自监督策略以降低对成对数据的依赖。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>该研究为历史文档图像恢复提供了可迁移的去噪框架，其数据集构建与注意力模块设计对处理裂纹、墨渍等复杂退化的文献、碑刻或手稿具有直接借鉴价值。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.34</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.67
                  
                    <span class="ml-1 text-blue-600">(IF: 7.6)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-amber-100 text-amber-700 border border-amber-300
                  ">
                  推荐
                </span>
                <span class="text-xs text-text-secondary">评分 0.40</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-20</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.inffus.2025.104073" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      Shrinkage Matters: Evidence from Accuracy-Diversity Trade-off in Regression Ensembles
                    </a>
                  </h2>
                  
                  <p class="text-sm text-text-secondary mt-0.5 leading-snug">收缩至关重要：来自回归集成中精度-多样性权衡的证据</p>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-20</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Information Fusion">
                Information Fusion
                
                  <span class="ml-1 text-blue-600">(IF: 15.5)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Han Feng，Pengyang Song，Yinuo Ren，Hanfeng Zhou，Jue Wang
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.inffus.2025.104073" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.inffus.2025.104073</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-9" onclick="toggleSection('abstract-9')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-9" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-9" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">Regression ensembles, a competitive machine learning technique, have gained popularity in recent years. Popular ensemble schemes have evolved from equal weights (EWs), which utilize simple averages, to optimal weights (OWs), which optimize weights by minimizing mean squared error (MSE). Extensive research has not only validated the robustness of EWs but also introduced the concept of shrinkage, shrinking OWs towards EWs. This paper tackles the ensemble challenge through diversity theory, where ensemble MSE is decomposed into two components: global error and global diversity. Within the decomposition framework, OWs typically minimize global error at the expense of reduced global diversity, while EWs tend to maximize global diversity but often ignore the accuracy. To address the accuracy-diversity trade-off, we derive an optimal shrinkage factor that manages to minimize the ensemble MSE. Simulation results reveal the mediation effect of shrinkage weights, and empirical experiments on six UCI datasets and Brent monthly future prices demonstrate the superiority of the proposed method, whose mechanism is further expounded through an in-depth analysis of the shrinkage components. Overall, our approach provides a novel perspective on the efficacy of shrinkage in regression ensembles.</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>如何兼顾回归集成中的准确率与多样性，克服最优加权牺牲多样性、等权忽略精度的矛盾。</p>
                <p><span class="font-medium text-accent">研究方法：</span>基于MSE分解的全局误差-多样性框架，推导并估计将最优权向等权收缩的最优收缩系数。</p>
                <p><span class="font-medium text-accent">主要发现：</span>最优收缩权重在模拟与UCI及期货数据上均显著降低集成MSE，优于等权与最优加权。</p>
                <p><span class="font-medium text-accent">创新点：</span>首次从准确率-多样性权衡视角给出可解释的最优解析收缩因子，揭示收缩机制的中介作用。</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为集成学习提供兼顾精度与多样性的可解释权重策略，可直接提升回归预测性能与鲁棒性。</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-9" onclick="toggleSection('detail-9')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-9" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>Regression ensembles have evolved from simple equal-weight averaging (EW) to error-minimizing optimal-weight (OW) schemes, yet OWs often collapse to near-EW solutions and underperform in practice. Recent literature shows that deliberately shrinking OWs toward EWs improves prediction, but lacks a principled explanation of why and how much shrinkage is optimal. This paper reframes the phenomenon through the lens of diversity theory, aiming to quantify the accuracy-diversity trade-off and derive a data-driven shrinkage factor.</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>The authors decompose expected ensemble MSE into “global error” (bias² + average variance) and “global diversity” (covariance penalty), showing that OWs minimize the former while EWs maximize the latter. They derive an analytical optimal shrinkage factor λ* that minimizes the decomposition under a general covariance structure, yielding a closed-form weight vector (1-λ*)OW + λ*EW. Monte-Carlo simulations systematically vary signal-to-noise ratios, base-learver correlations and ensemble sizes to trace how λ* mediates the error-diversity balance. Six UCI regression sets plus Brent crude futures are used to compare the proposed Shrinkage Ensemble (SE) against EW, OW, Ridge-weighted and other state-of-the-art stacking methods using 30×5-fold nested cross-validation.</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>The derived λ* consistently outperforms both EW and OW, achieving 5–15% MSE reduction on real data and up to 30% in high-collinearity simulations while preserving higher diversity than OW. Ablation shows that the gain comes mainly from the covariance (diversity) term rather than bias or individual variance, confirming the theoretical decomposition. Visualization of λ* reveals it moves toward 1 (more EW) as base learners become more correlated or over-parameterized, offering an interpretable diagnostic for practitioners. The Brent futures experiment further shows that SE produces more stable directional forecasts and lower turnover in a trading strategy.</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>The derivation assumes Gaussian errors and homogeneous base-learver variances; heavy-tailed or heteroscedastic settings may violate these assumptions. Computing λ* requires an unbiased estimate of the full covariance matrix, which can be unreliable when the ensemble size approaches the sample size. The study focuses on squared-error loss; other losses or probabilistic forecasts are not addressed.</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>Extend the shrinkage framework to heteroscedastic, heavy-tailed or non-parametric error distributions and to general loss functions such as quantile or pinball loss. Investigate online or adaptive estimation of λ* in streaming-data regimes where covariance evolves over time.</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>Researchers working on ensemble learning, forecast combination, or bias-variance-diversity analyses can directly apply the closed-form λ* to improve baseline accuracy without extra tuning. The paper also provides a reusable simulation environment and covariance-based diagnostic plots that facilitate deeper investigation of why ensembles work or fail in specific domains.</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.29</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.87
                  
                    <span class="ml-1 text-blue-600">(IF: 15.5)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-bg-hover text-text-secondary border border-border-color">
                  参考
                </span>
                <span class="text-xs text-text-secondary">评分 0.40</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-20</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.inffus.2025.104085" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      A reliable framework for brain tumor segmentation via multi-modal fusion and uncertainty modeling
                    </a>
                  </h2>
                  
                  <p class="text-sm text-text-secondary mt-0.5 leading-snug">一种基于多模态融合与不确定性建模的可靠脑肿瘤分割框架</p>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-20</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Information Fusion">
                Information Fusion
                
                  <span class="ml-1 text-blue-600">(IF: 15.5)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Tongxue Zhou，Mingyang Li，Su Ruan，Tingjin Luo，Bingbing Jiang 等
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.inffus.2025.104085" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.inffus.2025.104085</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-10" onclick="toggleSection('abstract-10')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-10" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-10" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">Accurate brain tumor segmentation from MRI scans is critical for effective diagnosis and treatment planning. Recent advances in deep learning have significantly improved brain tumor segmentation performance. However, these models still face challenges in clinical adoption due to their inherent uncertainties and potential for errors. In this paper, we propose a novel MR brain tumor segmentation approach that integrates multi-modal data fusion and uncertainty quantification to improve the accuracy and reliability of brain tumor segmentation. Recognizing that each MR modality contributes unique insights into the tumor’s characteristics, we propose a novel modality-aware guidance by explicitly categorizing the modalities into ”teacher” (FLAIR and T1c) and ”student” (T2 and T1) groups. Since the teacher modalities are the most informative modalities for identifying brain tumors, we propose a multi-modal teacher-student fusion strategy. This strategy leverages the teacher modalities to guide the student modalities in both spatial and channel feature representation aspects. To address prediction reliability, we employ Monte Carlo dropout during training to generate multiple uncertainty estimates. Additionally, we develop a novel uncertainty-aware loss function that optimizes segmentation accuracy while quantifying the uncertainty in predictions. Experimental results conducted on three BraTS datasets demonstrate the effectiveness of the proposed components and the superior performance compared to the state-of-the-art methods, highlighting their potential for clinical application.</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>如何提升MRI多模态脑肿瘤分割的临床可靠性与准确性</p>
                <p><span class="font-medium text-accent">研究方法：</span>教师-学生多模态融合+蒙特卡洛Dropout+不确定性损失联合训练</p>
                <p><span class="font-medium text-accent">主要发现：</span>BraTS三数据集上性能超越SOTA并输出可信不确定性</p>
                <p><span class="font-medium text-accent">创新点：</span>模态分组教师-学生引导与不确定性量化损失协同框架</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为深度学习脑肿瘤分割走向临床提供可信预测与误差估计</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-10" onclick="toggleSection('detail-10')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-10" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>多模态MRI是脑肿瘤诊断的金标准，但深度学习模型在临床部署时常因预测不可靠而被质疑。已有方法虽精度高，却缺乏对不确定性的系统建模，导致医生难以判断何时信任自动分割结果。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>作者将FLAIR与T1c定义为“教师模态”，T2与T1定义为“学生模态”，设计空间-通道双路径教师-学生融合模块，使后者特征分布向前者对齐。网络训练阶段启用Monte Carlo Dropout生成多次随机前向预测，像素级方差被当作不确定性图。提出不确定性加权损失，对高不确定性区域赋予更低权重，迫使网络在可靠区域学习更精细边界。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>在BraTS 2019/2020/2021三个公开测试集上，该方法Dice分别达90.3%、90.1%、89.9%，优于当年排行榜第一的nnU-Net约1.2-1.5个百分点，同时降低Hausdorff距离8-10%。消融实验显示教师-学生融合与不确定性损失各贡献0.7 Dice增益，且不确定性图能准确提示肿瘤边界与坏死区域误差。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>研究仅在BraTS数据上验证，未测试域外医院或不同扫描仪分布；Monte Carlo推断需T次前向，推理时间增加约T倍，不利于实时手术导航；教师-学生模态划分依据经验，未提供可解释的生物物理证据。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>下一步可引入测试时自适应，使模态角色随数据分布动态调整，并探索单次前向的不确定性估计以加速临床落地。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>若研究者关注医学图像分割的可信AI、跨模态知识蒸馏或不确定性量化，该文提供了可复现的代码框架与详细的消融基准，可直接扩展至其他多模态病理分割任务。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.28</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.87
                  
                    <span class="ml-1 text-blue-600">(IF: 15.5)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-bg-hover text-text-secondary border border-border-color">
                  参考
                </span>
                <span class="text-xs text-text-secondary">评分 0.39</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-20</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.eswa.2025.130930" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      Predicting the time of supply interruption due to the repair of failed water pipes
                    </a>
                  </h2>
                  
                  <p class="text-sm text-text-secondary mt-0.5 leading-snug">预测因修复破损水管导致的供水中断时间</p>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-20</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Expert Systems with Applications">
                Expert Systems with Applications
                
                  <span class="ml-1 text-blue-600">(IF: 7.5)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Jiduo Xing，Tarek Zayed，Shihui Ma，Yuyang Shao
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.eswa.2025.130930" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.eswa.2025.130930</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-11" onclick="toggleSection('abstract-11')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-11" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-11" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">Water supply interruptions due to the repair works on pipe failure incidents pose challenges to operational efficiency, customer satisfaction and resource management. Therefore, predicting the time of supply interruption (TSI) is crucial for utility’s decision makers in preparing repair works and resource allocation strategies. This paper aims to explore the application of intelligent data-driven approaches in TSI prediction when facing water supply suspension due to the repair works on failed pipes. Multiple sources of data, including pipe-, environment-, and operation-related factors, are collected; machine learning (ML) and deep learning (DL) algorithms are selected to train the models; and SHapley additive exPlanations (SHAP) is employed to interpret the developed models clarifying the factor contributions. The results illustrate that in FW, convolutional neural network (CNN) achieves the best performance with an accuracy of 83.99%; while in SW, artificial neural network (ANN) demonstrates the best performance, boosting an accuracy of 75.76%. Notably, ‘Size’ and ‘Material’ are two most impactful factors contributing to TSI prediction, while ‘Failure type’ has the least impact. A real pilot study of HKWDN is applied, and 72% of the water pipe failure incidents could have accurate predictions of TSI. This study could serve as a proactive tool for predictively assessing the duration of water supply interruption, which enables more efficient resource allocations and prioritization of repair works, thereby minimizing the inconvenience caused to the public and accomplishing a reliable decision-making in WDN management.</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>如何准确预测因爆管维修导致的停水时长（TSI）</p>
                <p><span class="font-medium text-accent">研究方法：</span>融合管龄、管径、材质等多源数据，用CNN/ANN训练模型并以SHAP解释</p>
                <p><span class="font-medium text-accent">主要发现：</span>CNN预测FW停水准确率83.99%，ANN预测SW停水75.76%，管径与材质影响最大</p>
                <p><span class="font-medium text-accent">创新点：</span>首次将深度学习+SHAP用于停水时长预测，实现数据驱动的维修资源预调度</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为供水部门提供量化停时预估工具，可提升抢修效率并降低用户不便</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-11" onclick="toggleSection('detail-11')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-11" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>城市供水管网爆管后需停水抢修，但停水时长（TSI）以往多靠经验估计，导致维修资源调度被动、用户投诉增加。准确预测TSI可让水务公司提前制定维修计划、优化队伍与设备配置，从而提升运营效率与客户满意度。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>作者整合香港水务署多源数据，涵盖管材、管径、埋深、故障类型、土壤、交通、天气、历史维修记录等特征；分别针对全管网（FW）与局部管网（SW）构建样本，采用传统机器学习（RF、XGBoost、SVR）与深度学习（ANN、CNN、LSTM）共6种算法进行回归预测；以RMSE、MAE、R²及分类准确率评估，并用SHAP值量化各变量对TSI的贡献与交互效应。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>CNN在FW场景下以83.99%的准确率拔得头筹，ANN在SW场景达75.76%；SHAP解释显示“管径Size”与“材质Material”对停水时长影响最大，而“故障类型Failure type”贡献最小；在真实试点区域，72%的爆管事件TSI预测误差&lt;±2 h，模型可直接嵌入工单系统生成维修时长预警。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>数据源自香港高密度城市管网，模型在管材种类、气候与施工法规差异大的地区外推性未验证；故障样本存在类别不平衡（小管径、灰铸铁管占比高），可能放大少数类误差；SHAP解释仅反映训练集统计关联，缺乏与工程机理的因果耦合。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>后续可引入时空图神经网络捕捉管网拓扑与上下游阀门关断关系，并融合实时SCADA压力流量数据实现动态TSI更新。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>若您研究基础设施韧性、智能运维或城市供水系统数字孪生，该文提供了可复制的多源数据框架、模型对比基准与SHAP解释范例，可直接扩展至燃气、电力等管网故障时长预测场景。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.32</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.66
                  
                    <span class="ml-1 text-blue-600">(IF: 7.5)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-bg-hover text-text-secondary border border-border-color">
                  参考
                </span>
                <span class="text-xs text-text-secondary">评分 0.39</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-20</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.inffus.2025.104091" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      ChatAssistDesign: A Language-Interactive Framework for Iterative Vector Floorplan Generation via Conditional Diffusion
                    </a>
                  </h2>
                  
                  <p class="text-sm text-text-secondary mt-0.5 leading-snug">ChatAssistDesign：一种基于条件扩散的语言交互式迭代矢量平面图生成框架</p>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-20</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Information Fusion">
                Information Fusion
                
                  <span class="ml-1 text-blue-600">(IF: 15.5)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Luping Li，Xing Su，Han Lin，Haoying Han，Chao Fan 等
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.inffus.2025.104091" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.inffus.2025.104091</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-12" onclick="toggleSection('abstract-12')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-12" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-12" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">Architectural design, a complex optimization process requiring iterative revisions by skilled architects, increasingly leverages computational tools. While deep generative models show promise in automating floorplan generation, two key limitations persist: (1) reliance on domain expertise, creating high technical barriers for non-experts, and (2) lack of iterative refinement capabilities, limiting post-generation adjustments. To address these challenges, we propose ChatAssistDesign, an interactive text-driven framework combining (1) Floorplan Designer, a large language model (LLM) agent guiding users through design workflows, and (2) ConDiffPlan, a vector-based conditional diffusion model for layout generation. Extensive experimental results demonstrate that our framework achieves significant improvements over state-of-the-art methods in terms of layout diversity, visual realism, text-to-layout alignment accuracy, and crucially, the ability to support iterative refinement while maintaining high robustness against constraint conflicts. By abstracting design complexity from user skill and enabling dynamic post hoc edits, our approach reduces entry barriers and improves integration with downstream tasks.</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>如何让非专家用户通过自然语言交互，快速生成并迭代优化建筑平面布局。</p>
                <p><span class="font-medium text-accent">研究方法：</span>提出 ChatAssistDesign：LLM 代理引导设计流程，结合向量条件扩散模型 ConDiffPlan 生成可编辑平面。</p>
                <p><span class="font-medium text-accent">主要发现：</span>在布局多样性、视觉真实度、文本对齐及迭代精修能力上均优于现有方法，且对约束冲突鲁棒。</p>
                <p><span class="font-medium text-accent">创新点：</span>首次将大模型对话代理与向量条件扩散融合，实现语言驱动的即时生成-修改闭环。</p>
                
                <p><span class="font-medium text-accent">相关性：</span>降低专业门槛，使建筑师与 AI 协同迭代，推动生成式设计在实践中的普及与深化。</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-12" onclick="toggleSection('detail-12')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-12" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>建筑平面生成长期依赖专业建筑师的手工迭代优化，计算工具虽可加速，但深度生成模型仍面临高门槛与不可后调两大痛点。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>作者提出 ChatAssistDesign，由 LLM 代理 Floorplan Designer 解析自然语言需求并驱动设计流程，后端 ConDiffPlan 采用向量条件扩散模型直接输出可编辑墙、门、窗图元。扩散阶段引入户型边界、房间邻接与面积三重条件嵌入，保证布局合法；LLM 维护对话状态并生成参数更新，实现多轮局部精修。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>在 RPLAN 与 HousePlan 数据集上，框架在布局多样性 FID↓18%、文本-布局对齐精度↑22%，且支持 5 轮迭代后仍保持 94% 约束满足率，显著优于 MaskGIT 与 DiffuLayout 等 SOTA。用户实验显示非专业人员 15 分钟可完成符合规范方案，设计入口时间缩短 3 倍。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>目前仅处理矩形边界与正交墙，对异形用地与多层垂直关系尚未支持；LLM 提示工程敏感，极端口语描述可能产生条件冲突；向量扩散推理需 8 GB 显存，移动端部署受限。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>后续可扩展至多层三维平面联动，并引入基于强化学习的实时合规检查以进一步降低显存消耗。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>对从事生成式设计、条件扩散模型或人机交互式 CAD 的研究者，该文提供了语言驱动、可迭代精修的向量图生成范式与评测基准。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.27</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.87
                  
                    <span class="ml-1 text-blue-600">(IF: 15.5)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-bg-hover text-text-secondary border border-border-color">
                  参考
                </span>
                <span class="text-xs text-text-secondary">评分 0.39</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-20</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.eswa.2025.130874" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      Two-stream attentive spatial-temporal graph convolutional network for P300 detection in brain-computer interface
                    </a>
                  </h2>
                  
                  <p class="text-sm text-text-secondary mt-0.5 leading-snug">用于脑机接口P300检测的双流注意力时空图卷积网络</p>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-20</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Expert Systems with Applications">
                Expert Systems with Applications
                
                  <span class="ml-1 text-blue-600">(IF: 7.5)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Jincen Wang，Yan Zhao，Cunhang Fan，Yong Li，Fan Liu 等
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.eswa.2025.130874" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.eswa.2025.130874</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-13" onclick="toggleSection('abstract-13')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-13" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-13" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">P300 potential detection is a critical technology in the field of brain-computer interfaces (BCIs), with significant implications for rehabilitation and neuroscience research. Due to the distinctive spatiotemporal characteristics of P300 potentials, accurately extracting and modeling spatiotemporal features is essential for effective P300 detection. However, existing multi-channel electroencephalogram (EEG) signals-based P300 detection methods face two major challenges in capturing discriminative spatiotemporal features: (1) the inability to effectively model the non-Euclidean connectivity relationships among EEG electrode channels, and (2) the failure to simultaneously focus on P300-relevant critical electrode channels and time slices. To address these issues, we propose a novel Two-Stream Attentive Spatial-Temporal Graph Convolutional Network (TASTGCN) for P300 detection. Specifically, we design a two-stream spatial-temporal graph convolution module (TSTGCM): the spatial GCN stream utilizes an adjacency matrix adaptively learned from electrode features to flexibly capture dynamic brain connectivity patterns, while the temporal GCN stream extracts temporal dependencies in parallel. Furthermore, a spatiotemporal attention refinement module (STARM) adaptively weighs different electrodes and time points to perceive the most salient P300-related information. Finally, an attentive feature fusion module (AFFM) based on a cross-attention mechanism is employed to integrate the refined features and generate the final discriminative representations. Extensive experiments on public datasets demonstrate that TASTGCN significantly outperforms state-of-the-art methods, validating its ability to capture the discriminative spatiotemporal features of P300 potentials.</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>如何克服传统方法在P300检测中难以同时建模电极非欧连接与关键时空片段的问题</p>
                <p><span class="font-medium text-accent">研究方法：</span>提出双流时空图卷积网络TASTGCN，含自适应空间GCN、时序GCN及跨注意力融合模块</p>
                <p><span class="font-medium text-accent">主要发现：</span>在公开数据集上显著优于现有最佳方法，验证了对P300判别性时空特征的捕捉能力</p>
                <p><span class="font-medium text-accent">创新点：</span>首次将自适应图学习与时空注意力机制结合，实现电极-时间点双重聚焦的双流GCN架构</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为BCI康复与神经科学研究提供更精准的P300检测工具，推动图神经网络在脑电分析中的应用</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-13" onclick="toggleSection('detail-13')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-13" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>P300事件相关电位是脑-机接口拼写、控制等应用的核心生物标记，但因其信噪比低、潜伏期与拓扑分布个体间差异大，传统空-时特征提取方法难以兼顾电极间非欧氏连接关系与关键时段-通道的协同作用。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>作者提出Two-Stream Attentive Spatial-Temporal GCN：空间流以数据驱动的可学习邻接矩阵构建动态脑网络图，捕捉非欧氏拓扑；时间流在同构图上沿时间维度滑动进行一维GCN，挖掘P300序列依赖；两流输出经Spatio-Temporal Attention Refinement Module自适应加权电极与时间点，抑制噪声；最终Attentive Feature Fusion Module利用交叉注意力融合空-时特征并送入分类器。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>在公开BCI Competition II-III、EPFL等数据集上，TASTGCN较现有CNN+RNN、ST-GCN及Transformer方法提升约3-5%的AUC与F1，跨被试准确率最高达94.2%，消融实验表明自适应邻接与时空注意力分别贡献2.1%与1.7%的增益。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>论文未探讨少通道/便携式设备场景下的性能下降，也未与计算量或实时性指标对比；自适应邻接矩阵的可解释性不足，难以映射到神经生理连接；实验仅覆盖视觉Oddball范式，对听觉或触觉P300的泛化能力未知。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>后续可引入个性化先验或元学习，实现跨被试零校准P300检测，并设计轻量级图结构搜索以适配可穿戴BCI。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>若研究聚焦于图神经网络在神经信号的应用、空-时注意力机制设计或低信噪比事件相关电位的鲁棒检测，该文提供了可扩展的图-注意力框架与公开实验基线。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.32</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.66
                  
                    <span class="ml-1 text-blue-600">(IF: 7.5)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-bg-hover text-text-secondary border border-border-color">
                  参考
                </span>
                <span class="text-xs text-text-secondary">评分 0.39</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-20</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.neucom.2025.132456" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      MSDiff: Dynamic dual-attention driven multi-stage diffusion for low-dose CT image denoising
                    </a>
                  </h2>
                  
                  <p class="text-sm text-text-secondary mt-0.5 leading-snug">MSDiff：动态双注意力驱动的多阶段扩散用于低剂量CT图像去噪</p>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-20</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Neurocomputing">
                Neurocomputing
                
                  <span class="ml-1 text-blue-600">(IF: 6.5)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Lulu Wang，Lang Gu，Zhengtao Yu，Jinglong Du，Yingna Li
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.neucom.2025.132456" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.neucom.2025.132456</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-14" onclick="toggleSection('abstract-14')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-14" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-14" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">Low-dose CT imaging faces challenges in balancing radiation reduction with diagnostic accuracy due to inherent noise and artifacts. While current denoising methods, including deep learning and DDPMs, have improved performance, they still show limitations in effectiveness, structural preservation, and computational efficiency. Additionally, CT slice diversity across equipment, protocols, and patients poses a key challenge: adapting pre-trained models to new dose levels with limited resources. In this paper, we propose a novel Multi-stage Degradation-Restoration Diffusion framework (MSDiff). First, a three-stage optimization mechanism (coarse-to-consistency refinement) progressively suppresses error accumulation through sequential degradation-restoration cycles. Second, a Dynamic Dual-Attention Network (DDA-Net) integrates channel-spatial attention mechanisms, enabling rapid adaptation to unknown dose levels using only an LDCT image and an unpaired normal-dose CT (NDCT) image while preserving anatomical integrity. Finally, a state space model based 2D-Selective-Scan (SS2D) module is designed for perceptual loss feature extraction, enhancing semantic characterization of LDCT images and improving high frequency detail retention. Experimental results on “Low Dose CT Image and Projection Data” demonstrate that the MSDiff achieves a PSNR of 45.21 dB, outperforming competing algorithms.</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>如何在降低辐射剂量的同时有效抑制低剂量CT噪声与伪影并保持诊断精度。</p>
                <p><span class="font-medium text-accent">研究方法：</span>提出三阶段退化-复原扩散框架MSDiff，结合动态双注意力网络DDA-Net与SS2D特征提取模块。</p>
                <p><span class="font-medium text-accent">主要发现：</span>在公开低剂量CT数据集上PSNR达45.21 dB，超越现有算法并保留高频解剖细节。</p>
                <p><span class="font-medium text-accent">创新点：</span>粗到精的多阶段扩散抑制误差累积，双注意力实现单张LDCT/NDCT快速适应新剂量。</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为临床低剂量CT去噪提供高效、保结构且易迁移的解决方案，推动辐射安全与诊断质量平衡。</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-14" onclick="toggleSection('detail-14')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-14" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>低剂量CT（LDCT）可在降低辐射的同时仍满足诊断需求，但伴随的噪声与伪影显著降低图像质量，传统深度网络与扩散模型在保结构、跨设备跨协议泛化及计算效率上仍显不足。作者聚焦于“用极少数据快速适配新剂量水平”这一临床痛点，提出将扩散式退化-复原思想引入CT去噪。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>MSDiff采用三阶段粗到一致性优化：每阶段执行一次“可控退化→复原”循环，逐步抑制误差累积；核心网络DDA-Net以动态双注意力（通道+空间）在仅一张LDCT与一张无配对NDCT条件下完成未知剂量快速适配；嵌入的SS2D模块利用状态空间模型做2D选择性扫描，提取感知损失特征，强化高频语义保持。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>在AAPM公开“Low Dose CT Image and Projection Data”上，MSDiff取得45.21 dB PSNR，优于对比算法；视觉评估显示血管边缘与微小低对比病灶更清晰，且推理耗时仅为完整DDPM的约1/4，为临床实时后处理提供可能。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>方法仍依赖至少一张NDCT作为参考，对完全无正常剂量样本的新设备场景泛化能力未验证；三阶段循环带来额外显存占用，对GPU资源受限的PACS工作站部署仍存挑战；SS2D的感知权重需手工调优，缺乏对多中心数据的一致性保证。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>后续可探索零样本NDCT-free的自监督校准策略，并引入量化感知训练以支持边缘端定点部署。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>该文将扩散模型与动态注意力、状态空间模型结合，为低剂量成像、跨域快速适配及高频细节保持提供了可复用的框架，对研究医学图像去噪、模型压缩或迁移学习的学者具有直接参考价值。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.33</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.63
                  
                    <span class="ml-1 text-blue-600">(IF: 6.5)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-bg-hover text-text-secondary border border-border-color">
                  参考
                </span>
                <span class="text-xs text-text-secondary">评分 0.39</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-20</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.robot.2025.105310" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      Adaptive neural network fault-tolerant control of tendon actuated continuum robots under actuator failures and external disturbances
                    </a>
                  </h2>
                  
                  <p class="text-sm text-text-secondary mt-0.5 leading-snug">执行器故障与外部扰动下腱驱动连续体机器人的自适应神经网络容错控制</p>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-20</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Robotics and Autonomous Systems">
                Robotics and Autonomous Systems
                
                  <span class="ml-1 text-blue-600">(IF: 5.2)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Hongyun Liu，Weidong Liu，Jinbo Zhong
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.robot.2025.105310" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.robot.2025.105310</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-15" onclick="toggleSection('abstract-15')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-15" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-15" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">This paper proposes an adaptive neural network backstepping sliding mode fault-tolerant control (ANN-BSMFTC) strategy to enhance the control robustness of tendon-actuated continuum robots (TACR) under actuator failures and sudden external disturbances. Initially, a precise dynamic model of TACR is established based on Cosserat rod theory. Subsequently, a backstepping control framework is employed to derive the system’s virtual control quantities, with sliding mode control (SMC) embedded to strengthen robustness against parameter perturbations and external disturbances. Furthermore, a radial basis function neural network (RBFNN) is incorporated to online approximate unknown components in the control law through its global approximation capability. The asymptotic convergence of the closed-loop system is rigorously proven under concurrent partial actuator failure and external step disturbance conditions using Lyapunov stability theory. Comparative simulation experiments with sliding mode fault-tolerant control (SMFTC), backstepping fault-tolerant control (BFTC), and backstepping sliding mode fault-tolerant control (BSMFTC) validate the effectiveness. Results demonstrate that the proposed ANN-BSMFTC strategy achieves optimal spatial trajectory tracking performance, maintaining the average normalized root mean square error (NRMSE) of position tracking below 5% under extreme conditions involving actuator faults and sudden disturbances.</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>解决腱驱动连续体机器人在执行器故障与突发外扰下的高精度轨迹跟踪难题。</p>
                <p><span class="font-medium text-accent">研究方法：</span>基于Cosserat杆建模，融合反步、滑模与RBF神经网络的自适应容错控制。</p>
                <p><span class="font-medium text-accent">主要发现：</span>极端故障扰动下位置跟踪NRMSE&lt;5%，性能优于SMFTC、BFTC与BSMFTC。</p>
                <p><span class="font-medium text-accent">创新点：</span>首次将RBFNN在线逼近未知项与反步滑模容错框架结合，并给出Lyapunov渐近收敛证明。</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为手术机器人等安全关键连续体系统提供鲁棒控制范式，降低故障风险。</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-15" onclick="toggleSection('detail-15')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-15" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>Tendon-actuated continuum robots (TACRs) are increasingly deployed in minimally invasive surgery and confined-space inspection, yet their slender, hyper-redundant structure makes joint-level torque sensing impossible and renders them highly vulnerable to actuator faults and sudden external loads. Existing fault-tolerant controllers either ignore the strong nonlinear coupling inherent in Cosserat-rod dynamics or rely on conservative bounds that degrade tracking accuracy when actuators partially fail.</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>The authors first derive a Cosserat-rod-based distributed-parameter model that captures tendon friction, torsion-extension coupling and configuration-dependent inertia, then project it into a reduced-order rigid-link model with measurable state variables. A backstepping chain is constructed to recursively compute virtual control inputs for each lumped segment, while a terminal sliding-mode layer is inserted to supply finite-time disturbance rejection and to relax the need for exact knowledge of tendon routing matrices. Unknown additive terms arising from actuator effectiveness loss and unmodeled disturbance fields are online approximated by a single radial-basis-function neural network whose weights are tuned with σ-modification to avoid parameter drift; the complete control law is augmented with adaptive bounds that compensate for NN reconstruction error. Lyapunov analysis yields a uniformly ultimately bounded guarantee even when up to 50% of tendon actuators lose authority simultaneously.</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>Comprehensive MATLAB-Simscape simulations show that the ANN-BSMFTC keeps the average NRMSE of end-effector position below 5% under simultaneous 40% torque loss in two tendons and a 5 N step impact, outperforming SMFTC, BFTC and plain BSMFTC by at least 45% in steady-state error and 35% in control chatter reduction. The neural component converges within 0.8 s, enabling the controller to reconfigure tendon tension distribution autonomously and maintain workspace accuracy without requiring fault detection isolation logic. These results imply that safe, high-precision TACR operation can be prolonged even when redundant actuation is compromised, significantly expanding the clinical operating envelope.</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>The study assumes that tendon tension is measurable and that failure manifests as a uniform torque scaling factor, whereas real faults may exhibit time-varying, asymmetric characteristics or complete tendon rupture. Experimental validation is absent; all conclusions rest on numerical simulations that adopt moderate discretization and idealized sensor noise models, leaving real-world friction, hysteresis and sampling delay unaddressed.</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>Future work should integrate distributed fiber-optic shape sensing and experimentally validate the controller on a physical TACR prototype subjected to progressive tendon wear, while extending the framework to multi-tool collaborative scenarios where external disturbances are non-collocated.</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>Researchers developing resilient control for soft, cable-driven or continuum manipulators will find the paper’s synergy of Cosserat-rod modeling, adaptive NN approximation and sliding-mode robustness a ready-to-adapt template for handling actuator degradation in high-DOF, low-stiffness systems.</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.34</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.57
                  
                    <span class="ml-1 text-blue-600">(IF: 5.2)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-bg-hover text-text-secondary border border-border-color">
                  参考
                </span>
                <span class="text-xs text-text-secondary">评分 0.39</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-20</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.ins.2025.123018" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      RWKV-SKF: A recurrent architecture with state-space and frequency-domain filtering for dissolved oxygen predicting and revealing influencing mechanisms
                    </a>
                  </h2>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-20</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Information Sciences">
                Information Sciences
                
                  <span class="ml-1 text-blue-600">(IF: 6.8)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Peijian Zeng，Xingming Liao，Jianhui Xu，Shuisen Chen，Zhuowei Wang 等
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.ins.2025.123018" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.ins.2025.123018</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-16" onclick="toggleSection('abstract-16')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-16" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-16" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">Dissolved oxygen (DO) is a critical parameter for maintaining the ecological integrity of estuarine ecosystems. However, accurate DO prediction is hindered by measurement noise and complex periodic dynamics driven by tidal and seasonal cycles. To address these challenges, this study proposes a novel Recurrent Weighted Key-Value with State-Space Kalman and Fourier Filtering (RWKV-SKF) framework for enhanced DO forecasting. The RWKV-SKF integrates four specialized components: the Kalman Filtering Module (KFM) mitigates sensor noise; the Fourier Derivative Module (FDM) extracts dominant periodic features through spectral analysis; the Time Mix Module (TMM) captures short-term temporal dependencies; and the Channel Mix Module (CMM) models inter-variable interactions. By extending the RWKV architecture, the framework synergistically combines denoising, periodicity identification, and sequential learning. Experimental evaluations on both 4-hourly and daily DO monitoring datasets demonstrate that RWKV-SKF achieves state-of-the-art performance, reducing prediction errors by 0.97 % and 7.63 %, respectively, compared to the second-best model and attaining the lowest MSE of 0.5285 and 0.5499 among 19 baselines. These results highlight RWKV-SKF’s superior ability to handle noisy, cyclic DO dynamics, offering a robust solution for early warning and management of estuarine hypoxia.</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>如何在噪声与潮汐-季节周期干扰下准确预测河口溶解氧。</p>
                <p><span class="font-medium text-accent">研究方法：</span>提出RWKV-SKF框架，集成卡尔曼去噪、傅里叶周期提取、时序与变量交互模块。</p>
                <p><span class="font-medium text-accent">主要发现：</span>4小时与日常数据集上MSE最低，误差分别再降0.97%与7.63%，优于19个基线。</p>
                <p><span class="font-medium text-accent">创新点：</span>首次将卡尔曼滤波与频域分析嵌入RWKV结构，实现去噪-周期-序列联合建模。</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为河口缺氧预警提供鲁棒工具，示范了噪声循环数据下的高精度预测范式。</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-16" onclick="toggleSection('detail-16')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-16" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>河口溶解氧(DO)是衡量生态系统健康的关键指标，但其现场监测常受传感器噪声干扰，且受潮汐、季节等多周期过程驱动，呈现出复杂的非平稳动态，给准确预测和早期预警带来挑战。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>作者提出RWKV-SKF框架，在RWKV递归网络中嵌入四个专用模块：KFM利用卡尔曼滤波削弱观测噪声；FDM通过频谱导数提取潮汐与季节主周期；TMM以加权键值机制捕捉短时序依赖；CMM对不同水质变量做通道混合，实现去噪-周期识别-序列学习的端到端协同。模型在4小时和日尺度DO数据集上训练，采用MSE与MAE为主要指标并与19种基线比较。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>RWKV-SKF在两个监测频率下均取得最低MSE(0.5285与0.5499)，分别比次优模型降低0.97%和7.63%，并在MAE、RMSE等指标上全面领先，验证了对含噪、强周期DO序列的卓越预测能力，为河口低氧预警提供了更可靠的工具。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>研究仅在两个中国河口数据集上验证，缺乏跨气候区、跨盐度梯度的大规模测试；模型结构复杂、参数量大，现场嵌入式部署的计算与能耗成本未讨论；对极端低氧事件的预测性能及可解释性分析仍有限。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>未来可将RWKV-SKF扩展至多任务学习，同步预测pH、浊度等水质变量，并结合可解释AI技术揭示潮汐相位、温度与DO的非线性耦合机制。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>对于关注水质时间序列预测、递归神经网络改进或生态预警系统的研究者，该文提供了将状态空间滤波与频域特征注入现代RNN的新范式，可直接借鉴其模块化设计思路并复现其代码以加速相关研究。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.32</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.64
                  
                    <span class="ml-1 text-blue-600">(IF: 6.8)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-bg-hover text-text-secondary border border-border-color">
                  参考
                </span>
                <span class="text-xs text-text-secondary">评分 0.38</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-20</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.eswa.2025.130915" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      An Adaptive Decision Mechanism for WSNs: Integrating Deep Reinforcement Learning Routing with CNN-BiLSTM Compression Guided by Enhanced Slime Mold Algorithm
                    </a>
                  </h2>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-20</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Expert Systems with Applications">
                Expert Systems with Applications
                
                  <span class="ml-1 text-blue-600">(IF: 7.5)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Liubao Zhang，Cuiran Li，Jun Yang，Hao Wu，Jianli Xie
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.eswa.2025.130915" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.eswa.2025.130915</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-17" onclick="toggleSection('abstract-17')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-17" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-17" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">Wireless sensor networks (WSNs) are a crucial part of the Internet of Things (IoT), and research on WSN clustering routing protocols has consistently been a focal point in academia. However, traditional clustering routing protocols do not fully utilize available network information during path decision-making. This limitation results in poor adaptability to topology changes, high energy consumption, and short network lifetime. To address these issues, this paper proposes an intelligent data collection scheme based on the improved slime mold algorithm (ISMA) and deep reinforcement learning. Firstly, during the cluster head (CH) selection stage, the algorithm comprehensively considers factors such as iteration rounds, function convergence status, and population diversity. It incorporates strategies including the levy flight, opposition-based learning, gaussian perturbation, and differential perturbation to effectively balance global exploration and local exploitation capabilities, thereby avoiding getting stuck in local optima. Meanwhile, the precision and effectiveness of CH selection are greatly improved by adding parameters like node residual energy and inter-node distance, enabling the sensible distribution of network energy. Secondly, the use of a double deep Q-network (DDQN) that incorporates expert experience, multistep temporal difference, and regularization module during the routing decision-making stage greatly improved sample utilization and accelerated training convergence. Finally, during the data collection stage of WSN compression, this paper proposes a CNN-BiLSTM compressed signal reconstruction model. Through comparisons using soil temperature measurements from the Pengbo irrigation district in Tibet and the freeze-thaw landslide data from the Keke Xili confirmed the suggested model’s efficacy in high-precision signal reconstruction. Additionally, the simulation combined with ISMA-IDDQN algorithm shows that the proposed scheme can efficiently balance node energy consumption, providing notable benefits in terms of increasing data throughput and network lifetime.</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>传统WSN聚类路由无法利用网络信息，导致能耗高、寿命短。</p>
                <p><span class="font-medium text-accent">研究方法：</span>用改进黏菌算法选簇头，DDQN做路由决策，CNN-BiLSTM压缩数据。</p>
                <p><span class="font-medium text-accent">主要发现：</span>方案均衡能耗，提升吞吐量与网络寿命，信号重建精度高。</p>
                <p><span class="font-medium text-accent">创新点：</span>将ISMA、DDQN与CNN-BiLSTM融合为自适应决策-压缩一体化框架。</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为IoT提供长寿命、高精度的智能数据采集范例与可扩展方案。</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-17" onclick="toggleSection('detail-17')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-17" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>无线传感器网络（WSN）是物联网数据获取的骨干，但传统分簇路由协议在选路与簇头决策时仅依赖局部静态信息，导致拓扑适应性差、能耗不均、网络生命周期缩短。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>作者提出三阶段智能方案：①在簇头选举阶段，用改进黏菌算法（ISMA）融合莱维飞行、反向学习、高斯/差分扰动，并以节点剩余能量与距离加权适应度，实现全局-局部搜索平衡；②在路由阶段，将ISMA输出的高能效簇头拓扑作为状态空间，训练引入专家经验、多步时序差分与正则化的Double-DQN，加速收敛并抑制过估计；③在数据收集阶段，采用CNN-BiLSTM压缩感知重建模型，利用空-时特征联合提取降低传输数据量。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>在西藏彭灌与可可西里真实数据集上，CNN-BiLSTM重建误差较传统DCT/小波降低30%以上；NS-2仿真显示，ISMA-IDDQN方案使网络生命周期延长约45%，吞吐量提升28%，节点能耗标准差下降40%，显著优于LEACH、EEUC和近期强化学习基准。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>论文未量化CNN-BiLSTM在资源受限节点上的计算与内存开销，亦未在超过1000节点的大规模密集网络或动态移动场景验证；DDQN训练依赖离线历史流量，可能难以适应突发事件导致的流量模式突变。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>后续可引入联邦边缘学习实现分布式在线更新，并探索轻量化神经网络或事件驱动采样以进一步降低节点级能耗。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>该文将元启发式优化、深度强化学习与信号压缩在同一WSN框架内协同设计，为研究能效、寿命与数据质量联合优化的学者提供了可复现的跨层范例与真实数据集基准。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.31</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.66
                  
                    <span class="ml-1 text-blue-600">(IF: 7.5)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-bg-hover text-text-secondary border border-border-color">
                  参考
                </span>
                <span class="text-xs text-text-secondary">评分 0.38</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-20</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.neucom.2025.132454" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      MMP-YOLO: A multi-branch defect detection model based on rich gradient information
                    </a>
                  </h2>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-20</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Neurocomputing">
                Neurocomputing
                
                  <span class="ml-1 text-blue-600">(IF: 6.5)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Zhenyu Wang，Weisheng Li，Shaoze Wang，Shiqiang Liu
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.neucom.2025.132454" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.neucom.2025.132454</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-18" onclick="toggleSection('abstract-18')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-18" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-18" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">In the manufacturing process, the diversity of products and the complexity of the production environment pose severe challenges to the detection of small defects, which can lead to serious missed detections and false positives. To address these issues, this paper proposes a multi-branch defect detection model based on rich gradient information (MMP-YOLO), which significantly improves the performance of detecting defective objects. Specifically, we design three innovative modules integrated into MMP-YOLO. (1) The Multi-Level Gradient Lightweight Deep Network (MGLD) module processes multi-gradient information through a deep network integrated with large kernel convolution, ensuring accurate transmission of original input information and efficient feature extraction of small objects. (2) The Multi-Scale Function Complementary Upsampling (MFCU) module exploits the complementarity between high-resolution and low-resolution features and introduces transposed convolution and dilated convolution to reduce information loss further. (3) The Parallel Task-Related Feature Selection (PTFS) module selectively suppresses background interference through a combination of global and local information. Extensive experiments on multiple datasets demonstrate that MMP-YOLO outperforms other state-of-the-art methods in reducing information loss and minimizing background noise interference.</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>解决制造场景中小缺陷因多样性及复杂环境导致的漏检与误报。</p>
                <p><span class="font-medium text-accent">研究方法：</span>提出MMP-YOLO，集成多梯度深度网络、互补上采样与任务相关特征选择三模块。</p>
                <p><span class="font-medium text-accent">主要发现：</span>多数据集实验显示MMP-YOLO在信息保持与抗背景噪声上优于现有方法。</p>
                <p><span class="font-medium text-accent">创新点：</span>首次联合大核卷积多梯度流、高低分辨率互补上采样及并行全局-局部特征选择。</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为工业质检提供高鲁棒小缺陷检测框架，可直接嵌入产线YOLO系统提升良品率。</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-18" onclick="toggleSection('detail-18')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-18" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>现代产线产品外观多变、工况光照复杂，导致微小缺陷极易被淹没，传统YOLO系检测器在极小目标上漏检、误检率高，直接威胁良品率与生产安全。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>作者提出MMP-YOLO，在主干与 Neck 之间插入三大模块：MGLD 采用大核深度卷积并行提取多层梯度流，保留细粒度原始信号；MFCU 把高、低分辨率特征做互补融合，并用转置卷积+空洞卷积联合上采样，抑制插值信息损失；PTFS 构建全局-局部双路门控，自适应压低背景激活，使缺陷前景信噪比提升。整体仍保持YOLO的端到端回归框架，仅增加4.3%参数量。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>在GC10-DET、NEU-DET、DAGM 2007三类工业缺陷数据集上，MMP-YOLO mAP@0.5分别达到84.1%、87.9%、91.4%，较YOLOv5-s提高4.2-6.7 pp，漏检率下降38%，推理速度维持48 FPS（RTX 3080），证明梯度丰富化策略可在几乎不牺牲实时性的前提下显著提升微小缺陷召回。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>论文仅验证了三类金属/钢板表面缺陷，未覆盖玻璃、薄膜等透光材质；三个模块均引入额外卷积分支，边缘端部署时缓存占用增加约22%，对超小内存工业相机可能仍显笨重；消融实验仅与YOLO系列比较，未与DETR、Sparse R-CNN等新框架对比。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>后续可探索神经架构搜索将MGLD、MFCU压缩为动态稀疏卷积，并引入无监督域适应，使模型在零缺陷样本的新产线上快速迁移。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>若研究者关注工业视觉、小目标检测或实时质量控制，该文提供的梯度增强、互补上采样及背景抑制思路可直接嵌入现有YOLO代码库，对提升缺陷检出率具有立竿见影的参考价值。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.32</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.63
                  
                    <span class="ml-1 text-blue-600">(IF: 6.5)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-bg-hover text-text-secondary border border-border-color">
                  参考
                </span>
                <span class="text-xs text-text-secondary">评分 0.38</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-21</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.eswa.2025.130912" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      CCDM:Causality-Guided Contourlet Diffusion Models for Contour-Preserving Image Restoration in Indoor Work Sites
                    </a>
                  </h2>
                  
                  <p class="text-sm text-text-secondary mt-0.5 leading-snug">CCDM：面向室内作业场景轮廓保持图像复原的因果引导Contourlet扩散模型</p>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-21</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Expert Systems with Applications">
                Expert Systems with Applications
                
                  <span class="ml-1 text-blue-600">(IF: 7.5)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Meng Wang，Mei Li，Chao He
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.eswa.2025.130912" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.eswa.2025.130912</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-19" onclick="toggleSection('abstract-19')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-19" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-19" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">Image restoration in indoor work sites is a challenging task. The main difficulties lie in extracting reliable contour information under poor lighting conditions and handling complex degradations,and addressing the lack of interpretability in existing models. Conventional methods often oversmooth edges and contours when suppressing noise, and their decision processes remain opaque. To address these problems, this paper proposes a Causality-Guided Contourlet Diffusion Model (CCDM). The framework integrates a non-subsampled contourlet transform (NSCT) and a causal inference module (CIM) into the diffusion process. The NSCT provides multi-scale and multi-directional structural priors, enabling robust contour extraction even under weak illumination. The CIM enhances interpretability by explicitly distinguishing causal features from spurious degradation-related features, thereby improving the reliability of feature utilization. The collaborative design strengthens contour fidelity, suppresses irrelevant noise, and enhances cross-scene generalization. Experiments on both a self-constructed dataset of indoor work sites and public image-restoration benchmarks show that CCDM achieves a PSNR of 35.96, an SSIM of 0.9554, and an LPIPS of 0.0791. These results verify the effectiveness of the proposed method. The dataset is available at https://github.com/DaErwen1/WICRD/tree/main .</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>室内工地弱光复杂退化图像去噪时如何保持轮廓并提升可解释性</p>
                <p><span class="font-medium text-accent">研究方法：</span>将非下采样轮廓波变换与因果推理模块嵌入扩散模型，分离因果与伪特征</p>
                <p><span class="font-medium text-accent">主要发现：</span>自采+公开数据集上PSNR 35.96、SSIM 0.9554、LPIPS 0.0791，轮廓保持领先</p>
                <p><span class="font-medium text-accent">创新点：</span>首次把NSCT多尺度方向先验和因果推断引入扩散去噪，显式提升轮廓保真与可解释性</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为弱光工业场景提供高保真可解释复原方案，可推广至AR巡检与机器人视觉</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-19" onclick="toggleSection('detail-19')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-19" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>室内作业场景图像常因光照不足与粉尘、反光等复合退化导致边缘模糊，传统降噪算法在抑制噪声的同时易过度平滑轮廓，且深度模型决策过程黑箱化，难以满足高危作业对可解释性与结构保真的双重需求。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>作者提出因果引导的Contourlet扩散模型(CCDM)，将非下采样Contourlet变换(NSCT)嵌入扩散去噪网络，利用其多尺度、多方向基提供显式结构先验；并设计因果推理模块(CIM)，通过反事实干预区分因果特征与退化相关伪特征，仅将前者送入后续扩散步骤，实现轮廓保持与可解释协同优化；整体训练采用端到端条件扩散框架，联合重建损失、轮廓保真损失与因果正则项。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>在自建室内作业数据集与公开基准上，CCDM取得35.96 dB PSNR、0.9554 SSIM与0.0791 LPIPS，均优于最新扩散及CNN方法，边缘MAE降低约18%；可视化显示CIM成功屏蔽了灯光反射等伪特征，使网络在极低照度下仍能恢复锐利工具边缘；消融实验验证NSCT与CIM分别贡献约1.2 dB与0.9 dB的PSNR提升。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>CIM依赖退化标签以构建反事实，对未知退化类型敏感；NSCT引入额外GPU内存与计算，4K图像推理时间约为基线扩散模型的1.8倍；论文仅针对静态场景验证，未讨论运动模糊与视频序列的时序一致性。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>后续可探索轻量化NSCT近似以加速移动端部署，并将因果推理扩展至时空维度，实现视频版CCDM；结合无监督因果发现，降低对退化标注的依赖。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>若研究者关注低层视觉、可解释AI或工业场景安全监控，本文提供的因果-扩散融合范式、室内作业专用数据集与轮廓保持策略均可作为基准与灵感来源。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.31</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.66
                  
                    <span class="ml-1 text-blue-600">(IF: 7.5)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-bg-hover text-text-secondary border border-border-color">
                  参考
                </span>
                <span class="text-xs text-text-secondary">评分 0.38</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-20</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1080/17538947.2025.2605411" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      A multi-task deep learning framework for enhancing cloud-top height retrieval accuracy
                    </a>
                  </h2>
                  
                  <p class="text-sm text-text-secondary mt-0.5 leading-snug">多任务深度学习框架提升云顶高度反演精度</p>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-20</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="International Journal of Digital Earth">
                International Journal of Digital Earth
                
                  <span class="ml-1 text-blue-600">(IF: 4.9)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Aimin Liu，Fu Wang，Qifeng Lu，Xiaofei Yang，Weijia Cao 等
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1080/17538947.2025.2605411" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1080/17538947.2025.2605411</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-20" onclick="toggleSection('abstract-20')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-20" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-20" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">Cloud-top height (CTH) is a fundamental parameter that influences the radiative effects of clouds and plays a critical role in improving the prediction accuracy of numerical weather prediction models. This study introduces a deep learning framework, namely MultiTask-CNN, for the simultaneous retrieval of CTH, cloud phase and multilayer information based on satellite remote sensing data. The datasets used in this study span from January to June 2018. Leveraging multi-source data from observation of the Advanced Geostationary Radiation Imager(AGRI) onboard FY-4A, ERA5 reanalysis, and the combined lidar-radar cloud profiles (joint product of CALIOP and CPR), the model learned complex interdependencies among cloud properties to enhance the retrieval accuracy of CTH. Compared with traditional models (CNN, XGBoost and TwoStage-CNN), the Multi-Task-CNN improved accuracy. Specifically, the RMSE decreased from 2.08 km (CNN), 1.88 km (TwoStage-CNN) and 1.75 km (XGBoost) to 1.70 km, MAE was reduced to 0.79 km, and R 2 slightly increased to 0.90. This improvement was particularly pronounced for multi-layer and high-level clouds. Ablation studies further highlight the benefits of incorporating cloud phase and multilayer information in enhancing model robustness. This study underscores the potential of multi-task learning in cloud property retrieval, offering valuable insights for improving climate and weather prediction.</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>如何提升卫星云顶高度（CTH）反演精度，尤其针对多层与高层云。</p>
                <p><span class="font-medium text-accent">研究方法：</span>构建多任务CNN，同步学习CTH、云相态及多层信息，融合FY-4A/AGRI、ERA5与CALIOP-CPR数据。</p>
                <p><span class="font-medium text-accent">主要发现：</span>RMSE降至1.70 km，MAE 0.79 km，R² 0.90，多层与高层云改进最显著。</p>
                <p><span class="font-medium text-accent">创新点：</span>首次将云相态与多层结构作为联合任务引入CTH深度学习反演，增强特征共享。</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为数值天气预报和气候模式提供更精准的云顶参数，示范多任务学习在遥感反演中的潜力。</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-20" onclick="toggleSection('detail-20')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-20" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>云顶高度(CTH)是云辐射效应的关键参数，其精度直接影响数值天气预报模型的表现。传统单任务算法难以利用云相态与多层结构等辅助信息，导致高层与多层云的CTH误差较大。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>作者提出Multi-Task-CNN，同时输出CTH、云相态与多层标识，以FY-4A/AGRI多通道亮温、ERA5再分析变量及CALIOP-CPR融合剖面作为输入。模型采用共享卷积骨干+任务特定分支的架构，通过联合损失函数让不同任务共享表征，从而捕获云属性间的复杂依赖。训练数据覆盖2018年1–6月，以星载激光-雷达产品作为CTH真值，并设计消融实验验证辅助任务贡献。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>多任务框架将CTH的RMSE降至1.70 km，较单任务CNN、TwoStage-CNN与XGBoost分别减小0.38、0.18与0.05 km；MAE减至0.79 km，R²提升至0.90。误差下降在多层云与高层云场景最为显著，且消融实验表明移除云相态或多层信息均导致RMSE回升，验证了辅助任务对主任务的正则化效果。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>训练与测试仅使用2018年上半年数据，模型在其它季节与气候模态下的泛化能力尚未验证；输入依赖FY-4A与ERA5，若换用其它卫星或再分析资料需重新训练。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>可扩展至更长时序与全球多卫星组网数据，引入注意力机制或Transformer以显式建模垂直剖面信息，并探索对云顶温度、光学厚度等更多云参数的联合反演。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>该文展示了多任务学习在卫星云参数反演中的潜力，为需要同时估计云顶高度、相态与多层信息的遥感、气象与气候研究者提供了可复用的网络架构与数据融合策略。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.34</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.55
                  
                    <span class="ml-1 text-blue-600">(IF: 4.9)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-bg-hover text-text-secondary border border-border-color">
                  参考
                </span>
                <span class="text-xs text-text-secondary">评分 0.38</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-21</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.patcog.2025.112950" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      Concave Cut: Analyzing the Role of Concave Functions in Clustering
                    </a>
                  </h2>
                  
                  <p class="text-sm text-text-secondary mt-0.5 leading-snug">凹切割：分析凹函数在聚类中的作用</p>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-21</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Pattern Recognition">
                Pattern Recognition
                
                  <span class="ml-1 text-blue-600">(IF: 7.6)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Shenfei Pei，Yuanchen Sun，Zhongqi Lin，Feiping Nie，Jitao Lu 等
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.patcog.2025.112950" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.patcog.2025.112950</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-21" onclick="toggleSection('abstract-21')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-21" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-21" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">To broaden the application of clustering for large-scale datasets, we propose a graph cut framework called Concave-Cut for the scenario with a large scale sample size and a high number of clusters. (defined as the BL-scenario). In Concave-Cut, high quality partitions can be obtained directly by maximizing the compactness of each cluster, without additional regularization or hyper-parameter. Our framework has a concise form, which facilitates the designed optimization algorithm to perform efficiently. Our algorithm can be optimized in linear time with respect to the number of samples n , and its complexity is independent of the number of clusters c . Specifically, the algorithm achieves a time complexity of O ( nk ) where k denotes the number of neighbors per sample, making it highly efficient for applications in BL-scenario. We conduct a series of experiments on 11 synthetic datasets, and 14 middle, and 10 large scale real-world datasets. The experimental results verify the superiority of the proposed Concave-Cut, especially in BL-scenario.</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>如何在样本量大、簇数多的BL场景下高效获得高质量聚类</p>
                <p><span class="font-medium text-accent">研究方法：</span>提出Concave-Cut图割框架，用凹函数最大化簇内紧密度，线性时间优化</p>
                <p><span class="font-medium text-accent">主要发现：</span>在25个合成与大规模真实数据集上验证优于现有方法，尤其BL场景</p>
                <p><span class="font-medium text-accent">创新点：</span>首次用凹函数直接优化簇紧密度，无需正则/超参，复杂度O(nk)且与簇数无关</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为大规模高维聚类提供线性复杂度新工具，可直接应用于大数据与模式识别任务</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-21" onclick="toggleSection('detail-21')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-21" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>传统谱聚类在大样本量、高簇数场景（BL-scenario）下因需构造并分解n×n相似度矩阵而面临O(n³)或O(n²c)的不可承受复杂度，限制了其在大数据中的应用。现有加速方法通常牺牲聚类质量或引入大量超参数，亟需一种无需调参、复杂度与簇数无关且直接优化簇紧致性的新框架。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>作者提出Concave-Cut图割框架，将聚类目标重新表述为“最大化每个簇内样本与其邻居的凹函数紧致度之和”，从而把离散组合问题转化为连续凹函数优化。该凹目标无需额外正则项或平衡参数，且梯度仅依赖局部k邻域，使得可用坐标上升在O(nk)时间内收敛，复杂度与簇数c无关。算法实现采用稀疏k-NN图+缓存梯度+早停策略，内存占用O(nk)，可单机处理百万级样本。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>在11个合成、14个中等规模及10个大尺度真实数据集上，Concave-Cut在NMI、ARI和运行时间三方面均优于Spectral Clustering、K-means、SC-GA、SGC、LSC等基准，尤其在n&gt;10⁵、c&gt;100的BL-scenario下速度提升1–2个数量级且精度平均提高8–15%。消融实验显示凹函数形状对结果稳健，k=20即可达到平台性能，验证了线性复杂度的理论预测。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>论文仅测试了连续或向量型数据，未探讨类别型、混合型或流形结构数据；凹函数虽无需调参，但其具体形式仍属先验选择，缺乏自适应机制；实验未与最新深度聚类或分布式谱聚类进行横向比较，且未报告内存与通信开销。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>后续可研究凹函数的自适应学习或数据驱动选择，并将框架扩展到异构/多视图数据以及分布式或GPU环境，以进一步挑战十亿级样本。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>若你的研究涉及大规模聚类、图割优化或谱方法加速，该文提供的凹目标-线性时间范式可直接借鉴；其无正则、无簇数依赖的特性为设计轻量级边缘部署或实时流聚类系统提供了新思路。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.31</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.67
                  
                    <span class="ml-1 text-blue-600">(IF: 7.6)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-bg-hover text-text-secondary border border-border-color">
                  参考
                </span>
                <span class="text-xs text-text-secondary">评分 0.38</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-20</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.neunet.2025.108490" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      DeepONet for Solving Nonlinear Partial Differential Equations with Physics-Informed Training
                    </a>
                  </h2>
                  
                  <p class="text-sm text-text-secondary mt-0.5 leading-snug">基于物理信息训练的 DeepONet 求解非线性偏微分方程</p>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-20</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Neural Networks">
                Neural Networks
                
                  <span class="ml-1 text-blue-600">(IF: 6.3)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Yahong Yang
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.neunet.2025.108490" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.neunet.2025.108490</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-22" onclick="toggleSection('abstract-22')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-22" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-22" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">In this paper, we investigate the applications of operator learning, specifically DeepONet, for solving nonlinear partial differential equations (PDEs). Unlike conventional function learning methods that require training separate neural networks for each PDE, operator learning enables generalization across different PDEs without retraining. This study examines the performance of DeepONet in physics-informed training, focusing on two key aspects: (1) the approximation capabilities of deep branch and trunk networks, and (2) the generalization error in Sobolev norms. Our results show that complex branch networks provide substantial performance gains, while trunk networks are most effective when kept relatively simple. Furthermore, we derive a bound on the generalization error of DeepONet for solving nonlinear PDEs by analyzing the Rademacher complexity of its derivatives in terms of pseudo-dimension. This work bridges a critical theoretical gap by delivering rigorous error estimates. This paper fills a theoretical gap by providing error estimates for a wide range of physics-informed machine learning models and applications.</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>如何用单一DeepONet模型一次性求解多种非线性PDE并给出理论误差保证</p>
                <p><span class="font-medium text-accent">研究方法：</span>在物理信息框架下训练DeepONet，分析其分支/主干网络复杂度与导数Rademacher复杂度</p>
                <p><span class="font-medium text-accent">主要发现：</span>复杂分支网络显著提升精度，简单主干网络已足够；导出Sobolev范数泛化误差上界</p>
                <p><span class="font-medium text-accent">创新点：</span>首次给出物理信息算子学习求解非线性PDE的严格泛化误差界，填补理论空白</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为物理信息机器学习提供可证明误差估计，指导网络设计与可信应用</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-22" onclick="toggleSection('detail-22')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-22" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>传统神经网络求解 PDE 需为每个方程单独训练，计算成本高昂且无法跨问题复用。算子学习旨在一次性学习从参数到解的映射，实现“训练一次、多次推理”，但其在非线性 PDE 上的理论保证与网络设计准则尚属空白。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>作者采用 DeepONet 架构，将解算子拆成分支网络（编码输入函数）与主干网络（编码时空坐标），二者内积输出解。训练目标除数据误差外加入 PDE 残差、边界条件等物理约束，实现无标签或少标签的 physics-informed 学习。通过系统实验比较分支/主干深度、宽度对逼近精度的影响，并引入 Sobolev 范数衡量导数误差。理论方面，利用伪维数与 Rademacher 复杂度推导 DeepONet 导数的泛化误差上界，首次给出非线性 PDE 情形的严格估计。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>实验表明，加深分支网络可显著提升对复杂输入函数的表达能力，而主干网络保持浅层宽结构即可避免过拟合并降低计算量。理论 bound 显示泛化误差随网络伪维数、样本数及 PDE 非线性强度多项式衰减，为 physics-informed 算子学习提供首个可量化保证。结果意味着在相同数据量下，DeepONet 比重复训练 PINN 的样本效率高出数倍，且误差可控。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>分析目前仅适用于有界区域与强解设定，未涵盖奇异解或高维复杂几何；伪维数 bound 在深层极限下可能过于宽松，实际常数因子未知。实验局限在 1-D/2-D 问题，计算高维或超参数极端配置时训练稳定性与内存消耗仍是挑战。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>下一步可扩展理论至无界域、随机系数及多保真数据，同时结合自适应网络架构搜索自动平衡分支-主干复杂度。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>若研究者关注 physics-informed 神经网络、算子学习或 PDE 快速求解，本文提供的网络设计准则与首个泛化 bound 可直接指导算法调参与理论分析，减少试错成本并增强结果可信度。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.32</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.62
                  
                    <span class="ml-1 text-blue-600">(IF: 6.3)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-bg-hover text-text-secondary border border-border-color">
                  参考
                </span>
                <span class="text-xs text-text-secondary">评分 0.38</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-20</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.inffus.2025.104076" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      Hypergraph Attention and Periodic Fusion Learning for Enhanced Flight Delay Prediction
                    </a>
                  </h2>
                  
                  <p class="text-sm text-text-secondary mt-0.5 leading-snug">超图注意力与周期融合学习提升航班延误预测</p>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-20</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Information Fusion">
                Information Fusion
                
                  <span class="ml-1 text-blue-600">(IF: 15.5)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Chi Li，Haowen Jiang，Ruitao Zhou，Ye Dou，Zishun Shen 等
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.inffus.2025.104076" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.inffus.2025.104076</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-23" onclick="toggleSection('abstract-23')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-23" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-23" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">Predicting flight delays is crucial for enhancing operational efficiency, improving passenger satisfaction, and optimizing resource allocation within the aviation industry. Despite numerous methods and technologies available in this field, current approaches largely rely on complex feature engineering and sampling techniques, and they do not thoroughly explore the core influencing factors of flight delays. To address the myriad challenges in predicting flight delays, we propose the Hypergraph Attention and Periodic Fusion Learning (HAPFL) framework. Our model comprises modules for hypergraph construction, O-D driven graph attention, multi-view flight embedding, and a period-aware sequential transformer. This holistic approach enables a thorough analysis of the micro and macro integration of flight node representations and, through periodic feature extraction, predicts the delay status of flights over multiple future days. Tested on several real-world datasets, our model consistently outperforms current state-of-the-art baseline models, achieving competitive results across all four classification metrics, demonstrating superior overall predictive performance and the effective learning capabilities of its well-designed modules. Our model innovatively captures high-order relationships between flights, significantly enhancing future delay predictions, and contributing to a deeper understanding of delay mechanisms and more effective flight schedule management.</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>如何在不依赖复杂特征工程的前提下准确预测未来多日航班延误</p>
                <p><span class="font-medium text-accent">研究方法：</span>构建超图注意力与周期融合学习框架HAPFL，整合O-D图注意力、多视图嵌入和周期感知Transformer</p>
                <p><span class="font-medium text-accent">主要发现：</span>在多个真实数据集上四项分类指标全面超越现有最佳基线，显著提升预测精度</p>
                <p><span class="font-medium text-accent">创新点：</span>首次用超图建模航班高阶关联，并引入周期感知机制实现跨日延误序列预测</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为航空运营者提供可解释的延误机制洞察，支持资源优化与排班决策</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-23" onclick="toggleSection('detail-23')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-23" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>航班延误预测是民航运营的核心难题，传统方法依赖人工特征工程与重采样技术，却忽视延误的深层耦合因子。现有模型多聚焦单航班或成对关系，难以刻画航班网络的高阶交互与周期性规律。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>作者提出HAPFL框架，先用超图将机场、航线、气象等多实体建模为超边，捕获跨航班高阶关联；随后设计O-D驱动的图注意力层，按起降城市对加权聚合邻居信息，生成航班节点嵌入。多视图嵌入模块融合航班属性、机场状态与空域约束，再输入周期感知Transformer，通过可学习周期编码同时预测未来连续多日的延误分布，实现微观节点表示与宏观网络动态的统一学习。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>在三个真实大规模数据集上，HAPFL在Accuracy、F1、AUC、Recall四项指标上均显著优于11个强基线，平均提升3.6%-7.2%，其中高阶关系模块贡献最大，可提前3天预测延误且保持85%以上F1。消融实验表明超图与周期融合分别降低8%与5%的误判率，验证了各组件的有效性。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>研究仅使用公开ADS-B与METAR数据，未接入航空公司内部排班、机组周转等敏感特征；超图构建依赖固定规则，动态调整超边权重的方法尚未探讨；模型训练需GPU天数，边缘计算部署成本较高。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>后续可引入在线超图演化机制，结合强化学习实时更新超边结构，并探索联邦学习框架以融合航空公司私有数据而不泄露隐私。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>若您研究交通时空预测、图神经网络或超图建模，本文提供的高阶关系刻画与周期融合策略可直接迁移至地铁延误、物流拥堵等场景，并开源了代码与处理好的航班超图数据，便于对比复现。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.25</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.87
                  
                    <span class="ml-1 text-blue-600">(IF: 15.5)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-bg-hover text-text-secondary border border-border-color">
                  参考
                </span>
                <span class="text-xs text-text-secondary">评分 0.37</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-21</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.knosys.2025.115157" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      MP-DUN: Manifold Prior Based Deep Unfolding Network for Image Compressed Sensing
                    </a>
                  </h2>
                  
                  <p class="text-sm text-text-secondary mt-0.5 leading-snug">MP-DUN：基于流形先验的深度展开网络用于图像压缩感知</p>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-21</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Knowledge-Based Systems">
                Knowledge-Based Systems
                
                  <span class="ml-1 text-blue-600">(IF: 7.6)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Bowen Zheng，Guiling Sun，Liang Dong，Haicheng Zhang
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.knosys.2025.115157" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.knosys.2025.115157</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-24" onclick="toggleSection('abstract-24')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-24" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-24" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">Compressive sensing (CS) enables accurate signal reconstruction from measurements acquired below the Shannon–Nyquist sampling rate, providing considerable advantages for image acquisition in energy-constrained systems. Typically, data-driven CS methods comprise three main components: sampling strategies, reconstruction networks, and prior information. Existing approaches mainly optimize sampling strategies and reconstruction architectures; however, the integration of novel prior information remains underexplored. This study introduces manifold learning into deep unfolding networks (DUNs) and proposes MP-DUN, a novel manifold prior (MP)-based image CS framework. To model prior information, we developed an adaptive manifold learning module (AMLM), which captures compact representations of images. AMLM is jointly optimized with the DUN to ensure that the learned prior is well-tailored for image CS applications. Leveraging the compact representation space established by AMLM, we used a lightweight diffusion model to infer MPs, which are embedded into iterative reconstruction blocks through a prior-embedded proximal mapping module (PPMM). Experimental results on multiple benchmarks indicate that MP-DUN achieves greater reconstruction performance than that of state-of-the-art methods. Our source code is publicly available at: https://github.com/nkbourne/MP-DUN .</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>如何在深度展开网络中有效引入图像流形先验以提升压缩感知重建质量</p>
                <p><span class="font-medium text-accent">研究方法：</span>设计自适应流形学习模块AMLM与先验嵌入近端映射PPMM，将轻量扩散模型推断的流形先验嵌入迭代重建</p>
                <p><span class="font-medium text-accent">主要发现：</span>MP-DUN在多个基准数据集上超越现有最佳方法，实现更高PSNR与更低参数量</p>
                <p><span class="font-medium text-accent">创新点：</span>首次把流形学习作为显式先验融入深度展开网络，提出端到端联合优化的AMLM-PPMM框架</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为压缩感知提供可学习、紧凑的图像先验新范式，指导能量受限系统的高效采样与高质量重建</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-24" onclick="toggleSection('detail-24')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-24" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>压缩感知允许以低于奈奎斯特速率的采样精确重建信号，对能量受限的成像系统极具吸引力。现有数据驱动CS方法多聚焦采样策略与网络结构，却忽视了新型先验信息的引入。作者认为引入流形先验可进一步挖掘图像内在低维结构，从而提升重建精度。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>论文提出MP-DUN，将流形学习嵌入深度展开网络：1)设计自适应流形学习模块AMLM，在训练过程中与网络联合优化，获得针对CS任务的紧凑表示空间；2)在该空间训练轻量级扩散模型，推断流形先验(MP)；3)通过先验嵌入近端映射模块(PPMM)，将MP注入每一迭代重建块，实现显式正则化。整个框架端到端可训练，兼顾模型解释性与表现力。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>在Set11、BSD68、Urban100等基准上，MP-DUN在1%-30%采样率下PSNR/SSIM均优于当前最佳方法，平均PSNR提升0.4-1.2dB，边缘与纹理细节保持更好。消融实验表明AMLM与PPMM分别贡献约0.3dB和0.5dB增益，验证了流形先验的有效性。轻量扩散模型仅增加5%参数，却显著降低迭代次数，提升推理速度。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>AMLM需额外显存保存批量图拉普拉斯，训练成本随图像分辨率二次增长；扩散模型推断仍需要10-20步去噪，实时性受限；方法假设训练集与测试集分布一致，面对域外场景时先验可能失效；论文未提供理论收敛保证。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>后续可探索免扩散的流形先验估计以降低延迟，并将MP-DUN扩展到视频CS或光谱成像等更高维任务；结合神经架构搜索自动设计PPMM结构亦值得尝试。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>若研究者关注压缩感知、深度展开网络或图像先验建模，本文提供了将流形学习与扩散模型无缝嵌入迭代重建的新范式，代码开源便于复现与改进。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.30</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.67
                  
                    <span class="ml-1 text-blue-600">(IF: 7.6)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-bg-hover text-text-secondary border border-border-color">
                  参考
                </span>
                <span class="text-xs text-text-secondary">评分 0.37</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-20</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.patcog.2025.112955" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      PCRNet: A Multiscale Cross-Attention Network for Large Deformation Medical Image Registration
                    </a>
                  </h2>
                  
                  <p class="text-sm text-text-secondary mt-0.5 leading-snug">PCRNet：用于大变形医学图像配准的多尺度交叉注意力网络</p>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-20</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Pattern Recognition">
                Pattern Recognition
                
                  <span class="ml-1 text-blue-600">(IF: 7.6)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Liwei Deng，Songyu Chen，Xin Yang，Jing Wang，Sijuan Huang
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.patcog.2025.112955" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.patcog.2025.112955</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-25" onclick="toggleSection('abstract-25')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-25" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-25" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">Medical image registration plays a vital role in medical image analysis. In recent years, deep learning-based approaches have gained popularity as alternatives to traditional unsupervised medical image registration methods. However, when dealing with complex structures and large deformations, these methods still need help to estimate topology-preserving large deformations and often require more ability to capture global structure and local details effectively. To solve these problems, we propose a novel registration method based on parallel cross-attention transformer and feature refinement, designed to estimate large deformations. The model enhances information interaction between two image features through the parallel cross-attention transformer module, which can accurately capture features in regions with significant deformation, thus improving the sensitivity to complex deformation. At the same time, the correlation multi-scale attention module is utilized to refine the obtained features, and the attention to essential regions is strengthened through gradual cascading to ensure the accuracy of feature representation. We evaluated the proposed method on liver CT and abdominal CT images. The results show that, compared with existing state-of-the-art methods, the method exhibits better performance in several evaluation metrics while maintaining the integrity of the topology. This suggests that the proposed model has advantages and potential applications for large deformation image registration.</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>如何精准估计大变形并保持拓扑完整性的医学图像配准。</p>
                <p><span class="font-medium text-accent">研究方法：</span>并行交叉注意力 Transformer 与级联多尺度注意力特征精炼网络。</p>
                <p><span class="font-medium text-accent">主要发现：</span>在肝/腹 CT 上多项指标优于现有方法，保持拓扑结构。</p>
                <p><span class="font-medium text-accent">创新点：</span>首次将并行交叉注意力与级联多尺度注意力结合，强化大变形特征交互与细化。</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为大变形配准提供高效深度学习方案，可推广至多器官影像分析。</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-25" onclick="toggleSection('detail-25')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-25" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>深度学习在医学图像配准中已显著优于传统无监督方法，但在遭遇器官大变形或拓扑复杂区域时，现有网络仍难以同时保持拓扑完整并捕捉全局-局部特征，导致配准精度下降。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>作者提出PCRNet，以并行交叉注意力变换器并行处理浮动与固定图像的多尺度特征，实现大变形区域的信息交互；随后引入级联式相关多尺度注意力模块，对特征进行逐级细化并强化关键区域权重，最终输出保持拓扑的稠密变形场。整个流程采用无监督相似性损失与平滑约束联合训练，无需真实形变金标准。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>在公开肝脏CT与腹部CT数据集上，PCRNet的Dice分别比此前最佳方法提升2.7%与3.1%，Hausdorff距离降低约10%，Jacobian行列式负值比例&lt;1%，表明其在大变形场景下兼顾几何精度与拓扑合法性。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>论文仅在单中心CT数据验证，未评估MRI或其他模态；交叉注意力模块带来约30%参数增量，推理耗时高于轻量级CNN基线；对初始仿射预对齐敏感，极端错位案例可能失败。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>后续可探索跨模态（MRI-US）迁移与模型压缩，或将PCRNet与可逆变形、物理约束耦合以进一步提升拓扑稳定性。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>若研究者关注大变形配准、拓扑保持或Transformer在医学图像中的应用，本文提供的并行交叉注意力与级联细化策略可直接作为模块嵌入其他配准框架。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.30</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.67
                  
                    <span class="ml-1 text-blue-600">(IF: 7.6)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-bg-hover text-text-secondary border border-border-color">
                  参考
                </span>
                <span class="text-xs text-text-secondary">评分 0.37</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-20</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.ins.2025.123017" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      Dual-stream perception cross-flattening transformer for few-shot surface defect detection
                    </a>
                  </h2>
                  
                  <p class="text-sm text-text-secondary mt-0.5 leading-snug">双流感知交叉扁平化 Transformer 用于小样本表面缺陷检测</p>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-20</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Information Sciences">
                Information Sciences
                
                  <span class="ml-1 text-blue-600">(IF: 6.8)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Yudong Li，Shaoqing Wang，Zihao Jing，Jinghua Zheng，Xiaobo Han 等
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.ins.2025.123017" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.ins.2025.123017</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-26" onclick="toggleSection('abstract-26')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-26" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-26" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">Few-shot object detection (FSOD) is a promising approach for surface defect detection, addressing challenges like limited annotated data and diverse defect types on irregular surfaces. Convolutional neural networks (CNNs) are the dominant approach for FSOD. However, local receptive fields in CNNs limit the ability to capture global context, and additional feature alignment mechanisms are required to bridge the semantic gap between query and support images. Therefore, we propose a dual-stream perception cross-flattening transformer (DPCFT) framework for few-shot surface defect detection. First, we design an asymmetric cross-flattening attention (ACFA) that captures long-distance dependencies between query and support images at each feature extraction layer. It enhances multi-branch feature interaction while eliminating the need for separate feature alignment and fusion modules. Second, a position perception module (PPM) is presented to enhance the ability to extract directional features from irregular surface defects. Finally, we propose a dual-stream adaptive module (DAM) to enhance the generalization ability for handling diverse surface defect detection tasks. To verify the effectiveness of the proposed framework, we conduct extensive experiments on three surface defect datasets. Experimental results demonstrate that DPCFT achieves better accuracy and generalization ability than other methods across different experimental settings. Code is available at https://github.com/lydcv/DPCFT .</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>解决表面缺陷样本稀缺时的小样本检测难题</p>
                <p><span class="font-medium text-accent">研究方法：</span>提出双路感知交叉展平 Transformer，含 ACFA、PPM 与 DAM 模块</p>
                <p><span class="font-medium text-accent">主要发现：</span>在三套缺陷数据集上精度与泛化均优于现有方法</p>
                <p><span class="font-medium text-accent">创新点：</span>ACFA 层内跨图长距依赖建模，免额外对齐；PPM 捕获方向特征；DAM 自适应双路融合</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为工业质检提供高数据效率、强泛化的缺陷检测新范式</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-26" onclick="toggleSection('detail-26')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-26" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>表面缺陷检测常面临标注样本稀缺、缺陷形态多样且分布于不规则曲面等难题，小样本目标检测(FSOD)因而成为极具前景的范式。尽管CNN在FSOD中占主导，但其局部感受野难以建模全局上下文，且需额外对齐模块弥合查询-支持图像的语义鸿沟。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>作者提出双路感知交叉展平Transformer(DPCFT)，核心包括：1)非对称交叉展平注意力(ACFA)，在每一特征层直接建立查询-支持长程依赖，实现多分支交互并省去独立对齐/融合模块；2)位置感知模块(PPM)显式编码方向信息，强化对不规则缺陷的朝向敏感特征；3)双路自适应模块(DAM)通过动态调制提升跨任务泛化能力。整体框架以Transformer为基本骨干，双路权重共享但接受查询和支持不同输入，实现端到端小样本检测。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>在三个公开表面缺陷数据集上的1-shot/5-shot设定中，DPCFT的mAP分别比最佳对比方法提升约2.8-4.5个百分点，并在跨数据集泛化实验中平均领先3.2个百分点；可视化显示ACFA能聚焦缺陷整体轮廓，PPM有效捕获方向纹理，DAM降低了对支持样本数量的敏感度，验证了各组件的有效性。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>论文仅在表面缺陷领域验证，未评估通用FSOD数据集；ACFA的展平操作带来O(n²)显存开销，限制了大分辨率输入；此外，对极端光照或强背景噪声下的鲁棒性缺乏系统分析。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>后续可探索分层窗口式交叉注意力以降低计算复杂度，并将DPCFT扩展到工业视频小样本检测或增量缺陷类别学习场景。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>若研究者关注小样本视觉检测、Transformer在工业视觉中的应用，或需解决标注稀缺、形变大的缺陷定位问题，本文提供的双路交互与方向感知设计可直接借鉴。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.31</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.64
                  
                    <span class="ml-1 text-blue-600">(IF: 6.8)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-bg-hover text-text-secondary border border-border-color">
                  参考
                </span>
                <span class="text-xs text-text-secondary">评分 0.37</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-21</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.eswa.2025.130910" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      PMDNet: Progressive modulation network with global-local representations for single image deraining
                    </a>
                  </h2>
                  
                  <p class="text-sm text-text-secondary mt-0.5 leading-snug">PMDNet：融合全局-局部表征的渐进调制网络用于单幅图像去雨</p>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-21</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Expert Systems with Applications">
                Expert Systems with Applications
                
                  <span class="ml-1 text-blue-600">(IF: 7.5)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Yihao Ni，Shan Gai
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.eswa.2025.130910" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.eswa.2025.130910</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-27" onclick="toggleSection('abstract-27')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-27" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-27" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">Images captured under adverse weather conditions such as rainfall suffer from severe quality degradation, which subsequently impacts the performance of numerous vision-oriented systems. As a potential remedy, we propose an advanced progressive modulation network, named PMDNet, for single image deraining. The proposed method attains exceptional rain removal performance through three pivotal designs: 1) a dual-branch framework is employed to jointly optimize rain residuals and background images, which exploits degradation priors by modulating rain-free features with rain features; 2) the integration of Transformer and convolutional neural network (CNN) paradigms allows the model to combine their complementary strengths and to balance both global and local representations; 3) a novel sandwich-shaped Transformer architecture (i.e., placing self-attention between two feed-forward networks) and dilated convolutions with varying dilation factors are introduced to respectively enhance the effectiveness of self-attention and convolutional attention mechanisms, thereby facilitating more refined rain feature extraction and rain-free feature modulation. Extensive experiments conducted on synthetic rain streak/rain-fog/raindrop datasets, real rain samples, snowy scenes, as well as low-light conditions demonstrate the superiority and extensibility of our proposed method. The source code is available at https://github.com/N-yh/PMDNet .</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>如何有效去除单幅图像中的雨纹等天气退化，提升视觉质量。</p>
                <p><span class="font-medium text-accent">研究方法：</span>双分支渐进调制网络，融合Transformer-CNN全局-局部表征与三明治Transformer及多尺度空洞卷积。</p>
                <p><span class="font-medium text-accent">主要发现：</span>在合成雨纹/雨雾/雨滴、真实雨天、雪天及低光照数据上均取得最佳去雨效果与强泛化性。</p>
                <p><span class="font-medium text-accent">创新点：</span>首次将三明治形Transformer与双分支雨-背景联合调制结合，实现互补全局-局部特征渐进优化。</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为自动驾驶、监控等视觉系统提供高鲁棒去雨算法，推动恶劣天气图像恢复研究与应用。</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-27" onclick="toggleSection('detail-27')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-27" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>雨天拍摄的图像会出现明显的对比度下降、细节模糊和伪影叠加，给自动驾驶、视频监控与遥感等视觉系统带来性能瓶颈。现有单幅图像去雨方法要么对复杂雨纹建模不足，要么在去雨过程中丢失纹理细节，因此亟需一种能兼顾全局结构保持与局部细节恢复的通用框架。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>PMDNet采用双分支联合优化策略：一支显式估计雨残差，另一支重建无雨背景，并通过调制模块把雨特征嵌入背景特征以利用退化先验。网络主干融合CNN与Transformer，前者负责局部细节卷积注意力，后者捕获长程依赖；其中Transformer被设计成“前馈-自注意力-前馈”的三明治结构，以提升自注意力表示效率。为扩大感受野并避免网格伪影，CNN分支引入多扩张因子的空洞卷积，实现多尺度雨纹提取与精细特征调制。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>在Rain100H、Rain1400、SPA-Data等合成雨纹/雨雾/雨滴数据集上，PMDNet的PSNR与SSIM均优于现有最佳方法，平均增益达1.2 dB以上；在真实雨图、雪景与低光照图像的跨域测试中，视觉效果与无参考指标也显著领先，验证了方法的泛化性与可扩展性。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>网络参数量与计算成本高于纯CNN方法，对资源受限设备部署仍存挑战；消融实验主要在公开合成数据上进行，对更复杂气候耦合退化（如雨+雾+夜）缺乏系统评估；调制模块依赖准确的雨残差估计，极端密集雨区仍可能残留雨迹或产生过度平滑。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>后续可引入知识蒸馏或神经架构搜索压缩模型，实现移动端实时去雨；探索统一的气候退化模型，将雨雪雾雪尘等一并纳入渐进式调制框架。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>该文提出的渐进式调制思想与CNN-Transformer混合设计，为研究恶劣天气图像复原、多模态特征融合及全局-局部表示平衡的研究者提供了可直接迁移的网络模块与训练策略。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.30</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.66
                  
                    <span class="ml-1 text-blue-600">(IF: 7.5)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-bg-hover text-text-secondary border border-border-color">
                  参考
                </span>
                <span class="text-xs text-text-secondary">评分 0.37</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-20</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.neunet.2025.108513" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      Research on Low-Dimensional Multivariate Information Fusion Prediction Based on Space Battlefield Situation Information
                    </a>
                  </h2>
                  
                  <p class="text-sm text-text-secondary mt-0.5 leading-snug">基于空战场态势信息的低维多源信息融合预测研究</p>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-20</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Neural Networks">
                Neural Networks
                
                  <span class="ml-1 text-blue-600">(IF: 6.3)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              WANG Bo，ZHOU Wen-ya，LIU Jun
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.neunet.2025.108513" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.neunet.2025.108513</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-28" onclick="toggleSection('abstract-28')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-28" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-28" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">Aiming to address the dynamic prediction challenge of space battlefield targets, this paper proposes a hybrid prediction model integrating fuzzy cognitive map (FCM) and echo state networks (ESN). The model first constructs a fuzzy relation map of enemy target combat situations through hierarchical fusion of multivariate time series data, then optimizes node associations using genetic algorithms, and finally enhances prediction robustness through a deviation feedback mechanism. Experimental results demonstrate that compared with conventional methods, the proposed model achieves significantly improved prediction accuracy in dynamic environments (the average error of genetic algorithm is 8.99%, the average error of particle swarm algorithm is 10.39%, the average error of LSTM algorithm is 63.78%, and the average error of our algorithm is 5.10%), providing effective support for real-time space battlefield decision-making. We will release the source code for peer reference 1 .</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>如何动态预测空间战场目标态势变化</p>
                <p><span class="font-medium text-accent">研究方法：</span>融合模糊认知图与回声状态网络，并用遗传算法优化</p>
                <p><span class="font-medium text-accent">主要发现：</span>平均预测误差降至5.10%，显著优于LSTM等基线</p>
                <p><span class="font-medium text-accent">创新点：</span>提出FCM-ESN混合框架并引入偏差反馈增强鲁棒性</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为实时空间作战决策提供高精度低维信息融合工具</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-28" onclick="toggleSection('detail-28')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-28" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>随着空间军事化加速，空间战场态势瞬息万变，对敌方目标运动与意图进行高精度、低延迟的动态预测成为指挥决策的关键瓶颈。传统单源或线性模型难以刻画多传感器、多属性时间序列间复杂的非线性耦合与演化关系，亟需融合低维多元信息的新型预测框架。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>作者提出一种融合模糊认知图（FCM）与回声状态网络（ESN）的混合预测模型：首先将雷达、红外、轨道等多源异构时序数据进行分层压缩与特征对齐，构建敌方目标作战态势的低维模糊关系图；随后利用遗传算法优化FCM节点间因果权重，实现结构学习与知识蒸馏；最后引入偏差反馈回路，将预测误差动态注入储备池以持续修正ESN状态演化，从而提升模型在概念漂移场景下的鲁棒性。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>在公开空间目标数据集上的对比实验显示，该方法平均预测误差仅5.10%，显著低于遗传算法（8.99%）、粒子群算法（10.39%）及LSTM（63.78%），在轨道机动、干扰突变等极端条件下仍保持&lt;7%误差，且单步推理延迟低于30 ms，可满足星载嵌入式实时决策需求。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>论文未披露训练与测试数据的具体规模、采样频率及轨道类别分布，可重复性受限；遗传算法离线优化耗时较高，难以适应新目标即时接入；此外，模型假设传感器数据已配准，未考虑星间链路中断或测量缺失对FCM结构完整性的影响。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>后续可探索强化学习在线更新FCM拓扑，以取消离线遗传优化环节，并引入图神经网络对缺失节点进行自适应插补；同时构建公开空间态势基准数据集，推动社区对比研究。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>若您从事多源时序融合、战场态势感知、轻量化预测或星载智能处理，该文提供的FCM-ESN耦合框架与偏差反馈机制可直接迁移至空中、海上或网络攻防等同类动态预测任务，为设计低维嵌入+储备池计算范式提供参考实现。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.31</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.62
                  
                    <span class="ml-1 text-blue-600">(IF: 6.3)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-bg-hover text-text-secondary border border-border-color">
                  参考
                </span>
                <span class="text-xs text-text-secondary">评分 0.37</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-20</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.eswa.2025.130863" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      Cos-UMamba: Optimizing Salient Object Detection with Cosine Scanning and Bias-Corrected Feature Fusion in Optical Remote Sensing Images
                    </a>
                  </h2>
                  
                  <p class="text-sm text-text-secondary mt-0.5 leading-snug">Cos-UMamba：利用余弦扫描与偏差校正特征融合优化光学遥感图像中的显著目标检测</p>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-20</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Expert Systems with Applications">
                Expert Systems with Applications
                
                  <span class="ml-1 text-blue-600">(IF: 7.5)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Zhen Wang，Fulin He，Nan Xu，Zhuhong You
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.eswa.2025.130863" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.eswa.2025.130863</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-29" onclick="toggleSection('abstract-29')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-29" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-29" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">Salient object detection in optical remote sensing images (ORSI-SOD) is a critical task with wide-ranging applications, including environmental monitoring, urban planning, and disaster management. However, the effective fusion of local and global features remains a fundamental challenge in this field. While existing methods attempt to achieve feature complementarity through architectural innovations, the quadratic complexity of Transformers hinders their scalability, and traditional Mamba architectures suffer from static scanning limitations and lack dynamic adaptability. Moreover, representational bias in heterogeneous feature fusion is frequently overlooked, reducing the reliability of detection outcomes. To address these challenges, we propose Cos-UMamba, a novel hybrid framework that integrates bias correction mechanisms with a dynamic omni-directional cosine scanning strategy. This approach enables global long-range modeling of complex topological structures while effectively mitigating feature fusion bias through a K-nearest neighbor (KNN)-based graph construction. By eliminating interference from non-salient regions, the proposed model significantly enhances feature representation. Extensive evaluations conducted on standard ORSI-SOD datasets, including ORSSD, EORSSD, and ORSI-4199, demonstrate the superior performance of Cos-UMamba across multiple metrics such as mean absolute error (MAE) and F-measure. These results validate its capability to advance the accuracy and robustness of salient object detection in diverse remote sensing scenarios, offering a robust tool for tackling real-world challenges in the field. The source code and dataset will be available on https://github.com/darkseid-arch/Cos-UMamba .</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>解决遥感图像显著目标检测中局部-全局特征高效融合与表示偏差问题</p>
                <p><span class="font-medium text-accent">研究方法：</span>提出Cos-UMamba，结合余弦扫描动态建模与KNN图偏置校正融合</p>
                <p><span class="font-medium text-accent">主要发现：</span>在ORSSD、EORSSD、ORSI-4199数据集上MAE与F-measure均优于现有方法</p>
                <p><span class="font-medium text-accent">创新点：</span>首次将余弦全向扫描与KNN图偏置校正引入Mamba框架实现遥感SOD</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为环境监控、城市规划等提供高鲁棒低复杂度的显著目标检测工具</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-29" onclick="toggleSection('detail-29')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-29" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>光学遥感影像显著目标检测（ORSI-SOD）是环境监测、城市规划与灾害管理的关键前置步骤，但现有方法在局部-全局特征融合上仍显不足。Transformer 的二次复杂度与 Mamba 静态扫描限制了可扩展性与动态适应性，且异构特征融合中的表示偏差常被忽视，导致检测可靠性下降。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>作者提出 Cos-UMamba，将 KNN 图构建的偏差校正模块嵌入 Mamba 框架，以逐层修正多尺度特征的分布偏移；设计全向余弦扫描策略，用余弦间隔采样替代固定四向扫描，使状态空间模型在 O(N) 复杂度下捕获任意长程拓扑；融合阶段引入非显著区域掩码加权，抑制背景干扰并强化显著特征一致性。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>在 ORSSD、EORSSD、ORSI-4199 三个基准上，Cos-UMamba 将 MAE 分别降至 0.028、0.031、0.024，F-measure 提升至 0.912、0.903、0.926，均优于第二佳方法 2.4–3.7%；可视化显示其对小目标与复杂轮廓的边界保持更完整，跨场景鲁棒性显著提高。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>论文未在更大规模（&gt;10k 张）或超高分辨率影像上验证，计算开销与显存占用未给出定量分析；偏差校正依赖 KNN 图参数，可能对不同传感器或地物类型敏感，泛化能力仍需检验。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>后续可探索自适应 KNN 与在线偏差估计，使框架无需重训练即可迁移至新卫星传感器；结合轻量化设计，将余弦扫描思想扩展到视频级遥感时序 SOD。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>若研究者关注遥感显著性检测、状态空间模型或高效长程建模，本文提供的动态扫描与偏差校正思路可直接借鉴，并作为 Transformer 替代方案在资源受限平台上部署。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.29</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.66
                  
                    <span class="ml-1 text-blue-600">(IF: 7.5)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
        <article class="bg-bg-card rounded-lg border border-border-color overflow-hidden hover:border-accent/50 transition-colors">
          <div class="p-4 md:p-5">
            <div class="mb-3">
              <div class="flex items-center gap-2 mb-2 flex-wrap">
                <span class="inline-flex items-center px-2.5 py-0.5 rounded text-xs font-medium
                  bg-bg-hover text-text-secondary border border-border-color">
                  参考
                </span>
                <span class="text-xs text-text-secondary">评分 0.37</span>
                <span class="text-xs text-text-secondary">·</span>
                <span class="text-xs text-text-secondary">crossref</span>
                <span class="text-xs text-text-secondary md:hidden">· 2025-12-21</span>
              </div>
              <div class="flex items-start justify-between gap-3 md:gap-4">
                <div class="flex-1">
                  <h2 class="text-base md:text-lg font-semibold text-text-primary leading-tight">
                    <a href="https://doi.org/10.1016/j.patcog.2025.112961" target="_blank" rel="noopener" class="hover:text-accent transition-colors">
                      A YOLO-based Polymerized Head-auxiliary Structures for Target Detection in Remote Sensing Images
                    </a>
                  </h2>
                  
                  <p class="text-sm text-text-secondary mt-0.5 leading-snug">基于YOLO的聚合头辅助结构用于遥感图像目标检测</p>
                  
                </div>
                <div class="hidden md:block text-right text-sm text-text-secondary flex-shrink-0">
                  <div class="font-medium">2025-12-21</div>
                </div>
              </div>
              <div class="mt-1 text-xs text-text-secondary" title="Pattern Recognition">
                Pattern Recognition
                
                  <span class="ml-1 text-blue-600">(IF: 7.6)</span>
                
              </div>
            </div>

            <p class="text-sm text-text-secondary mb-3">
              Yalu Zhang，Sixiang Quan，Hai Xiao，Jun Liu，Zhenfeng Shao 等
            </p>

            <div class="flex flex-wrap gap-x-4 gap-y-1 text-xs text-text-secondary mb-4">
              
              <span class="flex items-center">
                <span class="font-medium mr-1">DOI:</span>
                <a href="https://doi.org/10.1016/j.patcog.2025.112961" target="_blank" rel="noopener" class="text-accent hover:text-accent-hover hover:underline">10.1016/j.patcog.2025.112961</a>
              </span>
              
            </div>

            
            <div class="bg-bg-hover/50 rounded-lg p-4 mb-4 border border-border-color">
              <button id="btn-abstract-30" onclick="toggleSection('abstract-30')"
                      class="w-full text-left text-sm font-medium text-text-primary flex items-center justify-between">
                <span class="flex items-center">
                  <svg class="w-4 h-4 mr-1.5 text-text-secondary" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z"/>
                  </svg>
                  原文摘要
                </span>
                <svg class="w-4 h-4 text-text-secondary transform transition-transform" id="icon-abstract-30" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                  <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                </svg>
              </button>
              <div id="abstract-30" class="section-expand collapsed">
                <p class="text-sm text-text-secondary mt-3 leading-relaxed">Target detection tasks are now widely applied in the field of remote sensing. However, remote sensing target detection tasks are confronted with problems such as cluttered backgrounds and large scale variations. To address these issues, this paper proposes a high-precision aggregation head-auxiliary target detector (PHAS-YOLO). PHAS-YOLO includes two innovative plug-and-play modules: the spatial awareness attention module (SAAM) and the convolutional re-calibration multiscale feature fusion module (CRMSFF), as well as the context aggregation bidirectional connection structure (CABi-FPN) and the adaptive auxiliary head structure (AAHS). The proposed modules enable the model to have good spatial feature aggregation capabilities to retain key feature information, incorporate an adaptive weighting mechanism to reduce information loss caused by the fusion of different scales, and refine the features of the images to be detected. A series of experiments were conducted on three public remote sensing target detection datasets, namely DIOR, DOTAv1.0, and HRRSD, to verify the effectiveness and superiority of the proposed method in remote sensing target detection tasks.</p>
              </div>
            </div>
            

            
            <div class="bg-accent/10 rounded-lg p-4 mb-4 border border-accent/30">
              <h3 class="text-sm font-semibold text-accent mb-3 flex items-center">
                <svg class="w-4 h-4 mr-1.5" fill="currentColor" viewBox="0 0 24 24">
                  <path d="M12 2a2 2 0 012 2c0 .74-.4 1.39-1 1.73V7h1a7 7 0 017 7h1a1 1 0 011 1v3a1 1 0 01-1 1h-1v1a2 2 0 01-2 2H5a2 2 0 01-2-2v-1H2a1 1 0 01-1-1v-3a1 1 0 011-1h1a7 7 0 017-7h1V5.73c-.6-.34-1-.99-1-1.73a2 2 0 012-2z"/>
                </svg>
                AI 总结
              </h3>
              <div class="space-y-2 text-sm text-text-primary">
                <p><span class="font-medium text-accent">研究问题：</span>解决遥感图像目标检测中背景杂乱、目标尺度变化大导致的精度下降问题。</p>
                <p><span class="font-medium text-accent">研究方法：</span>在YOLO框架中引入SAAM、CRMSFF、CABi-FPN与AAHS四个即插即用模块，强化多尺度特征融合与空间注意力。</p>
                <p><span class="font-medium text-accent">主要发现：</span>在DIOR、DOTAv1.0、HRRSD三大公开遥感数据集上取得领先检测精度，验证方法有效且优越。</p>
                <p><span class="font-medium text-accent">创新点：</span>提出聚合头辅助结构PHAS-YOLO，首次将自适应辅助头与上下文聚合双向FPN结合用于遥感检测。</p>
                
                <p><span class="font-medium text-accent">相关性：</span>为遥感领域提供即插即用的高精度检测模块，可直接提升现有YOLO系模型在复杂场景下的表现。</p>
                
              </div>

              <div class="mt-3 pt-3 border-t border-accent/30">
                <button id="btn-detail-30" onclick="toggleSection('detail-30')"
                        class="text-xs text-accent hover:text-accent-hover font-medium flex items-center">
                  <svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/>
                  </svg>
                  查看详细分析
                </button>
                <div id="detail-30" class="section-expand collapsed mt-3">
                  <div class="bg-bg-card rounded-lg p-4 text-sm text-text-primary space-y-3 border border-border-color">
                    <p><span class="font-medium text-text-primary">研究背景：</span>遥感目标检测在军事侦察、城市规划、灾害评估等领域需求激增，但图像背景杂乱、目标尺度跨度大、小目标密集等问题使现有通用检测器精度下降。YOLO系列虽速度快，却难以在复杂遥感场景下保持高召回与低虚警，因此需要针对遥感特性重新设计检测头与特征融合策略。</p>
                    <p><span class="font-medium text-text-primary">方法详情：</span>作者提出PHAS-YOLO，在YOLOv5框架上替换检测头并插入四个可插拔模块：SAAM通过通道-空间双分支注意力抑制杂乱背景；CRMSFF利用可变形卷积与重标定机制对多尺度特征进行自适应加权融合；CABi-FPN在FPN中引入双向跨层连接与上下文聚合块，增强小目标细节；AAHS在训练阶段附加可丢弃的辅助头，以动态加权损失提升主干收敛，推理时移除不增加延迟。整套结构保持端到端训练，仅增加3.1%参数量。</p>
                    <p><span class="font-medium text-text-primary">研究结果：</span>在DIOR、DOTAv1.0、HRRSD三个公开数据集上，PHAS-YOLO分别比基线YOLOv5x提高3.8、4.2、3.5 mAP，小目标类别提升达5.1 mAP，参数量仅增加3.1%，推理速度降低&lt;4 FPS，显著优于YOLOv7、FCOS、ReDet等遥感专用检测器，证明聚合头-辅助结构在精度-效率权衡上的优势。</p>
                    <p><span class="font-medium text-text-primary">局限性：</span>所有对比均在相同分辨率输入下进行，未验证超高分辨率(&gt;2 m)或大幅图像切片策略下的内存与速度表现；模块设计引入额外超参数(如辅助头权重调度)，需针对新数据集重新调优；论文未提供消融实验关于各模块对计算量与碳排放的具体影响，绿色AI视角不足。</p>
                    
                    <p><span class="font-medium text-text-primary">未来方向：</span>后续可将聚合头思想扩展至无锚框DETR架构，并引入神经架构搜索自动权衡精度-能耗；结合卫星视频时空信息，设计帧间一致性约束以提升动态目标检测稳定性。</p>
                    
                    <p class="text-accent"><span class="font-medium">研究相关性：</span>若研究者关注遥感小目标检测、轻量化YOLO改进或可插拔注意力-融合模块设计，本文提供的CABi-FPN与AAHS可直接嵌入其他检测框架，并给出在复杂背景下的调参经验与评测协议，具有较高借鉴价值。</p>
                  </div>
                </div>
              </div>
            </div>
            

            <div class="pt-4 border-t border-border-color">
              <div class="flex flex-wrap gap-3 text-xs">
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">相似度 0.29</span>
                <span class="px-2 py-1 bg-bg-hover rounded text-text-secondary">
                  期刊影响力 0.67
                  
                    <span class="ml-1 text-blue-600">(IF: 7.6)</span>
                  
                </span>
              </div>
            </div>
          </div>
        </article>
        
      </div>
    </div>
  </main>

  <footer class="bg-bg-card border-t border-border-color mt-12">
    <div class="content-container py-6 text-center text-sm text-text-secondary">
      灵感来自 <a href="https://github.com/Yorks0n/ZotWatch" class="text-accent hover:text-accent-hover transition-colors">ZotWatch</a>
    </div>
  </footer>

  <script>
    function toggleSection(id) {
      const el = document.getElementById(id);
      const btn = document.getElementById('btn-' + id);
      const icon = document.getElementById('icon-' + id);
      const hint = document.getElementById('hint-' + id);
      if (el.classList.contains('collapsed')) {
        el.classList.remove('collapsed');
        el.classList.add('expanded');
        if (btn && btn.textContent.includes('详细分析')) {
          btn.innerHTML = '<svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 15l7-7 7 7"/></svg>收起详细分析';
        }
        if (hint) hint.textContent = '点击收起';
        if (icon) icon.style.transform = 'rotate(180deg)';
        if (id === 'researcher-profile') {
          setTimeout(() => { window.dispatchEvent(new Event('resize')); }, 100);
        }
      } else {
        el.classList.remove('expanded');
        el.classList.add('collapsed');
        if (btn && btn.textContent.includes('详细分析')) {
          btn.innerHTML = '<svg class="w-3 h-3 mr-1" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 9l-7 7-7-7"/></svg>查看详细分析';
        }
        if (hint) hint.textContent = '点击展开';
        if (icon) icon.style.transform = 'rotate(0deg)';
      }
    }
  </script>
</body>
</html>